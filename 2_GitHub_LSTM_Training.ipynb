{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6acd83e-0756-4a8a-b087-a026a5728202",
   "metadata": {},
   "source": [
    "# Reward Function Estimation Using LSTM with Attention Mechanism (Overview)\n",
    "\n",
    "This file implements the **sequential behavioral modeling pipeline**, which captures how user engagement evolves over time as behavioral histories accumulate. Its role is to learn dynamic patterns in user–ad interactions that cannot be represented by static or contextual features alone.\n",
    "\n",
    "At a high level, the file:\n",
    "- Constructs **user-level impression sequences**, ordered chronologically, to model temporal dependence in engagement.\n",
    "- Transforms impression histories into fixed-length or padded sequences suitable for sequence models.\n",
    "- Trains a **recurrent neural network (LSTM)** to predict click probabilities conditional on past behavior, capturing learning, habit formation, and persistence in user preferences.\n",
    "- Separates behavioral signals from contextual and geographic information to enable clean comparisons across information regimes.\n",
    "- Produces **behavioral counterfactual predictions** that are later used for policy evaluation and IPS-based value estimation.\n",
    "- Saves trained sequence models and out-of-sample predictions for downstream analysis, including residualized spatial tests and complementarity assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6d5c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2875838/3324023163.py:5: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each column:\n",
      "IP_ADDRESS                       1227584\n",
      "MEDIA_PACKAGE_NAME                  9515\n",
      "DEVICE_ID                         952155\n",
      "ANDROID_ID                        439344\n",
      "MODEL                               4620\n",
      "BRAND_ID                               7\n",
      "DATA                                   2\n",
      "OPERATOR_ID                            3\n",
      "ISP_ID                                 8\n",
      "LATITUDE                          250316\n",
      "LONGITUDE                         280751\n",
      "CITY                                6306\n",
      "COUNTRY                              155\n",
      "PROVINCE                             828\n",
      "CURRENT_AD_ID                         10\n",
      "PRICE                                435\n",
      "CLICK                                  2\n",
      "FRAUD_CODE                             7\n",
      "ANDROID_ID_COUNT                       4\n",
      "YEAR                                   1\n",
      "MONTH                                  1\n",
      "DAY                                   12\n",
      "HOUR                                  24\n",
      "MINUTE                                60\n",
      "SECOND                                60\n",
      "TIME                              926631\n",
      "MEDIA_PACKAGE_NAME_CLASS              52\n",
      "MEDIA_PACKAGE_NAME_EMBEDDING          51\n",
      "MODEL_CLASS                           52\n",
      "MODEL_EMBEDDING                       51\n",
      "BRAND_ID_EMBEDDING                     8\n",
      "OPERATOR_ID_EMBEDDING                  4\n",
      "ISP_ID_EMBEDDING                       9\n",
      "HOUR_SIN                              21\n",
      "HOUR_COS                              22\n",
      "MINUTE_SIN                            52\n",
      "MINUTE_COS                            52\n",
      "AD_FREQUENCY                       10473\n",
      "AD_CTR                             19230\n",
      "AD_CTR_Overall                  10337974\n",
      "EC                                 27513\n",
      "CH                                   884\n",
      "SCTR                               55761\n",
      "TSE                               304157\n",
      "TSA                               444759\n",
      "TCE                               617518\n",
      "TCA                               435878\n",
      "CTR_i_Ad                           19230\n",
      "Usage_App                         218077\n",
      "Effect_App                           457\n",
      "Preference_App                     49111\n",
      "Influence_App                        201\n",
      "Overall_Usage_App               10535649\n",
      "Overall_Effect_App               1750445\n",
      "dtype: int64\n",
      "Data type of TIME column: int64\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10537179 entries, 0 to 10537178\n",
      "Data columns (total 54 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   IP_ADDRESS                    int64  \n",
      " 1   MEDIA_PACKAGE_NAME            int64  \n",
      " 2   DEVICE_ID                     int64  \n",
      " 3   ANDROID_ID                    int64  \n",
      " 4   MODEL                         int64  \n",
      " 5   BRAND_ID                      float64\n",
      " 6   DATA                          float64\n",
      " 7   OPERATOR_ID                   float64\n",
      " 8   ISP_ID                        float64\n",
      " 9   LATITUDE                      float64\n",
      " 10  LONGITUDE                     float64\n",
      " 11  CITY                          int64  \n",
      " 12  COUNTRY                       int64  \n",
      " 13  PROVINCE                      int64  \n",
      " 14  CURRENT_AD_ID                 int64  \n",
      " 15  PRICE                         float64\n",
      " 16  CLICK                         int64  \n",
      " 17  FRAUD_CODE                    float64\n",
      " 18  ANDROID_ID_COUNT              int64  \n",
      " 19  YEAR                          int64  \n",
      " 20  MONTH                         int64  \n",
      " 21  DAY                           int64  \n",
      " 22  HOUR                          int64  \n",
      " 23  MINUTE                        int64  \n",
      " 24  SECOND                        int64  \n",
      " 25  TIME                          int64  \n",
      " 26  MEDIA_PACKAGE_NAME_CLASS      object \n",
      " 27  MEDIA_PACKAGE_NAME_EMBEDDING  int64  \n",
      " 28  MODEL_CLASS                   object \n",
      " 29  MODEL_EMBEDDING               int64  \n",
      " 30  BRAND_ID_EMBEDDING            int64  \n",
      " 31  OPERATOR_ID_EMBEDDING         int64  \n",
      " 32  ISP_ID_EMBEDDING              int64  \n",
      " 33  HOUR_SIN                      float64\n",
      " 34  HOUR_COS                      float64\n",
      " 35  MINUTE_SIN                    float64\n",
      " 36  MINUTE_COS                    float64\n",
      " 37  AD_FREQUENCY                  int64  \n",
      " 38  AD_CTR                        float64\n",
      " 39  AD_CTR_Overall                float64\n",
      " 40  EC                            int64  \n",
      " 41  CH                            int64  \n",
      " 42  SCTR                          float64\n",
      " 43  TSE                           int64  \n",
      " 44  TSA                           int64  \n",
      " 45  TCE                           int64  \n",
      " 46  TCA                           int64  \n",
      " 47  CTR_i_Ad                      float64\n",
      " 48  Usage_App                     float64\n",
      " 49  Effect_App                    float64\n",
      " 50  Preference_App                float64\n",
      " 51  Influence_App                 float64\n",
      " 52  Overall_Usage_App             float64\n",
      " 53  Overall_Effect_App            float64\n",
      "dtypes: float64(22), int64(30), object(2)\n",
      "memory usage: 4.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'dataset_LSTM4.csv'\n",
    "df = pd.read_csv(file_path).copy()\n",
    "\n",
    "unique_values = df.nunique()\n",
    "\n",
    "print(\"Number of unique values in each column:\")\n",
    "print(unique_values)\n",
    "\n",
    "print(f\"Data type of TIME column: {df['TIME'].dtype}\")\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e65df0",
   "metadata": {},
   "source": [
    "## User-Level Train–Test Split and Preprocessing\n",
    "\n",
    "This step performs the train–test split and applies feature preprocessing in a consistent manner.\n",
    "\n",
    "Impressions are first sorted by user and time, and a unique identifier is assigned to each record. User-level statistics, including click rate and exposure count, are computed. Users with at least two exposures are split into training and test sets using stratification based on binned click rates to preserve engagement distribution across splits. Users with only one exposure are assigned to the training set.\n",
    "\n",
    "For consistent transformations, training and test data are temporarily combined. Categorical features are label-encoded, and numerical features are scaled using min–max normalization. A check is performed to ensure no unintended missing values remain. The fitted scaler and encoders are saved.\n",
    "\n",
    "The data are then separated back into training and test sets and saved as preprocessed datasets for subsequent modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdcdf5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2875838/3224240507.py:11: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"dataset_LSTM4.csv\").copy()  # Original dataset with all columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution (CLICK):\n",
      "CLICK\n",
      "0    10379560\n",
      "1      157619\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample records with Unique_ID:\n",
      "   ANDROID_ID     TIME  Unique_ID\n",
      "0           1  1754345          1\n",
      "1           1  1754346          2\n",
      "2           1  1754346          3\n",
      "3           1  1754346          4\n",
      "4           1  1754392          5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2875838/3224240507.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eligible_users['CLICK_RATE_BIN'] = pd.cut(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values after fillna(0) for time features:\n",
      "Column 'ISP_ID' has 60 NaN values.\n",
      "Column 'FRAUD_CODE' has 1 NaN values.\n",
      "Full preprocessed train and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "data = pd.read_csv(\"dataset_LSTM4.csv\").copy()\n",
    "print(\"\\nClass distribution (CLICK):\")\n",
    "print(data['CLICK'].value_counts())\n",
    "\n",
    "if 'ANDROID_ID' not in data.columns or 'TIME' not in data.columns:\n",
    "    raise ValueError(\"The dataset must contain 'ANDROID_ID' and 'TIME' columns.\")\n",
    "\n",
    "data = data.sort_values(['ANDROID_ID', 'TIME']).reset_index(drop=True)\n",
    "data['Unique_ID'] = data.index + 1\n",
    "\n",
    "print(\"\\nSample records with Unique_ID:\")\n",
    "print(data[['ANDROID_ID', 'TIME', 'Unique_ID']].head())\n",
    "\n",
    "user_stats = data.groupby('ANDROID_ID', as_index=False).agg(\n",
    "    CLICK_RATE=('CLICK', 'mean'),\n",
    "    EXPOSURE_COUNT=('CLICK', 'size')\n",
    ")\n",
    "\n",
    "eligible_users = user_stats[user_stats['EXPOSURE_COUNT'] >= 2]\n",
    "single_exposure_users = user_stats[user_stats['EXPOSURE_COUNT'] < 2]\n",
    "\n",
    "eligible_users['CLICK_RATE_BIN'] = pd.cut(\n",
    "    eligible_users['CLICK_RATE'],\n",
    "    bins=[-0.01, 0.001, 0.01, 0.1, 1.0],\n",
    "    labels=[\"Very Low\", \"Low\", \"Medium\", \"High\"]\n",
    ")\n",
    "\n",
    "train_users, test_users = train_test_split(\n",
    "    eligible_users['ANDROID_ID'],\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=eligible_users['CLICK_RATE_BIN']\n",
    ")\n",
    "\n",
    "train_users_set = set(train_users)\n",
    "test_users_set = set(test_users)\n",
    "train_users_set.update(single_exposure_users['ANDROID_ID'])\n",
    "\n",
    "train_data = data[data['ANDROID_ID'].isin(train_users_set)].copy()\n",
    "test_data = data[data['ANDROID_ID'].isin(test_users_set)].copy()\n",
    "\n",
    "del data, user_stats, eligible_users, single_exposure_users\n",
    "gc.collect()\n",
    "\n",
    "data_combined = pd.concat([train_data, test_data], axis=0)\n",
    "data_combined.ffill(inplace=True)\n",
    "\n",
    "def check_nan_in_combined(data_combined):\n",
    "    nan_columns = data_combined.columns[data_combined.isnull().any()].tolist()\n",
    "    if nan_columns:\n",
    "        print(\"Columns with NaN values after fillna(0) for time features:\")\n",
    "        for col in nan_columns:\n",
    "            nan_count = data_combined[col].isnull().sum()\n",
    "            print(f\"Column '{col}' has {nan_count} NaN values.\")\n",
    "    else:\n",
    "        print(\"No NaN values detected in any column of data_combined!\")\n",
    "\n",
    "check_nan_in_combined(data_combined)\n",
    "\n",
    "categorical_features = [\n",
    "    'MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING',\n",
    "    'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING',\n",
    "    'ISP_ID_EMBEDDING', 'CURRENT_AD_ID'\n",
    "]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    data_combined[col] = le.fit_transform(data_combined[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "numerical_features = [\n",
    "    'HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS',\n",
    "    'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall',\n",
    "    'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad',\n",
    "    'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App',\n",
    "    'Overall_Usage_App', 'Overall_Effect_App'\n",
    "]\n",
    "\n",
    "non_numeric_columns = data_combined[numerical_features].select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_columns:\n",
    "    print(f\"Warning: Non-numeric columns detected: {non_numeric_columns}\")\n",
    "    numerical_features = [col for col in numerical_features if col not in non_numeric_columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_combined[numerical_features] = scaler.fit_transform(data_combined[numerical_features])\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "train_data = data_combined[data_combined['ANDROID_ID'].isin(train_users_set)].copy()\n",
    "test_data = data_combined[data_combined['ANDROID_ID'].isin(test_users_set)].copy()\n",
    "\n",
    "del data_combined\n",
    "gc.collect()\n",
    "\n",
    "train_data.to_csv('preprocessed_train_data.csv', index=False)\n",
    "test_data.to_csv('preprocessed_test_data.csv', index=False)\n",
    "print(\"Full preprocessed train and test datasets saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cbd890a-112a-4125-a367-50fef5a29bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263128/1113317056.py:5: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data  = pd.read_csv('preprocessed_test_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 6356413\n",
      "Test records:  4180766\n",
      "Unique Android_ID in Train: 297749\n",
      "Unique Android_ID in Test:  141595\n",
      "\n",
      "Ad shares head:\n",
      "                   train      test\n",
      "CURRENT_AD_ID                    \n",
      "0              0.055223  0.056366\n",
      "1              0.117319  0.116961\n",
      "2              0.113417  0.112720\n",
      "3              0.135010  0.137379\n",
      "4              0.084590  0.085222\n",
      "5              0.126608  0.126198\n",
      "6              0.222984  0.219605\n",
      "7              0.050718  0.050533\n",
      "8              0.063654  0.064845\n",
      "9              0.030477  0.030170\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('preprocessed_train_data.csv')\n",
    "test_data  = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "print(f\"Train records: {len(train_data)}\")\n",
    "print(f\"Test records:  {len(test_data)}\")\n",
    "\n",
    "print(f\"Unique Android_ID in Train: {train_data['ANDROID_ID'].nunique()}\")\n",
    "print(f\"Unique Android_ID in Test:  {test_data['ANDROID_ID'].nunique()}\")\n",
    "\n",
    "def share(df):\n",
    "    return (df[\"CURRENT_AD_ID\"].value_counts(normalize=True)\n",
    "              .rename(\"share\").sort_index())\n",
    "\n",
    "ad_share = pd.concat({\"train\": share(train_data),\n",
    "                      \"test\" : share(test_data)}, axis=1).fillna(0)\n",
    "print(\"\\nAd shares head:\\n\", ad_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb938e3-dce4-4c3c-829f-eca2ecc5991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263128/3953706396.py:5: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data  = pd.read_csv('preprocessed_test_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 6356413\n",
      "Test records:  4180766\n",
      "Unique Android_ID in Train: 297749\n",
      "Unique Android_ID in Test:  141595\n",
      "\n",
      "Ad share head:\n",
      "                train_share  test_share\n",
      "CURRENT_AD_ID                         \n",
      "0                 0.055223    0.056366\n",
      "1                 0.117319    0.116961\n",
      "2                 0.113417    0.112720\n",
      "3                 0.135010    0.137379\n",
      "4                 0.084590    0.085222\n",
      "5                 0.126608    0.126198\n",
      "6                 0.222984    0.219605\n",
      "7                 0.050718    0.050533\n",
      "8                 0.063654    0.064845\n",
      "9                 0.030477    0.030170\n",
      "\n",
      "Ad CTR head:\n",
      "                train_ctr  test_ctr\n",
      "CURRENT_AD_ID                     \n",
      "0               0.014056  0.013350\n",
      "1               0.015559  0.014851\n",
      "2               0.013977  0.013704\n",
      "3               0.025938  0.025105\n",
      "4               0.008304  0.007909\n",
      "5               0.016884  0.016137\n",
      "6               0.010675  0.010534\n",
      "7               0.014526  0.013959\n",
      "8               0.017758  0.016507\n",
      "9               0.012378  0.012566\n",
      "\n",
      "Combined ad metrics head:\n",
      "                train_share  test_share  train_ctr  test_ctr\n",
      "CURRENT_AD_ID                                              \n",
      "0                 0.055223    0.056366   0.014056  0.013350\n",
      "1                 0.117319    0.116961   0.015559  0.014851\n",
      "2                 0.113417    0.112720   0.013977  0.013704\n",
      "3                 0.135010    0.137379   0.025938  0.025105\n",
      "4                 0.084590    0.085222   0.008304  0.007909\n",
      "5                 0.126608    0.126198   0.016884  0.016137\n",
      "6                 0.222984    0.219605   0.010675  0.010534\n",
      "7                 0.050718    0.050533   0.014526  0.013959\n",
      "8                 0.063654    0.064845   0.017758  0.016507\n",
      "9                 0.030477    0.030170   0.012378  0.012566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('preprocessed_train_data.csv')\n",
    "test_data  = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "print(f\"Train records: {len(train_data)}\")\n",
    "print(f\"Test records:  {len(test_data)}\")\n",
    "\n",
    "print(f\"Unique Android_ID in Train: {train_data['ANDROID_ID'].nunique()}\")\n",
    "print(f\"Unique Android_ID in Test:  {test_data['ANDROID_ID'].nunique()}\")\n",
    "\n",
    "def share(df):\n",
    "    return (df[\"CURRENT_AD_ID\"]\n",
    "            .value_counts(normalize=True)\n",
    "            .rename(\"share\")\n",
    "            .sort_index())\n",
    "\n",
    "ad_share = pd.concat({\n",
    "    \"train_share\": share(train_data),\n",
    "    \"test_share\" : share(test_data)\n",
    "}, axis=1).fillna(0)\n",
    "print(\"\\nAd share head:\\n\", ad_share)\n",
    "\n",
    "def ctr(df):\n",
    "    return (df.groupby(\"CURRENT_AD_ID\")[\"CLICK\"]\n",
    "            .mean()\n",
    "            .rename(\"ctr\")\n",
    "            .sort_index())\n",
    "\n",
    "ad_ctr = pd.concat({\n",
    "    \"train_ctr\": ctr(train_data),\n",
    "    \"test_ctr\" : ctr(test_data)\n",
    "}, axis=1).fillna(0)\n",
    "print(\"\\nAd CTR head:\\n\", ad_ctr)\n",
    "\n",
    "ad_metrics = pd.concat([ad_share, ad_ctr], axis=1)\n",
    "print(\"\\nCombined ad metrics head:\\n\", ad_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de036ed5-5837-444e-9a82-c29e67a8c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263128/1316694156.py:7: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data  = pd.read_csv('preprocessed_test_data.csv')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ad shares head:\n",
      " CURRENT_AD_ID\n",
      "0    0.055677\n",
      "1    0.117177\n",
      "2    0.113141\n",
      "3    0.135950\n",
      "4    0.084841\n",
      "5    0.126445\n",
      "6    0.221644\n",
      "7    0.050645\n",
      "8    0.064126\n",
      "9    0.030355\n",
      "Name: share, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv('preprocessed_train_data.csv')\n",
    "test_data  = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "df['history_length'] = df.groupby('ANDROID_ID').cumcount()\n",
    "\n",
    "all_history  = df['history_length']\n",
    "click_history = df.loc[df['CLICK'] == 1, 'history_length']\n",
    "\n",
    "max_hist = 500\n",
    "all_hist_lim   = all_history[all_history  <= max_hist]\n",
    "click_hist_lim = click_history[click_history <= max_hist]\n",
    "\n",
    "def plot_cdf(data, label):\n",
    "    sorted_data = np.sort(data)\n",
    "    cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    plt.plot(sorted_data, cdf, label=label)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_cdf(all_hist_lim,   'All Impressions (≤500)')\n",
    "plot_cdf(click_hist_lim, 'Clicks (≤500)')\n",
    "plt.xlabel('History Length (Number of Previous Impressions)', fontsize= 14)\n",
    "plt.ylabel('Cumulative Distribution Function', fontsize= 14)\n",
    "plt.title('CDF of User History Length for Impressions vs. Clicks', fontsize= 16)\n",
    "plt.xlim(0, max_hist)\n",
    "plt.legend()\n",
    "plt.grid(axis='both', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def share(df):\n",
    "    return (df[\"CURRENT_AD_ID\"].value_counts(normalize=True)\n",
    "              .rename(\"share\").sort_index())\n",
    "\n",
    "\n",
    "print(\"\\nAd shares head:\\n\", share(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f715aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2875838/685360985.py:5: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each column:\n",
      "IP_ADDRESS                       528896\n",
      "MEDIA_PACKAGE_NAME                 8561\n",
      "DEVICE_ID                        346578\n",
      "ANDROID_ID                       141595\n",
      "MODEL                              2995\n",
      "BRAND_ID                              7\n",
      "DATA                                  2\n",
      "OPERATOR_ID                           3\n",
      "ISP_ID                                8\n",
      "LATITUDE                         101960\n",
      "LONGITUDE                        118103\n",
      "CITY                               3942\n",
      "COUNTRY                             125\n",
      "PROVINCE                            553\n",
      "CURRENT_AD_ID                        10\n",
      "PRICE                               428\n",
      "CLICK                                 2\n",
      "FRAUD_CODE                            7\n",
      "ANDROID_ID_COUNT                      3\n",
      "YEAR                                  1\n",
      "MONTH                                 1\n",
      "DAY                                  12\n",
      "HOUR                                 24\n",
      "MINUTE                               60\n",
      "SECOND                               60\n",
      "TIME                             846151\n",
      "MEDIA_PACKAGE_NAME_CLASS             52\n",
      "MEDIA_PACKAGE_NAME_EMBEDDING         51\n",
      "MODEL_CLASS                          52\n",
      "MODEL_EMBEDDING                      51\n",
      "BRAND_ID_EMBEDDING                    8\n",
      "OPERATOR_ID_EMBEDDING                 4\n",
      "ISP_ID_EMBEDDING                      9\n",
      "HOUR_SIN                             20\n",
      "HOUR_COS                             21\n",
      "MINUTE_SIN                           46\n",
      "MINUTE_COS                           49\n",
      "AD_FREQUENCY                      10335\n",
      "AD_CTR                             7717\n",
      "AD_CTR_Overall                  4140546\n",
      "EC                                27513\n",
      "CH                                  106\n",
      "SCTR                              25465\n",
      "TSE                              189678\n",
      "TSA                              294941\n",
      "TCE                              438212\n",
      "TCA                              251931\n",
      "CTR_i_Ad                           7717\n",
      "Usage_App                        145041\n",
      "Effect_App                          326\n",
      "Preference_App                    28585\n",
      "Influence_App                       170\n",
      "Overall_Usage_App               4180530\n",
      "Overall_Effect_App              1105341\n",
      "Unique_ID                       4180766\n",
      "dtype: int64\n",
      "Data type of TIME column: int64\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4180766 entries, 0 to 4180765\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   IP_ADDRESS                    int64  \n",
      " 1   MEDIA_PACKAGE_NAME            int64  \n",
      " 2   DEVICE_ID                     int64  \n",
      " 3   ANDROID_ID                    int64  \n",
      " 4   MODEL                         int64  \n",
      " 5   BRAND_ID                      float64\n",
      " 6   DATA                          float64\n",
      " 7   OPERATOR_ID                   float64\n",
      " 8   ISP_ID                        float64\n",
      " 9   LATITUDE                      float64\n",
      " 10  LONGITUDE                     float64\n",
      " 11  CITY                          int64  \n",
      " 12  COUNTRY                       int64  \n",
      " 13  PROVINCE                      int64  \n",
      " 14  CURRENT_AD_ID                 int64  \n",
      " 15  PRICE                         float64\n",
      " 16  CLICK                         int64  \n",
      " 17  FRAUD_CODE                    float64\n",
      " 18  ANDROID_ID_COUNT              int64  \n",
      " 19  YEAR                          int64  \n",
      " 20  MONTH                         int64  \n",
      " 21  DAY                           int64  \n",
      " 22  HOUR                          int64  \n",
      " 23  MINUTE                        int64  \n",
      " 24  SECOND                        int64  \n",
      " 25  TIME                          int64  \n",
      " 26  MEDIA_PACKAGE_NAME_CLASS      object \n",
      " 27  MEDIA_PACKAGE_NAME_EMBEDDING  int64  \n",
      " 28  MODEL_CLASS                   object \n",
      " 29  MODEL_EMBEDDING               int64  \n",
      " 30  BRAND_ID_EMBEDDING            int64  \n",
      " 31  OPERATOR_ID_EMBEDDING         int64  \n",
      " 32  ISP_ID_EMBEDDING              int64  \n",
      " 33  HOUR_SIN                      float64\n",
      " 34  HOUR_COS                      float64\n",
      " 35  MINUTE_SIN                    float64\n",
      " 36  MINUTE_COS                    float64\n",
      " 37  AD_FREQUENCY                  float64\n",
      " 38  AD_CTR                        float64\n",
      " 39  AD_CTR_Overall                float64\n",
      " 40  EC                            float64\n",
      " 41  CH                            float64\n",
      " 42  SCTR                          float64\n",
      " 43  TSE                           float64\n",
      " 44  TSA                           float64\n",
      " 45  TCE                           float64\n",
      " 46  TCA                           float64\n",
      " 47  CTR_i_Ad                      float64\n",
      " 48  Usage_App                     float64\n",
      " 49  Effect_App                    float64\n",
      " 50  Preference_App                float64\n",
      " 51  Influence_App                 float64\n",
      " 52  Overall_Usage_App             float64\n",
      " 53  Overall_Effect_App            float64\n",
      " 54  Unique_ID                     int64  \n",
      "dtypes: float64(29), int64(24), object(2)\n",
      "memory usage: 1.7+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'preprocessed_test_data.csv'\n",
    "df = pd.read_csv(file_path).copy()\n",
    "\n",
    "unique_values = df.nunique()\n",
    "\n",
    "print(\"Number of unique values in each column:\")\n",
    "print(unique_values)\n",
    "\n",
    "print(f\"Data type of TIME column: {df['TIME'].dtype}\")\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "df = df.sort_values(by=['ANDROID_ID', 'TIME']).reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "dff = df.head(2000)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "dff\n",
    "\n",
    "output_file = \"TEST5.csv\"\n",
    "dff.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853530f",
   "metadata": {},
   "source": [
    "### Random User Validation\n",
    "As a final check, we validate the preprocessing pipeline on a randomly selected user. For a given user ID, we reconstruct the padded sequence, including numerical features, embedding features, targets, masks, timestamps, and unique identifiers. The resulting sequence is exported for manual inspection to verify that all features follow the intended temporal and logical structure, and that padding and masking behave as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e30bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full preprocessed train and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "test_data = pd.read_csv(\"preprocessed_test_data.csv\").copy()\n",
    "test_data = test_data[test_data['ANDROID_ID'] == 1369]\n",
    "if test_data.empty:\n",
    "    raise ValueError(\"ANDROID_ID 1369 not found in the dataset.\")\n",
    "\n",
    "test_data.sort_values(['ANDROID_ID', 'TIME'], inplace=True)\n",
    "test_data['SEQ_POS'] = test_data.groupby('ANDROID_ID').cumcount()\n",
    "\n",
    "max_seq_length = 150\n",
    "\n",
    "embedding_features = [\n",
    "    'MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING',\n",
    "    'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING',\n",
    "    'ISP_ID_EMBEDDING', 'CURRENT_AD_ID'\n",
    "]\n",
    "numerical_features = [\n",
    "    'HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS',\n",
    "    'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall',\n",
    "    'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad',\n",
    "    'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App',\n",
    "    'Overall_Usage_App', 'Overall_Effect_App'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def prepare_user_data(data, max_seq_length, numerical_features, embedding_features):\n",
    "    data = data.iloc[-max_seq_length:]\n",
    "    seq_len = len(data)\n",
    "    padding_needed = max_seq_length - seq_len\n",
    "\n",
    "    X_numerical = data[numerical_features].values\n",
    "    if padding_needed > 0:\n",
    "        X_numerical = np.pad(X_numerical, ((padding_needed, 0), (0, 0)), mode='constant', constant_values=0.0)\n",
    "\n",
    "    X_embedding = {}\n",
    "    for col in embedding_features:\n",
    "        if col in data.columns:\n",
    "            X_emb = data[col].values\n",
    "            if padding_needed > 0:\n",
    "                X_emb = np.pad(X_emb, (padding_needed, 0), mode='constant', constant_values=0)\n",
    "            X_embedding[col] = X_emb\n",
    "        else:\n",
    "            raise ValueError(f\"Embedding column {col} not found in the dataset.\")\n",
    "\n",
    "    y = data['CLICK'].values.astype(float)\n",
    "    if padding_needed > 0:\n",
    "        y = np.pad(y, (padding_needed, 0), mode='constant', constant_values=-1.0)\n",
    "    mask = (y != -1.0).astype(float)\n",
    "    y = np.where(y == -1.0, 0.0, y)\n",
    "\n",
    "    time_seq = data['TIME'].values\n",
    "    if padding_needed > 0:\n",
    "        time_seq = np.pad(time_seq, (padding_needed, 0), mode='constant', constant_values=0)\n",
    "\n",
    "    unique_id_seq = data['Unique_ID'].values\n",
    "    if padding_needed > 0:\n",
    "        unique_id_seq = np.pad(unique_id_seq, (padding_needed, 0), mode='constant', constant_values=0)\n",
    "\n",
    "    return X_numerical, X_embedding, y, mask, time_seq, unique_id_seq\n",
    "\n",
    "X_numerical, X_embedding, y, mask, times, unique_ids = prepare_user_data(\n",
    "    test_data, max_seq_length, numerical_features, embedding_features\n",
    ")\n",
    "\n",
    "debug_data = pd.DataFrame(X_numerical, columns=numerical_features)\n",
    "debug_data['TARGET'] = y\n",
    "debug_data['MASK'] = mask\n",
    "debug_data['TIME'] = times\n",
    "debug_data['Unique_ID'] = unique_ids\n",
    "\n",
    "for col in embedding_features:\n",
    "    debug_data[col] = X_embedding[col]\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "debug_file_path = os.path.join(output_dir, f\"user_1369_debug.csv\")\n",
    "debug_data.to_csv(debug_file_path, index=False)\n",
    "print(\"Full preprocessed train and test datasets saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118da30-e108-4458-a214-f4695c64b36b",
   "metadata": {},
   "source": [
    "## Behavioral Sequence Tensor Construction\n",
    "\n",
    "This step prepares sequence tensors for the **behavioral model only**, excluding geographic features. The inputs consist of behavioral, temporal, and ad-related features that evolve over user history.\n",
    "\n",
    "Impressions are sorted chronologically within each user. For each user, the most recent `max_seq_length` observations are retained. Sequences shorter than this length are **right-padded** with zeros to obtain a fixed-length tensor. Numerical features are stored as floating-point arrays, while categorical features are stored as integer arrays for embedding layers.\n",
    "\n",
    "Targets (`CLICK`) are padded using a sentinel value and a corresponding **mask** is created to indicate valid (non-padded) positions. During training, this mask ensures that padded timesteps do not contribute to the loss, preventing leakage from artificial padding values.\n",
    "\n",
    "Class weights are computed using valid training targets to address click imbalance.\n",
    "\n",
    "The final output includes numerical tensors, embedding tensors, target sequences, masks, and metadata for both train and test sets, all saved for downstream LSTM training of the behavioral model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, gc, os\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data = pd.read_csv(\"preprocessed_train_data.csv\").copy()\n",
    "test_data  = pd.read_csv(\"preprocessed_test_data.csv\").copy()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in geo_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_data[col], test_data[col]], axis=0).astype(str))\n",
    "    train_data[f\"{col}_EMB\"] = le.transform(train_data[col].astype(str))\n",
    "    test_data[f\"{col}_EMB\"]  = le.transform(test_data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "train_data.sort_values(['ANDROID_ID', 'TIME'], inplace=True)\n",
    "test_data.sort_values(['ANDROID_ID', 'TIME'], inplace=True)\n",
    "\n",
    "train_data['SEQ_POS'] = train_data.groupby('ANDROID_ID').cumcount()\n",
    "test_data['SEQ_POS']  = test_data.groupby('ANDROID_ID').cumcount()\n",
    "\n",
    "max_seq_length = 150\n",
    "\n",
    "embedding_features = [\n",
    "    'MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING',\n",
    "    'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING',\n",
    "    'ISP_ID_EMBEDDING', 'CURRENT_AD_ID',\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS',\n",
    "    'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall',\n",
    "    'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad',\n",
    "    'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App',\n",
    "    'Overall_Usage_App',\n",
    "]\n",
    "\n",
    "def prepare_data(data, maxlen, num_feats, emb_feats):\n",
    "    data = data.groupby('ANDROID_ID', group_keys=False).apply(lambda x: x.iloc[-maxlen:])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data['SEQ_POS'] = data.groupby('ANDROID_ID').cumcount()\n",
    "    data.set_index(['ANDROID_ID', 'SEQ_POS'], inplace=True)\n",
    "\n",
    "    user_ids = data.index.get_level_values(0).unique()\n",
    "    X_num_all, y_all, mask_all, time_all, uid_all = [], [], [], [], []\n",
    "    X_emb_dict = {c: [] for c in emb_feats}\n",
    "\n",
    "    for uid in user_ids:\n",
    "        seq = data.loc[uid]\n",
    "        pad = maxlen - len(seq)\n",
    "\n",
    "        X_num = seq[num_feats].values.astype(np.float64)\n",
    "        if pad:\n",
    "            X_num = np.pad(X_num, ((0, pad), (0, 0)))\n",
    "        X_num_all.append(X_num)\n",
    "\n",
    "        for col in emb_feats:\n",
    "            X_e = seq[col].values.astype(np.int64)\n",
    "            if pad:\n",
    "                X_e = np.pad(X_e, (0, pad))\n",
    "            X_emb_dict[col].append(X_e)\n",
    "\n",
    "        y = seq['CLICK'].values.astype(np.float64)\n",
    "        if pad:\n",
    "            y = np.pad(y, (0, pad), constant_values=-1)\n",
    "        mask = (y != -1).astype(np.float64)\n",
    "        y[y == -1] = 0\n",
    "        y_all.append(y)\n",
    "        mask_all.append(mask)\n",
    "\n",
    "        t = seq['TIME'].values\n",
    "        u = seq['Unique_ID'].values\n",
    "        if pad:\n",
    "            t = np.pad(t, (0, pad))\n",
    "            u = np.pad(u, (0, pad))\n",
    "        time_all.append(t)\n",
    "        uid_all.append(u)\n",
    "\n",
    "    return (\n",
    "        np.array(X_num_all, dtype=np.float64),\n",
    "        {k: np.array(v, dtype=np.int64) for k, v in X_emb_dict.items()},\n",
    "        np.array(y_all, dtype=np.float64),\n",
    "        np.array(mask_all, dtype=np.float64),\n",
    "        user_ids.tolist(),\n",
    "        time_all,\n",
    "        uid_all\n",
    "    )\n",
    "\n",
    "X_train_num, X_train_emb, y_train, train_mask, train_ids, train_times, train_uids = prepare_data(\n",
    "    train_data, max_seq_length, numerical_features, embedding_features\n",
    ")\n",
    "\n",
    "X_test_num, X_test_emb, y_test, test_mask, test_ids, test_times, test_uids = prepare_data(\n",
    "    test_data, max_seq_length, numerical_features, embedding_features\n",
    ")\n",
    "\n",
    "valid_clicks = y_train[train_mask == 1]\n",
    "cw = class_weight.compute_class_weight('balanced', classes=np.unique(valid_clicks), y=valid_clicks)\n",
    "class_weight_dict = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "out = {\n",
    "    'X_train_numerical': X_train_num,\n",
    "    'X_train_embedding': X_train_emb,\n",
    "    'y_train': y_train,\n",
    "    'train_mask': train_mask,\n",
    "    'X_test_numerical': X_test_num,\n",
    "    'X_test_embedding': X_test_emb,\n",
    "    'y_test': y_test,\n",
    "    'test_mask': test_mask,\n",
    "    'class_weight_dict': class_weight_dict,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'numerical_features': numerical_features,\n",
    "    'embedding_features': embedding_features,\n",
    "    'train_user_ids': train_ids,\n",
    "    'train_times': train_times,\n",
    "    'train_unique_ids': train_uids,\n",
    "    'test_user_ids': test_ids,\n",
    "    'test_times': test_times,\n",
    "    'test_unique_ids': test_uids,\n",
    "}\n",
    "\n",
    "with open('processed_data_pytorch.pkl', 'wb') as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "with open('label_encoders0.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "with open('params0.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'max_seq_length': max_seq_length,\n",
    "        'numerical_features': numerical_features,\n",
    "        'embedding_features': embedding_features\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea8fdd-4027-4d9e-b7d0-2a77a9b5e6d6",
   "metadata": {},
   "source": [
    "### LSTM Data Validation For Behavioral Model\n",
    "\n",
    "We validate the LSTM data construction by selecting random users from the processed test set and reconstructing their full padded sequences. For each user, we inspect numerical features, embedding features, targets, masks, timestamps, and unique identifiers to ensure that sequence truncation, right-padding, and masking follow the intended temporal logic. This step confirms that the model inputs are correctly aligned and that padded positions are properly identified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a16da7-b4d6-4f05-94ad-b77da2345e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train_numerical', 'X_train_embedding', 'y_train', 'train_mask', 'X_test_numerical', 'X_test_embedding', 'y_test', 'test_mask', 'class_weight_dict', 'max_seq_length', 'numerical_features', 'embedding_features', 'train_user_ids', 'train_times', 'train_unique_ids', 'test_user_ids', 'test_times', 'test_unique_ids']\n",
      "Numerical Features Columns:\n",
      "['HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS', 'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall', 'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad', 'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App', 'Overall_Usage_App']\n",
      "\n",
      "Embedding Features Columns:\n",
      "['MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING', 'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING', 'ISP_ID_EMBEDDING', 'CURRENT_AD_ID']\n",
      "Retrieved test data for ANDROID_ID 1369 has been saved to output/retrieved_user_1369_test.csv\n",
      "\n",
      "Sample retrieved data (valid entries):\n",
      "     HOUR_SIN  HOUR_COS  MINUTE_SIN  MINUTE_COS  AD_FREQUENCY  AD_CTR  \\\n",
      "0    0.982963   0.37059    0.066987    0.250000      0.000000     0.0   \n",
      "1    0.982963   0.37059    0.066987    0.250000      0.000000     0.0   \n",
      "2    0.982963   0.37059    0.043227    0.296632      0.000095     0.0   \n",
      "3    0.982963   0.37059    0.043227    0.296632      0.000191     0.0   \n",
      "4    0.982963   0.37059    0.024472    0.345492      0.000286     0.0   \n",
      "..        ...       ...         ...         ...           ...     ...   \n",
      "145  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "146  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "147  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "148  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "149  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "\n",
      "     AD_CTR_Overall        EC   CH  SCTR  ...  TARGET  MASK     TIME  \\\n",
      "0          0.014339  0.000000  0.0   0.0  ...     0.0   1.0  1755605   \n",
      "1          0.009804  0.000036  0.0   0.0  ...     0.0   1.0  1755622   \n",
      "2          0.014941  0.000073  0.0   0.0  ...     0.0   1.0  1755690   \n",
      "3          0.014545  0.000109  0.0   0.0  ...     0.0   1.0  1755709   \n",
      "4          0.014007  0.000145  0.0   0.0  ...     0.0   1.0  1755740   \n",
      "..              ...       ...  ...   ...  ...     ...   ...      ...   \n",
      "145        0.000000  0.000000  0.0   0.0  ...     0.0   0.0        0   \n",
      "146        0.000000  0.000000  0.0   0.0  ...     0.0   0.0        0   \n",
      "147        0.000000  0.000000  0.0   0.0  ...     0.0   0.0        0   \n",
      "148        0.000000  0.000000  0.0   0.0  ...     0.0   0.0        0   \n",
      "149        0.000000  0.000000  0.0   0.0  ...     0.0   0.0        0   \n",
      "\n",
      "     Unique_ID  MEDIA_PACKAGE_NAME_EMBEDDING  MODEL_EMBEDDING  \\\n",
      "0        20707                            46               46   \n",
      "1        20708                            46               46   \n",
      "2        20709                            46               46   \n",
      "3        20710                            46               46   \n",
      "4        20711                            46               46   \n",
      "..         ...                           ...              ...   \n",
      "145          0                             0                0   \n",
      "146          0                             0                0   \n",
      "147          0                             0                0   \n",
      "148          0                             0                0   \n",
      "149          0                             0                0   \n",
      "\n",
      "     BRAND_ID_EMBEDDING  OPERATOR_ID_EMBEDDING  ISP_ID_EMBEDDING  \\\n",
      "0                     0                      0                 8   \n",
      "1                     0                      0                 8   \n",
      "2                     0                      0                 8   \n",
      "3                     0                      0                 8   \n",
      "4                     0                      0                 8   \n",
      "..                  ...                    ...               ...   \n",
      "145                   0                      0                 0   \n",
      "146                   0                      0                 0   \n",
      "147                   0                      0                 0   \n",
      "148                   0                      0                 0   \n",
      "149                   0                      0                 0   \n",
      "\n",
      "     CURRENT_AD_ID  \n",
      "0                4  \n",
      "1                3  \n",
      "2                4  \n",
      "3                4  \n",
      "4                4  \n",
      "..             ...  \n",
      "145              0  \n",
      "146              0  \n",
      "147              0  \n",
      "148              0  \n",
      "149              0  \n",
      "\n",
      "[150 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(\"processed_data_pytorch.pkl\", \"rb\") as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "processed_data_keys = list(processed_data.keys())\n",
    "print(processed_data_keys)\n",
    "\n",
    "X_test_numerical = processed_data[\"X_test_numerical\"]\n",
    "X_test_embedding = processed_data[\"X_test_embedding\"]\n",
    "y_test = processed_data[\"y_test\"]\n",
    "test_mask = processed_data[\"test_mask\"]\n",
    "test_user_ids = processed_data[\"test_user_ids\"]\n",
    "test_times = processed_data[\"test_times\"]\n",
    "test_unique_ids = processed_data[\"test_unique_ids\"]\n",
    "\n",
    "numerical_features = processed_data[\"numerical_features\"]\n",
    "embedding_features = processed_data[\"embedding_features\"]\n",
    "\n",
    "print(\"Numerical Features Columns:\")\n",
    "print(numerical_features)\n",
    "\n",
    "print(\"\\nEmbedding Features Columns:\")\n",
    "print(embedding_features)\n",
    "\n",
    "target_id = 1369\n",
    "\n",
    "if target_id not in test_user_ids:\n",
    "    raise ValueError(f\"ANDROID_ID {target_id} not found in the processed test data.\")\n",
    "\n",
    "target_index = test_user_ids.index(target_id)\n",
    "\n",
    "retrieved_numerical = np.array(X_test_numerical)[target_index]\n",
    "\n",
    "retrieved_embedding = {\n",
    "    feature: np.array(X_test_embedding[feature])[target_index] for feature in embedding_features\n",
    "}\n",
    "\n",
    "retrieved_y = np.array(y_test)[target_index]\n",
    "retrieved_mask = np.array(test_mask)[target_index]\n",
    "retrieved_times = np.array(test_times)[target_index]\n",
    "retrieved_unique_ids = np.array(test_unique_ids)[target_index]\n",
    "\n",
    "retrieved_data = pd.DataFrame(retrieved_numerical, columns=numerical_features)\n",
    "retrieved_data[\"TARGET\"] = retrieved_y\n",
    "retrieved_data[\"MASK\"] = retrieved_mask\n",
    "retrieved_data[\"TIME\"] = retrieved_times\n",
    "retrieved_data[\"Unique_ID\"] = retrieved_unique_ids\n",
    "\n",
    "for feature in embedding_features:\n",
    "    retrieved_data[feature] = retrieved_embedding[feature]\n",
    "\n",
    "valid_data = retrieved_data[retrieved_data[\"MASK\"] == 1]\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f\"retrieved_user_{target_id}_test.csv\")\n",
    "retrieved_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Retrieved test data for ANDROID_ID {target_id} has been saved to {output_file}\")\n",
    "print(\"\\nSample retrieved data (valid entries):\")\n",
    "print(retrieved_data.head(150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288ab387-4442-4847-a37b-df5082068009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEDIA_PACKAGE_NAME_EMBEDDING': array([[46, 46, 46, ...,  0,  0,  0],\n",
       "        [12, 12, 46, ...,  0,  0,  0],\n",
       "        [46, 46,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [ 3,  3,  3, ...,  0,  0,  0]]),\n",
       " 'MODEL_EMBEDDING': array([[27, 27, 27, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [ 2,  2,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [11, 11, 11, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0]]),\n",
       " 'BRAND_ID_EMBEDDING': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 2, 2, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'OPERATOR_ID_EMBEDDING': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [2, 2, 2, ..., 0, 0, 0]]),\n",
       " 'ISP_ID_EMBEDDING': array([[7, 8, 8, ..., 0, 0, 0],\n",
       "        [7, 7, 0, ..., 0, 0, 0],\n",
       "        [8, 8, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        [4, 8, 8, ..., 0, 0, 0]]),\n",
       " 'CURRENT_AD_ID': array([[4, 4, 4, ..., 0, 0, 0],\n",
       "        [9, 1, 5, ..., 0, 0, 0],\n",
       "        [1, 6, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [8, 1, 2, ..., 0, 0, 0],\n",
       "        [4, 4, 3, ..., 0, 0, 0],\n",
       "        [5, 4, 0, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('processed_data_pytorch.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "processed_data['X_test_embedding']  \n",
    "processed_data['X_test_embedding'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46331075-c0e3-4483-ad66-5bd389006baa",
   "metadata": {},
   "source": [
    "### Full Model Sequence Tensor Construction (Behavioral + Geographical)\n",
    "\n",
    "This step prepares sequence tensors for the **full model**, which includes both behavioral features and geographic information. The inputs combine dynamic behavioral variables, ad-related metrics, temporal signals, and encoded geographic features (e.g., city, province, country).\n",
    "\n",
    "Impressions are sorted chronologically within each user. For each user, the most recent `max_seq_length` observations are retained. Sequences shorter than this length are **right-padded** with zeros to produce fixed-length tensors suitable for batch training. Numerical features are stored as floating-point arrays, and categorical features—including geographic embeddings—are stored as integer arrays for embedding layers.\n",
    "\n",
    "Targets (`CLICK`) are padded using a sentinel value, and a corresponding **mask** is constructed to identify valid timesteps. During training, this mask ensures that padded positions do not contribute to the loss, so only real historical observations influence parameter updates.\n",
    "\n",
    "Class weights are computed from valid training targets to account for class imbalance in click prediction.\n",
    "\n",
    "The resulting artifacts include numerical tensors, embedding tensors (behavioral and geographic), target sequences, masks, and metadata for both training and test sets. These are serialized and saved for downstream LSTM training of the full model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816929-2b00-43b2-bc24-b83b493390dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, gc, os\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data = pd.read_csv(\"preprocessed_train_data.csv\").copy()\n",
    "test_data  = pd.read_csv(\"preprocessed_test_data.csv\").copy()\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in geo_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_data[col], test_data[col]], axis=0).astype(str))\n",
    "    train_data[f\"{col}_EMB\"] = le.transform(train_data[col].astype(str))\n",
    "    test_data[f\"{col}_EMB\"]  = le.transform(test_data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "train_data.sort_values(['ANDROID_ID', 'TIME'], inplace=True)\n",
    "test_data.sort_values(['ANDROID_ID', 'TIME'], inplace=True)\n",
    "\n",
    "train_data['SEQ_POS'] = train_data.groupby('ANDROID_ID').cumcount()\n",
    "test_data['SEQ_POS']  = test_data.groupby('ANDROID_ID').cumcount()\n",
    "\n",
    "max_seq_length = 150\n",
    "\n",
    "embedding_features = [\n",
    "    'MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING',\n",
    "    'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING',\n",
    "    'ISP_ID_EMBEDDING', 'CURRENT_AD_ID',\n",
    "    'CITY', 'PROVINCE'  # geo categorical\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS',\n",
    "    'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall',\n",
    "    'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad',\n",
    "    'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App',\n",
    "    'Overall_Usage_App',\n",
    "    'LATITUDE', 'LONGITUDE' # geo numeric\n",
    "]\n",
    "\n",
    "def prepare_data(data, maxlen, num_feats, emb_feats):\n",
    "    data = data.groupby('ANDROID_ID', group_keys=False).apply(lambda x: x.iloc[-maxlen:])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data['SEQ_POS'] = data.groupby('ANDROID_ID').cumcount()\n",
    "    data.set_index(['ANDROID_ID', 'SEQ_POS'], inplace=True)\n",
    "\n",
    "    user_ids = data.index.get_level_values(0).unique()\n",
    "    X_num_all, y_all, mask_all, time_all, uid_all = [], [], [], [], []\n",
    "    X_emb_dict = {c: [] for c in emb_feats}\n",
    "\n",
    "    for uid in user_ids:\n",
    "        seq = data.loc[uid]\n",
    "        pad = maxlen - len(seq)\n",
    "\n",
    "        X_num = seq[num_feats].values.astype(np.float64)\n",
    "        if pad:\n",
    "            X_num = np.pad(X_num, ((0, pad), (0, 0)))\n",
    "        X_num_all.append(X_num)\n",
    "\n",
    "        for col in emb_feats:\n",
    "            X_e = seq[col].values.astype(np.int64)\n",
    "            if pad:\n",
    "                X_e = np.pad(X_e, (0, pad))\n",
    "            X_emb_dict[col].append(X_e)\n",
    "\n",
    "        y = seq['CLICK'].values.astype(np.float64)\n",
    "        if pad:\n",
    "            y = np.pad(y, (0, pad), constant_values=-1)\n",
    "        mask = (y != -1).astype(np.float64)\n",
    "        y[y == -1] = 0\n",
    "        y_all.append(y)\n",
    "        mask_all.append(mask)\n",
    "\n",
    "        t = seq['TIME'].values\n",
    "        u = seq['Unique_ID'].values\n",
    "        if pad:\n",
    "            t = np.pad(t, (0, pad))\n",
    "            u = np.pad(u, (0, pad))\n",
    "        time_all.append(t)\n",
    "        uid_all.append(u)\n",
    "\n",
    "    return (\n",
    "        np.array(X_num_all, dtype=np.float64),\n",
    "        {k: np.array(v, dtype=np.int64) for k, v in X_emb_dict.items()},\n",
    "        np.array(y_all, dtype=np.float64),\n",
    "        np.array(mask_all, dtype=np.float64),\n",
    "        user_ids.tolist(),\n",
    "        time_all,\n",
    "        uid_all\n",
    "    )\n",
    "\n",
    "X_train_num, X_train_emb, y_train, train_mask, train_ids, train_times, train_uids = prepare_data(\n",
    "    train_data, max_seq_length, numerical_features, embedding_features\n",
    ")\n",
    "\n",
    "X_test_num, X_test_emb, y_test, test_mask, test_ids, test_times, test_uids = prepare_data(\n",
    "    test_data, max_seq_length, numerical_features, embedding_features\n",
    ")\n",
    "\n",
    "valid_clicks = y_train[train_mask == 1]\n",
    "cw = class_weight.compute_class_weight('balanced', classes=np.unique(valid_clicks), y=valid_clicks)\n",
    "class_weight_dict = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "out = {\n",
    "    'X_train_numerical': X_train_num,\n",
    "    'X_train_embedding': X_train_emb,\n",
    "    'y_train': y_train,\n",
    "    'train_mask': train_mask,\n",
    "    'X_test_numerical': X_test_num,\n",
    "    'X_test_embedding': X_test_emb,\n",
    "    'y_test': y_test,\n",
    "    'test_mask': test_mask,\n",
    "    'class_weight_dict': class_weight_dict,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'numerical_features': numerical_features,\n",
    "    'embedding_features': embedding_features,\n",
    "    'train_user_ids': train_ids,\n",
    "    'train_times': train_times,\n",
    "    'train_unique_ids': train_uids,\n",
    "    'test_user_ids': test_ids,\n",
    "    'test_times': test_times,\n",
    "    'test_unique_ids': test_uids,\n",
    "}\n",
    "\n",
    "with open('processed_data_pytorch2.pkl', 'wb') as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "with open('label_encoders2.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "with open('params2.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'max_seq_length': max_seq_length,\n",
    "        'numerical_features': numerical_features,\n",
    "        'embedding_features': embedding_features\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d02f35-7b16-4cbb-8067-a5a589366734",
   "metadata": {},
   "source": [
    "### LSTM Data Validation For Full Model (Behavioral + Geographical)\n",
    "\n",
    "We validate the LSTM data construction by selecting random users from the processed test set and reconstructing their full padded sequences. For each user, we inspect numerical features, embedding features, targets, masks, timestamps, and unique identifiers to ensure that sequence truncation, right-padding, and masking follow the intended temporal logic. This step confirms that the model inputs are correctly aligned and that padded positions are properly identified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39d6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train_numerical', 'X_train_embedding', 'y_train', 'train_mask', 'X_test_numerical', 'X_test_embedding', 'y_test', 'test_mask', 'class_weight_dict', 'max_seq_length', 'numerical_features', 'embedding_features', 'train_user_ids', 'train_times', 'train_unique_ids', 'test_user_ids', 'test_times', 'test_unique_ids']\n",
      "Numerical Features Columns:\n",
      "['HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS', 'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall', 'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad', 'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App', 'Overall_Usage_App', 'LATITUDE', 'LONGITUDE']\n",
      "\n",
      "Embedding Features Columns:\n",
      "['MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING', 'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING', 'ISP_ID_EMBEDDING', 'CURRENT_AD_ID', 'CITY', 'PROVINCE']\n",
      "Retrieved test data for ANDROID_ID 1369 has been saved to output/retrieved_user_1369_test.csv\n",
      "\n",
      "Sample retrieved data (valid entries):\n",
      "     HOUR_SIN  HOUR_COS  MINUTE_SIN  MINUTE_COS  AD_FREQUENCY  AD_CTR  \\\n",
      "0    0.982963   0.37059    0.066987    0.250000      0.000000     0.0   \n",
      "1    0.982963   0.37059    0.066987    0.250000      0.000000     0.0   \n",
      "2    0.982963   0.37059    0.043227    0.296632      0.000095     0.0   \n",
      "3    0.982963   0.37059    0.043227    0.296632      0.000191     0.0   \n",
      "4    0.982963   0.37059    0.024472    0.345492      0.000286     0.0   \n",
      "..        ...       ...         ...         ...           ...     ...   \n",
      "145  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "146  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "147  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "148  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "149  0.000000   0.00000    0.000000    0.000000      0.000000     0.0   \n",
      "\n",
      "     AD_CTR_Overall        EC   CH  SCTR  ...     TIME  Unique_ID  \\\n",
      "0          0.014339  0.000000  0.0   0.0  ...  1755605      20707   \n",
      "1          0.009804  0.000036  0.0   0.0  ...  1755622      20708   \n",
      "2          0.014941  0.000073  0.0   0.0  ...  1755690      20709   \n",
      "3          0.014545  0.000109  0.0   0.0  ...  1755709      20710   \n",
      "4          0.014007  0.000145  0.0   0.0  ...  1755740      20711   \n",
      "..              ...       ...  ...   ...  ...      ...        ...   \n",
      "145        0.000000  0.000000  0.0   0.0  ...        0          0   \n",
      "146        0.000000  0.000000  0.0   0.0  ...        0          0   \n",
      "147        0.000000  0.000000  0.0   0.0  ...        0          0   \n",
      "148        0.000000  0.000000  0.0   0.0  ...        0          0   \n",
      "149        0.000000  0.000000  0.0   0.0  ...        0          0   \n",
      "\n",
      "     MEDIA_PACKAGE_NAME_EMBEDDING  MODEL_EMBEDDING  BRAND_ID_EMBEDDING  \\\n",
      "0                              46               46                   0   \n",
      "1                              46               46                   0   \n",
      "2                              46               46                   0   \n",
      "3                              46               46                   0   \n",
      "4                              46               46                   0   \n",
      "..                            ...              ...                 ...   \n",
      "145                             0                0                   0   \n",
      "146                             0                0                   0   \n",
      "147                             0                0                   0   \n",
      "148                             0                0                   0   \n",
      "149                             0                0                   0   \n",
      "\n",
      "     OPERATOR_ID_EMBEDDING  ISP_ID_EMBEDDING  CURRENT_AD_ID  CITY  PROVINCE  \n",
      "0                        0                 8              4   167        16  \n",
      "1                        0                 8              3   167        16  \n",
      "2                        0                 8              4   167        16  \n",
      "3                        0                 8              4   167        16  \n",
      "4                        0                 8              4   167        16  \n",
      "..                     ...               ...            ...   ...       ...  \n",
      "145                      0                 0              0     0         0  \n",
      "146                      0                 0              0     0         0  \n",
      "147                      0                 0              0     0         0  \n",
      "148                      0                 0              0     0         0  \n",
      "149                      0                 0              0     0         0  \n",
      "\n",
      "[150 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(\"processed_data_pytorch2.pkl\", \"rb\") as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "processed_data_keys = list(processed_data.keys())\n",
    "print(processed_data_keys)\n",
    "\n",
    "X_test_numerical = processed_data[\"X_test_numerical\"]\n",
    "X_test_embedding = processed_data[\"X_test_embedding\"]\n",
    "y_test = processed_data[\"y_test\"]\n",
    "test_mask = processed_data[\"test_mask\"]\n",
    "test_user_ids = processed_data[\"test_user_ids\"]\n",
    "test_times = processed_data[\"test_times\"]\n",
    "test_unique_ids = processed_data[\"test_unique_ids\"]\n",
    "\n",
    "numerical_features = processed_data[\"numerical_features\"]\n",
    "embedding_features = processed_data[\"embedding_features\"]\n",
    "\n",
    "print(\"Numerical Features Columns:\")\n",
    "print(numerical_features)\n",
    "\n",
    "print(\"\\nEmbedding Features Columns:\")\n",
    "print(embedding_features)\n",
    "\n",
    "target_id = 1369\n",
    "\n",
    "if target_id not in test_user_ids:\n",
    "    raise ValueError(f\"ANDROID_ID {target_id} not found in the processed test data.\")\n",
    "\n",
    "target_index = test_user_ids.index(target_id)\n",
    "\n",
    "retrieved_numerical = np.array(X_test_numerical)[target_index]\n",
    "\n",
    "retrieved_embedding = {\n",
    "    feature: np.array(X_test_embedding[feature])[target_index] for feature in embedding_features\n",
    "}\n",
    "\n",
    "retrieved_y = np.array(y_test)[target_index]\n",
    "retrieved_mask = np.array(test_mask)[target_index]\n",
    "retrieved_times = np.array(test_times)[target_index]\n",
    "retrieved_unique_ids = np.array(test_unique_ids)[target_index]\n",
    "\n",
    "retrieved_data = pd.DataFrame(retrieved_numerical, columns=numerical_features)\n",
    "retrieved_data[\"TARGET\"] = retrieved_y\n",
    "retrieved_data[\"MASK\"] = retrieved_mask\n",
    "retrieved_data[\"TIME\"] = retrieved_times\n",
    "retrieved_data[\"Unique_ID\"] = retrieved_unique_ids\n",
    "\n",
    "for feature in embedding_features:\n",
    "    retrieved_data[feature] = retrieved_embedding[feature]\n",
    "\n",
    "valid_data = retrieved_data[retrieved_data[\"MASK\"] == 1]\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f\"retrieved_user_{target_id}_test.csv\")\n",
    "retrieved_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Retrieved test data for ANDROID_ID {target_id} has been saved to {output_file}\")\n",
    "print(\"\\nSample retrieved data (valid entries):\")\n",
    "print(retrieved_data.head(150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215df962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEDIA_PACKAGE_NAME_EMBEDDING': array([[46, 46, 46, ...,  0,  0,  0],\n",
       "        [12, 12, 46, ...,  0,  0,  0],\n",
       "        [46, 46,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [ 3,  3,  3, ...,  0,  0,  0]]),\n",
       " 'MODEL_EMBEDDING': array([[27, 27, 27, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [ 2,  2,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [46, 46, 46, ...,  0,  0,  0],\n",
       "        [11, 11, 11, ...,  0,  0,  0],\n",
       "        [46, 46, 46, ...,  0,  0,  0]]),\n",
       " 'BRAND_ID_EMBEDDING': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 2, 2, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'OPERATOR_ID_EMBEDDING': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [2, 2, 2, ..., 0, 0, 0]]),\n",
       " 'ISP_ID_EMBEDDING': array([[7, 8, 8, ..., 0, 0, 0],\n",
       "        [7, 7, 0, ..., 0, 0, 0],\n",
       "        [8, 8, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        [4, 8, 8, ..., 0, 0, 0]]),\n",
       " 'CURRENT_AD_ID': array([[4, 4, 4, ..., 0, 0, 0],\n",
       "        [9, 1, 5, ..., 0, 0, 0],\n",
       "        [1, 6, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [8, 1, 2, ..., 0, 0, 0],\n",
       "        [4, 4, 3, ..., 0, 0, 0],\n",
       "        [5, 4, 0, ..., 0, 0, 0]]),\n",
       " 'CITY': array([[  1,   1,   1, ...,   0,   0,   0],\n",
       "        [  6,   6,   6, ...,   0,   0,   0],\n",
       "        [  8,   8,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  1,   1,   1, ...,   0,   0,   0],\n",
       "        [  9,   9,   9, ...,   0,   0,   0],\n",
       "        [209, 209, 209, ...,   0,   0,   0]]),\n",
       " 'PROVINCE': array([[ 5,  5,  5, ...,  0,  0,  0],\n",
       "        [ 8,  8,  8, ...,  0,  0,  0],\n",
       "        [ 9,  9,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [10, 10, 10, ...,  0,  0,  0],\n",
       "        [10, 10, 10, ...,  0,  0,  0],\n",
       "        [25, 25, 25, ...,  0,  0,  0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('processed_data_pytorch2.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "processed_data['X_test_embedding']  \n",
    "processed_data['X_test_embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765e106-a68c-4255-b2ed-54cb5c90bd46",
   "metadata": {},
   "source": [
    "# Full LSTM–Attention Sequence Model for Reward Function Estimation (Click Prediction)\n",
    "\n",
    "This script implements and trains a deep sequential model for user-level click prediction. The model operates at the impression sequence level, producing a click probability for each timestep while respecting temporal order and padding structure.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "The architecture is designed to model sequential behavioral dynamics while preventing information leakage from future impressions.\n",
    "\n",
    "At each timestep, the input representation is constructed by concatenating:\n",
    "\n",
    "1. Numerical behavioral features.\n",
    "2. Learned embeddings for categorical features.\n",
    "\n",
    "Each categorical feature is mapped to an embedding space using `nn.Embedding` with `padding_idx=0`, ensuring padded tokens do not introduce learned signal.\n",
    "\n",
    "The combined feature vector is then enriched with:\n",
    "\n",
    "- A learned absolute positional embedding, allowing the model to distinguish sequence positions.\n",
    "- An optional projected time-gap embedding (`log(1 + Δt)`), which encodes temporal spacing between consecutive impressions.\n",
    "\n",
    "The sequential backbone consists of a multi-layer LSTM. This component captures temporal dependencies in user behavior and produces hidden representations for every timestep.\n",
    "\n",
    "On top of the LSTM outputs, a **causal multi-head self-attention layer** is applied. Two masking mechanisms are used:\n",
    "\n",
    "- A **causal mask** (upper triangular) blocks access to future timesteps, ensuring predictions at time \\( t \\) depend only on information from \\( \\leq t \\).\n",
    "- A **key padding mask** ignores padded positions introduced during sequence padding.\n",
    "\n",
    "The attention output is combined with a residual connection and layer normalization.\n",
    "\n",
    "The final representation passes through a gated projection head:\n",
    "- A sigmoid gate controls information flow.\n",
    "- A tanh-transformed body provides nonlinear transformation.\n",
    "- Dropout regularizes the gated output.\n",
    "\n",
    "A final linear layer produces one logit per timestep. During training and evaluation, logits are converted to probabilities using the sigmoid function.\n",
    "\n",
    "## Data Handling and Masking\n",
    "\n",
    "Sequences are padded to a fixed maximum length. A binary mask identifies valid (non-padded) positions.  \n",
    "\n",
    "Loss and metrics are computed only on positions where `mask == 1`, ensuring padded timesteps do not affect training or evaluation.\n",
    "\n",
    "## Training Procedure\n",
    "\n",
    "The model is trained using:\n",
    "\n",
    "- **BCEWithLogitsLoss**\n",
    "- **AdamW optimizer**\n",
    "- Gradient clipping (max norm = 1.0)\n",
    "- Learning rate scheduling via `ReduceLROnPlateau` (monitored on validation AUC)\n",
    "\n",
    "Each epoch computes:\n",
    "\n",
    "- Loss\n",
    "- AUC\n",
    "- Average Precision\n",
    "- Gini coefficient\n",
    "- Accuracy, Precision, Recall, and F1 (threshold = 0.5)\n",
    "- Confusion matrices\n",
    "- Relative Information Gain (RIG)\n",
    "\n",
    "Validation predictions are stored with associated `Unique_ID` and `Ad_ID` for downstream analysis.\n",
    "\n",
    "Model checkpoints and performance plots are saved after every epoch.\n",
    "\n",
    "### Summary\n",
    "\n",
    "This implementation combines LSTM-based sequential modeling with causal self-attention and strict masking, ensuring temporally valid click prediction at the impression level while handling padded sequences correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde838b6-f4cf-442d-8393-204269d61a54",
   "metadata": {},
   "source": [
    "## Train LSTM with Attention for Full Model (Behavioral + Geographical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d842365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.16it/s]\n",
      "Epoch 1/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_1.csv\n",
      "\n",
      "Epoch [1/50]\n",
      "Train Loss: 0.0177, Train AUC: 0.5968, Train AP: 0.0248, Train Gini: 0.1936\n",
      "Train Acc: 0.9819, Train Precision: 0.0182, Train Recall: 0.0004, Train F1: 0.0008\n",
      "Val Loss: 0.0174, Val AUC: 0.6419, Val AP: 0.0306, Val Gini: 0.2839, Mean Y Predicted: 0.0128\n",
      "Val Acc: 0.9824, Val Precision: 0.0000, Val Recall: 0.0000, Val F1: 0.0000\n",
      "Train Confusion Matrix:\n",
      "[[4779529    2001]\n",
      " [  86340      37]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106744       0]\n",
      " [  55632       0]]\n",
      "Metrics plots saved to plots2/epoch_1_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.22it/s]\n",
      "Epoch 2/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_2.csv\n",
      "\n",
      "Epoch [2/50]\n",
      "Train Loss: 0.0165, Train AUC: 0.6960, Train AP: 0.1265, Train Gini: 0.3920\n",
      "Train Acc: 0.9825, Train Precision: 0.7044, Train Recall: 0.0259, Train F1: 0.0500\n",
      "Val Loss: 0.0157, Val AUC: 0.7721, Val AP: 0.1922, Val Gini: 0.5442, Mean Y Predicted: 0.0218\n",
      "Val Acc: 0.9830, Val Precision: 0.7420, Val Recall: 0.0505, Val F1: 0.0946\n",
      "Train Confusion Matrix:\n",
      "[[4780591     939]\n",
      " [  84139    2238]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105767     977]\n",
      " [  52822    2810]]\n",
      "Metrics plots saved to plots2/epoch_2_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.18it/s]\n",
      "Epoch 3/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_3.csv\n",
      "\n",
      "Epoch [3/50]\n",
      "Train Loss: 0.0157, Train AUC: 0.7590, Train AP: 0.2003, Train Gini: 0.5181\n",
      "Train Acc: 0.9829, Train Precision: 0.6790, Train Recall: 0.0706, Train F1: 0.1279\n",
      "Val Loss: 0.0155, Val AUC: 0.7820, Val AP: 0.2104, Val Gini: 0.5640, Mean Y Predicted: 0.0179\n",
      "Val Acc: 0.9830, Val Precision: 0.7415, Val Recall: 0.0553, Val F1: 0.1029\n",
      "Train Confusion Matrix:\n",
      "[[4778647    2883]\n",
      " [  80278    6099]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105672    1072]\n",
      " [  52557    3075]]\n",
      "Metrics plots saved to plots2/epoch_3_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|██████████| 1164/1164 [02:43<00:00,  7.10it/s]\n",
      "Epoch 4/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_4.csv\n",
      "\n",
      "Epoch [4/50]\n",
      "Train Loss: 0.0156, Train AUC: 0.7633, Train AP: 0.2086, Train Gini: 0.5266\n",
      "Train Acc: 0.9830, Train Precision: 0.6669, Train Recall: 0.0839, Train F1: 0.1491\n",
      "Val Loss: 0.0153, Val AUC: 0.7829, Val AP: 0.2211, Val Gini: 0.5658, Mean Y Predicted: 0.0149\n",
      "Val Acc: 0.9832, Val Precision: 0.6581, Val Recall: 0.0972, Val F1: 0.1694\n",
      "Train Confusion Matrix:\n",
      "[[4777908    3622]\n",
      " [  79126    7251]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103934    2810]\n",
      " [  50224    5408]]\n",
      "Metrics plots saved to plots2/epoch_4_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.17it/s]\n",
      "Epoch 5/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_5.csv\n",
      "\n",
      "Epoch [5/50]\n",
      "Train Loss: 0.0154, Train AUC: 0.7745, Train AP: 0.2222, Train Gini: 0.5491\n",
      "Train Acc: 0.9831, Train Precision: 0.6465, Train Recall: 0.1102, Train F1: 0.1883\n",
      "Val Loss: 0.0153, Val AUC: 0.7850, Val AP: 0.2279, Val Gini: 0.5700, Mean Y Predicted: 0.0178\n",
      "Val Acc: 0.9833, Val Precision: 0.6181, Val Recall: 0.1388, Val F1: 0.2267\n",
      "Train Confusion Matrix:\n",
      "[[4776324    5206]\n",
      " [  76857    9520]]\n",
      "Validation Confusion Matrix:\n",
      "[[3101973    4771]\n",
      " [  47909    7723]]\n",
      "Metrics plots saved to plots2/epoch_5_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.21it/s]\n",
      "Epoch 6/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_6.csv\n",
      "\n",
      "Epoch [6/50]\n",
      "Train Loss: 0.0153, Train AUC: 0.7783, Train AP: 0.2304, Train Gini: 0.5566\n",
      "Train Acc: 0.9833, Train Precision: 0.6563, Train Recall: 0.1194, Train F1: 0.2020\n",
      "Val Loss: 0.0151, Val AUC: 0.7869, Val AP: 0.2438, Val Gini: 0.5739, Mean Y Predicted: 0.0124\n",
      "Val Acc: 0.9837, Val Precision: 0.7755, Val Recall: 0.0998, Val F1: 0.1768\n",
      "Train Confusion Matrix:\n",
      "[[4776130    5400]\n",
      " [  76067   10310]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105137    1607]\n",
      " [  50080    5552]]\n",
      "Metrics plots saved to plots2/epoch_6_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.19it/s]\n",
      "Epoch 7/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_7.csv\n",
      "\n",
      "Epoch [7/50]\n",
      "Train Loss: 0.0150, Train AUC: 0.7780, Train AP: 0.2498, Train Gini: 0.5560\n",
      "Train Acc: 0.9837, Train Precision: 0.7542, Train Recall: 0.1178, Train F1: 0.2038\n",
      "Val Loss: 0.0149, Val AUC: 0.7870, Val AP: 0.2583, Val Gini: 0.5741, Mean Y Predicted: 0.0137\n",
      "Val Acc: 0.9839, Val Precision: 0.7457, Val Recall: 0.1293, Val F1: 0.2204\n",
      "Train Confusion Matrix:\n",
      "[[4778214    3316]\n",
      " [  76202   10175]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104292    2452]\n",
      " [  48440    7192]]\n",
      "Metrics plots saved to plots2/epoch_7_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Training: 100%|██████████| 1164/1164 [02:40<00:00,  7.24it/s]\n",
      "Epoch 8/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_8.csv\n",
      "\n",
      "Epoch [8/50]\n",
      "Train Loss: 0.0147, Train AUC: 0.7882, Train AP: 0.2709, Train Gini: 0.5763\n",
      "Train Acc: 0.9840, Train Precision: 0.7704, Train Recall: 0.1387, Train F1: 0.2351\n",
      "Val Loss: 0.0146, Val AUC: 0.7916, Val AP: 0.2774, Val Gini: 0.5831, Mean Y Predicted: 0.0182\n",
      "Val Acc: 0.9842, Val Precision: 0.8054, Val Recall: 0.1331, Val F1: 0.2284\n",
      "Train Confusion Matrix:\n",
      "[[4777959    3571]\n",
      " [  74394   11983]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104956    1788]\n",
      " [  48230    7402]]\n",
      "Metrics plots saved to plots2/epoch_8_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.16it/s]\n",
      "Epoch 9/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_9.csv\n",
      "\n",
      "Epoch [9/50]\n",
      "Train Loss: 0.0146, Train AUC: 0.7912, Train AP: 0.2815, Train Gini: 0.5824\n",
      "Train Acc: 0.9842, Train Precision: 0.7840, Train Recall: 0.1529, Train F1: 0.2558\n",
      "Val Loss: 0.0145, Val AUC: 0.7969, Val AP: 0.2856, Val Gini: 0.5938, Mean Y Predicted: 0.0171\n",
      "Val Acc: 0.9843, Val Precision: 0.8610, Val Recall: 0.1270, Val F1: 0.2213\n",
      "Train Confusion Matrix:\n",
      "[[4777892    3638]\n",
      " [  73173   13204]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105603    1141]\n",
      " [  48567    7065]]\n",
      "Metrics plots saved to plots2/epoch_9_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.20it/s]\n",
      "Epoch 10/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_10.csv\n",
      "\n",
      "Epoch [10/50]\n",
      "Train Loss: 0.0144, Train AUC: 0.7933, Train AP: 0.2932, Train Gini: 0.5866\n",
      "Train Acc: 0.9845, Train Precision: 0.7964, Train Recall: 0.1663, Train F1: 0.2751\n",
      "Val Loss: 0.0143, Val AUC: 0.7961, Val AP: 0.2972, Val Gini: 0.5921, Mean Y Predicted: 0.0154\n",
      "Val Acc: 0.9845, Val Precision: 0.8638, Val Recall: 0.1435, Val F1: 0.2461\n",
      "Train Confusion Matrix:\n",
      "[[4777858    3672]\n",
      " [  72015   14362]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105486    1258]\n",
      " [  47651    7981]]\n",
      "Metrics plots saved to plots2/epoch_10_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.19it/s]\n",
      "Epoch 11/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_11.csv\n",
      "\n",
      "Epoch [11/50]\n",
      "Train Loss: 0.0143, Train AUC: 0.7929, Train AP: 0.3017, Train Gini: 0.5858\n",
      "Train Acc: 0.9846, Train Precision: 0.8142, Train Recall: 0.1740, Train F1: 0.2867\n",
      "Val Loss: 0.0143, Val AUC: 0.7989, Val AP: 0.3016, Val Gini: 0.5978, Mean Y Predicted: 0.0137\n",
      "Val Acc: 0.9847, Val Precision: 0.8293, Val Recall: 0.1618, Val F1: 0.2708\n",
      "Train Confusion Matrix:\n",
      "[[4778101    3429]\n",
      " [  71349   15028]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104890    1854]\n",
      " [  46628    9004]]\n",
      "Metrics plots saved to plots2/epoch_11_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.19it/s]\n",
      "Epoch 12/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_12.csv\n",
      "\n",
      "Epoch [12/50]\n",
      "Train Loss: 0.0141, Train AUC: 0.7961, Train AP: 0.3121, Train Gini: 0.5921\n",
      "Train Acc: 0.9848, Train Precision: 0.8208, Train Recall: 0.1867, Train F1: 0.3043\n",
      "Val Loss: 0.0141, Val AUC: 0.8004, Val AP: 0.3089, Val Gini: 0.6007, Mean Y Predicted: 0.0150\n",
      "Val Acc: 0.9849, Val Precision: 0.8088, Val Recall: 0.1824, Val F1: 0.2977\n",
      "Train Confusion Matrix:\n",
      "[[4778008    3522]\n",
      " [  70247   16130]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104344    2400]\n",
      " [  45482   10150]]\n",
      "Metrics plots saved to plots2/epoch_12_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.18it/s]\n",
      "Epoch 13/50 - Validation: 100%|██████████| 554/554 [00:42<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_13.csv\n",
      "\n",
      "Epoch [13/50]\n",
      "Train Loss: 0.0139, Train AUC: 0.7972, Train AP: 0.3207, Train Gini: 0.5945\n",
      "Train Acc: 0.9850, Train Precision: 0.8356, Train Recall: 0.1954, Train F1: 0.3168\n",
      "Val Loss: 0.0140, Val AUC: 0.8008, Val AP: 0.3119, Val Gini: 0.6017, Mean Y Predicted: 0.0164\n",
      "Val Acc: 0.9849, Val Precision: 0.7921, Val Recall: 0.1928, Val F1: 0.3101\n",
      "Train Confusion Matrix:\n",
      "[[4778209    3321]\n",
      " [  69496   16881]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103929    2815]\n",
      " [  44907   10725]]\n",
      "Metrics plots saved to plots2/epoch_13_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.15it/s]\n",
      "Epoch 14/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_14.csv\n",
      "\n",
      "Epoch [14/50]\n",
      "Train Loss: 0.0138, Train AUC: 0.7995, Train AP: 0.3286, Train Gini: 0.5989\n",
      "Train Acc: 0.9852, Train Precision: 0.8361, Train Recall: 0.2085, Train F1: 0.3337\n",
      "Val Loss: 0.0138, Val AUC: 0.8017, Val AP: 0.3229, Val Gini: 0.6033, Mean Y Predicted: 0.0173\n",
      "Val Acc: 0.9852, Val Precision: 0.8329, Val Recall: 0.1956, Val F1: 0.3168\n",
      "Train Confusion Matrix:\n",
      "[[4778000    3530]\n",
      " [  68370   18007]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104561    2183]\n",
      " [  44750   10882]]\n",
      "Metrics plots saved to plots2/epoch_14_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.16it/s]\n",
      "Epoch 15/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_15.csv\n",
      "\n",
      "Epoch [15/50]\n",
      "Train Loss: 0.0137, Train AUC: 0.8006, Train AP: 0.3344, Train Gini: 0.6012\n",
      "Train Acc: 0.9854, Train Precision: 0.8477, Train Recall: 0.2152, Train F1: 0.3433\n",
      "Val Loss: 0.0140, Val AUC: 0.8032, Val AP: 0.3191, Val Gini: 0.6065, Mean Y Predicted: 0.0222\n",
      "Val Acc: 0.9851, Val Precision: 0.7656, Val Recall: 0.2167, Val F1: 0.3377\n",
      "Train Confusion Matrix:\n",
      "[[4778191    3339]\n",
      " [  67787   18590]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103053    3691]\n",
      " [  43579   12053]]\n",
      "Metrics plots saved to plots2/epoch_15_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.16it/s]\n",
      "Epoch 16/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_16.csv\n",
      "\n",
      "Epoch [16/50]\n",
      "Train Loss: 0.0136, Train AUC: 0.8010, Train AP: 0.3400, Train Gini: 0.6020\n",
      "Train Acc: 0.9856, Train Precision: 0.8615, Train Recall: 0.2216, Train F1: 0.3526\n",
      "Val Loss: 0.0138, Val AUC: 0.8043, Val AP: 0.3279, Val Gini: 0.6085, Mean Y Predicted: 0.0141\n",
      "Val Acc: 0.9852, Val Precision: 0.7859, Val Recall: 0.2188, Val F1: 0.3423\n",
      "Train Confusion Matrix:\n",
      "[[4778452    3078]\n",
      " [  67233   19144]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103428    3316]\n",
      " [  43460   12172]]\n",
      "Metrics plots saved to plots2/epoch_16_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Training: 100%|██████████| 1164/1164 [02:41<00:00,  7.19it/s]\n",
      "Epoch 17/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_17.csv\n",
      "\n",
      "Epoch [17/50]\n",
      "Train Loss: 0.0135, Train AUC: 0.8028, Train AP: 0.3451, Train Gini: 0.6056\n",
      "Train Acc: 0.9857, Train Precision: 0.8683, Train Recall: 0.2278, Train F1: 0.3609\n",
      "Val Loss: 0.0137, Val AUC: 0.8059, Val AP: 0.3300, Val Gini: 0.6118, Mean Y Predicted: 0.0155\n",
      "Val Acc: 0.9854, Val Precision: 0.8556, Val Recall: 0.2014, Val F1: 0.3260\n",
      "Train Confusion Matrix:\n",
      "[[4778547    2983]\n",
      " [  66704   19673]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104853    1891]\n",
      " [  44428   11204]]\n",
      "Metrics plots saved to plots2/epoch_17_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.18it/s]\n",
      "Epoch 18/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_18.csv\n",
      "\n",
      "Epoch [18/50]\n",
      "Train Loss: 0.0134, Train AUC: 0.8057, Train AP: 0.3496, Train Gini: 0.6114\n",
      "Train Acc: 0.9858, Train Precision: 0.8757, Train Recall: 0.2331, Train F1: 0.3682\n",
      "Val Loss: 0.0137, Val AUC: 0.8072, Val AP: 0.3328, Val Gini: 0.6143, Mean Y Predicted: 0.0176\n",
      "Val Acc: 0.9854, Val Precision: 0.8430, Val Recall: 0.2080, Val F1: 0.3337\n",
      "Train Confusion Matrix:\n",
      "[[4778671    2859]\n",
      " [  66244   20133]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104588    2156]\n",
      " [  44059   11573]]\n",
      "Metrics plots saved to plots2/epoch_18_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.14it/s]\n",
      "Epoch 19/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_19.csv\n",
      "\n",
      "Epoch [19/50]\n",
      "Train Loss: 0.0133, Train AUC: 0.8053, Train AP: 0.3558, Train Gini: 0.6105\n",
      "Train Acc: 0.9859, Train Precision: 0.8843, Train Recall: 0.2392, Train F1: 0.3765\n",
      "Val Loss: 0.0138, Val AUC: 0.8082, Val AP: 0.3319, Val Gini: 0.6165, Mean Y Predicted: 0.0175\n",
      "Val Acc: 0.9852, Val Precision: 0.7580, Val Recall: 0.2346, Val F1: 0.3583\n",
      "Train Confusion Matrix:\n",
      "[[4778827    2703]\n",
      " [  65718   20659]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102578    4166]\n",
      " [  42580   13052]]\n",
      "Metrics plots saved to plots2/epoch_19_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.15it/s]\n",
      "Epoch 20/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_20.csv\n",
      "\n",
      "Epoch [20/50]\n",
      "Train Loss: 0.0132, Train AUC: 0.8069, Train AP: 0.3573, Train Gini: 0.6138\n",
      "Train Acc: 0.9860, Train Precision: 0.8847, Train Recall: 0.2451, Train F1: 0.3839\n",
      "Val Loss: 0.0138, Val AUC: 0.8090, Val AP: 0.3341, Val Gini: 0.6181, Mean Y Predicted: 0.0212\n",
      "Val Acc: 0.9852, Val Precision: 0.7539, Val Recall: 0.2392, Val F1: 0.3631\n",
      "Train Confusion Matrix:\n",
      "[[4778771    2759]\n",
      " [  65205   21172]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102401    4343]\n",
      " [  42327   13305]]\n",
      "Metrics plots saved to plots2/epoch_20_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.18it/s]\n",
      "Epoch 21/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_21.csv\n",
      "\n",
      "Epoch [21/50]\n",
      "Train Loss: 0.0131, Train AUC: 0.8100, Train AP: 0.3630, Train Gini: 0.6200\n",
      "Train Acc: 0.9862, Train Precision: 0.8925, Train Recall: 0.2499, Train F1: 0.3905\n",
      "Val Loss: 0.0137, Val AUC: 0.8094, Val AP: 0.3317, Val Gini: 0.6188, Mean Y Predicted: 0.0157\n",
      "Val Acc: 0.9854, Val Precision: 0.8405, Val Recall: 0.2075, Val F1: 0.3328\n",
      "Train Confusion Matrix:\n",
      "[[4778930    2600]\n",
      " [  64792   21585]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104553    2191]\n",
      " [  44090   11542]]\n",
      "Metrics plots saved to plots2/epoch_21_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.17it/s]\n",
      "Epoch 22/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_22.csv\n",
      "\n",
      "Epoch [22/50]\n",
      "Train Loss: 0.0131, Train AUC: 0.8099, Train AP: 0.3654, Train Gini: 0.6198\n",
      "Train Acc: 0.9862, Train Precision: 0.8943, Train Recall: 0.2551, Train F1: 0.3970\n",
      "Val Loss: 0.0137, Val AUC: 0.8113, Val AP: 0.3373, Val Gini: 0.6226, Mean Y Predicted: 0.0168\n",
      "Val Acc: 0.9854, Val Precision: 0.8631, Val Recall: 0.2048, Val F1: 0.3311\n",
      "Train Confusion Matrix:\n",
      "[[4778926    2604]\n",
      " [  64341   22036]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104937    1807]\n",
      " [  44237   11395]]\n",
      "Metrics plots saved to plots2/epoch_22_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Training: 100%|██████████| 1164/1164 [02:42<00:00,  7.15it/s]\n",
      "Epoch 23/50 - Validation: 100%|██████████| 554/554 [00:41<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_23.csv\n",
      "\n",
      "Epoch [23/50]\n",
      "Train Loss: 0.0130, Train AUC: 0.8112, Train AP: 0.3693, Train Gini: 0.6225\n",
      "Train Acc: 0.9863, Train Precision: 0.8962, Train Recall: 0.2609, Train F1: 0.4041\n",
      "Val Loss: 0.0137, Val AUC: 0.8115, Val AP: 0.3359, Val Gini: 0.6230, Mean Y Predicted: 0.0191\n",
      "Val Acc: 0.9854, Val Precision: 0.8194, Val Recall: 0.2198, Val F1: 0.3467\n",
      "Train Confusion Matrix:\n",
      "[[4778919    2611]\n",
      " [  63844   22533]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104048    2696]\n",
      " [  43402   12230]]\n",
      "Metrics plots saved to plots2/epoch_23_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Training: 100%|██████████| 1164/1164 [02:36<00:00,  7.42it/s]\n",
      "Epoch 24/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_24.csv\n",
      "\n",
      "Epoch [24/50]\n",
      "Train Loss: 0.0129, Train AUC: 0.8127, Train AP: 0.3720, Train Gini: 0.6255\n",
      "Train Acc: 0.9864, Train Precision: 0.9016, Train Recall: 0.2647, Train F1: 0.4093\n",
      "Val Loss: 0.0138, Val AUC: 0.8108, Val AP: 0.3329, Val Gini: 0.6217, Mean Y Predicted: 0.0156\n",
      "Val Acc: 0.9854, Val Precision: 0.8193, Val Recall: 0.2148, Val F1: 0.3404\n",
      "Train Confusion Matrix:\n",
      "[[4779034    2496]\n",
      " [  63512   22865]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104109    2635]\n",
      " [  43681   11951]]\n",
      "Metrics plots saved to plots2/epoch_24_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Training: 100%|██████████| 1164/1164 [02:28<00:00,  7.85it/s]\n",
      "Epoch 25/50 - Validation: 100%|██████████| 554/554 [00:38<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_25.csv\n",
      "\n",
      "Epoch [25/50]\n",
      "Train Loss: 0.0129, Train AUC: 0.8117, Train AP: 0.3705, Train Gini: 0.6234\n",
      "Train Acc: 0.9864, Train Precision: 0.8998, Train Recall: 0.2655, Train F1: 0.4100\n",
      "Val Loss: 0.0138, Val AUC: 0.8109, Val AP: 0.3332, Val Gini: 0.6219, Mean Y Predicted: 0.0153\n",
      "Val Acc: 0.9854, Val Precision: 0.8189, Val Recall: 0.2156, Val F1: 0.3413\n",
      "Train Confusion Matrix:\n",
      "[[4778977    2553]\n",
      " [  63447   22930]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104092    2652]\n",
      " [  43638   11994]]\n",
      "Metrics plots saved to plots2/epoch_25_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Training: 100%|██████████| 1164/1164 [02:28<00:00,  7.86it/s]\n",
      "Epoch 26/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_26.csv\n",
      "\n",
      "Epoch [26/50]\n",
      "Train Loss: 0.0128, Train AUC: 0.8138, Train AP: 0.3774, Train Gini: 0.6276\n",
      "Train Acc: 0.9866, Train Precision: 0.9109, Train Recall: 0.2724, Train F1: 0.4194\n",
      "Val Loss: 0.0138, Val AUC: 0.8126, Val AP: 0.3322, Val Gini: 0.6253, Mean Y Predicted: 0.0187\n",
      "Val Acc: 0.9852, Val Precision: 0.7704, Val Recall: 0.2268, Val F1: 0.3505\n",
      "Train Confusion Matrix:\n",
      "[[4779227    2303]\n",
      " [  62847   23530]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102983    3761]\n",
      " [  43013   12619]]\n",
      "Metrics plots saved to plots2/epoch_26_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Training: 100%|██████████| 1164/1164 [02:28<00:00,  7.82it/s]\n",
      "Epoch 27/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_27.csv\n",
      "\n",
      "Epoch [27/50]\n",
      "Train Loss: 0.0128, Train AUC: 0.8142, Train AP: 0.3790, Train Gini: 0.6284\n",
      "Train Acc: 0.9867, Train Precision: 0.9143, Train Recall: 0.2754, Train F1: 0.4233\n",
      "Val Loss: 0.0139, Val AUC: 0.8112, Val AP: 0.3312, Val Gini: 0.6224, Mean Y Predicted: 0.0186\n",
      "Val Acc: 0.9853, Val Precision: 0.7866, Val Recall: 0.2235, Val F1: 0.3481\n",
      "Train Confusion Matrix:\n",
      "[[4779301    2229]\n",
      " [  62589   23788]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103371    3373]\n",
      " [  43200   12432]]\n",
      "Metrics plots saved to plots2/epoch_27_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Training: 100%|██████████| 1164/1164 [02:28<00:00,  7.85it/s]\n",
      "Epoch 28/50 - Validation: 100%|██████████| 554/554 [00:38<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_28.csv\n",
      "\n",
      "Epoch [28/50]\n",
      "Train Loss: 0.0127, Train AUC: 0.8138, Train AP: 0.3809, Train Gini: 0.6276\n",
      "Train Acc: 0.9867, Train Precision: 0.9141, Train Recall: 0.2784, Train F1: 0.4268\n",
      "Val Loss: 0.0138, Val AUC: 0.8113, Val AP: 0.3320, Val Gini: 0.6226, Mean Y Predicted: 0.0195\n",
      "Val Acc: 0.9854, Val Precision: 0.8230, Val Recall: 0.2155, Val F1: 0.3416\n",
      "Train Confusion Matrix:\n",
      "[[4779271    2259]\n",
      " [  62329   24048]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104166    2578]\n",
      " [  43642   11990]]\n",
      "Metrics plots saved to plots2/epoch_28_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Training: 100%|██████████| 1164/1164 [02:27<00:00,  7.88it/s]\n",
      "Epoch 29/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_29.csv\n",
      "\n",
      "Epoch [29/50]\n",
      "Train Loss: 0.0126, Train AUC: 0.8149, Train AP: 0.3853, Train Gini: 0.6299\n",
      "Train Acc: 0.9869, Train Precision: 0.9247, Train Recall: 0.2840, Train F1: 0.4346\n",
      "Val Loss: 0.0138, Val AUC: 0.8115, Val AP: 0.3296, Val Gini: 0.6231, Mean Y Predicted: 0.0184\n",
      "Val Acc: 0.9853, Val Precision: 0.7887, Val Recall: 0.2230, Val F1: 0.3477\n",
      "Train Confusion Matrix:\n",
      "[[4779531    1999]\n",
      " [  61843   24534]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103421    3323]\n",
      " [  43226   12406]]\n",
      "Metrics plots saved to plots2/epoch_29_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Training: 100%|██████████| 1164/1164 [02:29<00:00,  7.80it/s]\n",
      "Epoch 30/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_30.csv\n",
      "\n",
      "Epoch [30/50]\n",
      "Train Loss: 0.0126, Train AUC: 0.8160, Train AP: 0.3866, Train Gini: 0.6320\n",
      "Train Acc: 0.9869, Train Precision: 0.9243, Train Recall: 0.2852, Train F1: 0.4359\n",
      "Val Loss: 0.0139, Val AUC: 0.8119, Val AP: 0.3270, Val Gini: 0.6237, Mean Y Predicted: 0.0130\n",
      "Val Acc: 0.9852, Val Precision: 0.7883, Val Recall: 0.2197, Val F1: 0.3436\n",
      "Train Confusion Matrix:\n",
      "[[4779513    2017]\n",
      " [  61743   24634]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103462    3282]\n",
      " [  43410   12222]]\n",
      "Metrics plots saved to plots2/epoch_30_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Training: 100%|██████████| 1164/1164 [02:31<00:00,  7.67it/s]\n",
      "Epoch 31/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_31.csv\n",
      "\n",
      "Epoch [31/50]\n",
      "Train Loss: 0.0125, Train AUC: 0.8146, Train AP: 0.3877, Train Gini: 0.6292\n",
      "Train Acc: 0.9870, Train Precision: 0.9251, Train Recall: 0.2888, Train F1: 0.4402\n",
      "Val Loss: 0.0140, Val AUC: 0.8123, Val AP: 0.3257, Val Gini: 0.6247, Mean Y Predicted: 0.0153\n",
      "Val Acc: 0.9852, Val Precision: 0.7702, Val Recall: 0.2243, Val F1: 0.3474\n",
      "Train Confusion Matrix:\n",
      "[[4779510    2020]\n",
      " [  61433   24944]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103021    3723]\n",
      " [  43156   12476]]\n",
      "Metrics plots saved to plots2/epoch_31_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Training: 100%|██████████| 1164/1164 [02:32<00:00,  7.64it/s]\n",
      "Epoch 32/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_32.csv\n",
      "\n",
      "Epoch [32/50]\n",
      "Train Loss: 0.0125, Train AUC: 0.8162, Train AP: 0.3897, Train Gini: 0.6324\n",
      "Train Acc: 0.9870, Train Precision: 0.9252, Train Recall: 0.2925, Train F1: 0.4444\n",
      "Val Loss: 0.0139, Val AUC: 0.8124, Val AP: 0.3233, Val Gini: 0.6248, Mean Y Predicted: 0.0166\n",
      "Val Acc: 0.9852, Val Precision: 0.8070, Val Recall: 0.2106, Val F1: 0.3340\n",
      "Train Confusion Matrix:\n",
      "[[4779487    2043]\n",
      " [  61115   25262]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103941    2803]\n",
      " [  43915   11717]]\n",
      "Metrics plots saved to plots2/epoch_32_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Training: 100%|██████████| 1164/1164 [02:31<00:00,  7.70it/s]\n",
      "Epoch 33/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_33.csv\n",
      "\n",
      "Epoch [33/50]\n",
      "Train Loss: 0.0125, Train AUC: 0.8168, Train AP: 0.3904, Train Gini: 0.6336\n",
      "Train Acc: 0.9870, Train Precision: 0.9279, Train Recall: 0.2921, Train F1: 0.4444\n",
      "Val Loss: 0.0142, Val AUC: 0.8119, Val AP: 0.3201, Val Gini: 0.6239, Mean Y Predicted: 0.0154\n",
      "Val Acc: 0.9850, Val Precision: 0.7376, Val Recall: 0.2248, Val F1: 0.3446\n",
      "Train Confusion Matrix:\n",
      "[[4779570    1960]\n",
      " [  61142   25235]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102296    4448]\n",
      " [  43127   12505]]\n",
      "Metrics plots saved to plots2/epoch_33_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Training: 100%|██████████| 1164/1164 [02:32<00:00,  7.64it/s]\n",
      "Epoch 34/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_34.csv\n",
      "\n",
      "Epoch [34/50]\n",
      "Train Loss: 0.0124, Train AUC: 0.8173, Train AP: 0.3935, Train Gini: 0.6346\n",
      "Train Acc: 0.9871, Train Precision: 0.9291, Train Recall: 0.2979, Train F1: 0.4511\n",
      "Val Loss: 0.0141, Val AUC: 0.8106, Val AP: 0.3226, Val Gini: 0.6212, Mean Y Predicted: 0.0184\n",
      "Val Acc: 0.9850, Val Precision: 0.7430, Val Recall: 0.2295, Val F1: 0.3507\n",
      "Train Confusion Matrix:\n",
      "[[4779566    1964]\n",
      " [  60647   25730]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102329    4415]\n",
      " [  42866   12766]]\n",
      "Metrics plots saved to plots2/epoch_34_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Training: 100%|██████████| 1164/1164 [02:32<00:00,  7.65it/s]\n",
      "Epoch 35/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_35.csv\n",
      "\n",
      "Epoch [35/50]\n",
      "Train Loss: 0.0124, Train AUC: 0.8171, Train AP: 0.3947, Train Gini: 0.6343\n",
      "Train Acc: 0.9872, Train Precision: 0.9317, Train Recall: 0.2990, Train F1: 0.4527\n",
      "Val Loss: 0.0141, Val AUC: 0.8094, Val AP: 0.3131, Val Gini: 0.6189, Mean Y Predicted: 0.0144\n",
      "Val Acc: 0.9851, Val Precision: 0.8119, Val Recall: 0.2021, Val F1: 0.3237\n",
      "Train Confusion Matrix:\n",
      "[[4779638    1892]\n",
      " [  60550   25827]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104139    2605]\n",
      " [  44388   11244]]\n",
      "Metrics plots saved to plots2/epoch_35_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Training: 100%|██████████| 1164/1164 [02:32<00:00,  7.66it/s]\n",
      "Epoch 36/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_36.csv\n",
      "\n",
      "Epoch [36/50]\n",
      "Train Loss: 0.0123, Train AUC: 0.8175, Train AP: 0.3973, Train Gini: 0.6349\n",
      "Train Acc: 0.9872, Train Precision: 0.9352, Train Recall: 0.3022, Train F1: 0.4568\n",
      "Val Loss: 0.0141, Val AUC: 0.8121, Val AP: 0.3204, Val Gini: 0.6242, Mean Y Predicted: 0.0150\n",
      "Val Acc: 0.9850, Val Precision: 0.7408, Val Recall: 0.2279, Val F1: 0.3486\n",
      "Train Confusion Matrix:\n",
      "[[4779720    1810]\n",
      " [  60273   26104]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102307    4437]\n",
      " [  42952   12680]]\n",
      "Metrics plots saved to plots2/epoch_36_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Training: 100%|██████████| 1164/1164 [02:31<00:00,  7.68it/s]\n",
      "Epoch 37/50 - Validation: 100%|██████████| 554/554 [00:39<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_37.csv\n",
      "\n",
      "Epoch [37/50]\n",
      "Train Loss: 0.0123, Train AUC: 0.8180, Train AP: 0.3993, Train Gini: 0.6360\n",
      "Train Acc: 0.9873, Train Precision: 0.9358, Train Recall: 0.3054, Train F1: 0.4605\n",
      "Val Loss: 0.0141, Val AUC: 0.8112, Val AP: 0.3168, Val Gini: 0.6224, Mean Y Predicted: 0.0152\n",
      "Val Acc: 0.9852, Val Precision: 0.7924, Val Recall: 0.2135, Val F1: 0.3363\n",
      "Train Confusion Matrix:\n",
      "[[4779721    1809]\n",
      " [  59995   26382]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103633    3111]\n",
      " [  43756   11876]]\n",
      "Metrics plots saved to plots2/epoch_37_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Training: 100%|██████████| 1164/1164 [02:26<00:00,  7.95it/s]\n",
      "Epoch 38/50 - Validation: 100%|██████████| 554/554 [00:40<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_38.csv\n",
      "\n",
      "Epoch [38/50]\n",
      "Train Loss: 0.0122, Train AUC: 0.8197, Train AP: 0.4037, Train Gini: 0.6394\n",
      "Train Acc: 0.9874, Train Precision: 0.9422, Train Recall: 0.3116, Train F1: 0.4683\n",
      "Val Loss: 0.0142, Val AUC: 0.8116, Val AP: 0.3181, Val Gini: 0.6232, Mean Y Predicted: 0.0174\n",
      "Val Acc: 0.9849, Val Precision: 0.7336, Val Recall: 0.2262, Val F1: 0.3457\n",
      "Train Confusion Matrix:\n",
      "[[4779879    1651]\n",
      " [  59460   26917]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102175    4569]\n",
      " [  43050   12582]]\n",
      "Metrics plots saved to plots2/epoch_38_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Training: 100%|██████████| 1164/1164 [02:25<00:00,  7.98it/s]\n",
      "Epoch 39/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models2/val_predictions_epoch_39.csv\n",
      "\n",
      "Epoch [39/50]\n",
      "Train Loss: 0.0121, Train AUC: 0.8196, Train AP: 0.4050, Train Gini: 0.6392\n",
      "Train Acc: 0.9875, Train Precision: 0.9453, Train Recall: 0.3123, Train F1: 0.4695\n",
      "Val Loss: 0.0141, Val AUC: 0.8112, Val AP: 0.3156, Val Gini: 0.6224, Mean Y Predicted: 0.0166\n",
      "Val Acc: 0.9851, Val Precision: 0.7737, Val Recall: 0.2192, Val F1: 0.3416\n",
      "Train Confusion Matrix:\n",
      "[[4779970    1560]\n",
      " [  59400   26977]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103177    3567]\n",
      " [  43440   12192]]\n",
      "Metrics plots saved to plots2/epoch_39_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Training: 100%|██████████| 1164/1164 [02:17<00:00,  8.48it/s]\n",
      "Epoch 40/50 - Validation:  51%|█████     | 281/554 [00:26<00:12, 22.66it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x785e8e994700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-hoc_project/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jupyter-hoc_project/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/tljh/user/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/tljh/user/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/tljh/user/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/tljh/user/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Epoch 40/50 - Validation:  51%|█████     | 281/554 [00:26<00:25, 10.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 364>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    429\u001b[0m unique_id_flat \u001b[38;5;241m=\u001b[39m unique_id_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    431\u001b[0m valid_idx      \u001b[38;5;241m=\u001b[39m mask_flat \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 432\u001b[0m logits_valid   \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_flat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    433\u001b[0m y_valid        \u001b[38;5;241m=\u001b[39m y_batch_flat[valid_idx]\n\u001b[1;32m    434\u001b[0m uid_valid      \u001b[38;5;241m=\u001b[39m unique_id_flat[valid_idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "os.makedirs(\"Models2\", exist_ok=True)\n",
    "os.makedirs(\"plots2\", exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "class NASSequenceModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 numerical_features,\n",
    "                 categorical_features,\n",
    "                 embedding_dims,\n",
    "                 label_encoders,\n",
    "                 hidden_size=512,\n",
    "                 lstm_layers=4,\n",
    "                 attention_heads=4,\n",
    "                 attention_dropout=0.2,\n",
    "                 fc_dropout=0.2,\n",
    "                 max_seq_len=150):\n",
    "        super().__init__()\n",
    "\n",
    "        self.numerical_features   = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            col: nn.Embedding(\n",
    "                len(label_encoders[col].classes_) + 1,\n",
    "                embedding_dims[col],\n",
    "                padding_idx=0\n",
    "            )\n",
    "            for col in categorical_features\n",
    "        })\n",
    "        total_embed_dim = sum(embedding_dims[c] for c in categorical_features)\n",
    "        input_dim       = total_embed_dim + len(numerical_features)\n",
    "\n",
    "        self.abs_pos_emb   = nn.Parameter(torch.zeros(1, max_seq_len, input_dim))\n",
    "        self.time_gap_proj = nn.Linear(1, input_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "\n",
    "        self.layer_norm_pre_attn  = nn.LayerNorm(hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            hidden_size, attention_heads, attention_dropout, batch_first=True\n",
    "        )\n",
    "        self.layer_norm_post_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.gate_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.body_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out    = nn.Linear(hidden_size, 1)\n",
    "        self.dropout   = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, X_num, X_cat, mask=None, delta_t=None):\n",
    "        cat_parts = [self.embeddings[col](X_cat[col]) for col in self.categorical_features]\n",
    "        x_cat  = torch.cat(cat_parts, dim=-1)\n",
    "        x      = torch.cat([X_num, x_cat], dim=-1)\n",
    "\n",
    "        x = x + self.abs_pos_emb[:, :x.size(1), :]\n",
    "\n",
    "        if delta_t is not None:\n",
    "            x = x + self.time_gap_proj(torch.log1p(delta_t))\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm_pre_attn(x)\n",
    "        key_padding = None if mask is None else (mask == 0)\n",
    "        seq_len = x.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool),\n",
    "                                 diagonal=1)\n",
    "        attn_out, _ = self.multihead_attn(x, x, x,\n",
    "                                          attn_mask=causal_mask,\n",
    "                                          key_padding_mask=key_padding)\n",
    "        x = residual + attn_out\n",
    "        x = self.layer_norm_post_attn(x)\n",
    "\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        body = torch.tanh(self.body_proj(x))\n",
    "        x = self.dropout(gate * body)\n",
    "        logits = self.fc_out(x).squeeze(-1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "class UserSequenceDataset(Dataset):\n",
    "    def __init__(self, X_numerical, X_categorical, y, mask, unique_ids):\n",
    "        self.X_numerical = torch.tensor(X_numerical, dtype=torch.float32)\n",
    "        self.X_categorical = {col: torch.tensor(values, dtype=torch.long) for col, values in X_categorical.items()}\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.unique_ids = unique_ids\n",
    "        self.num_samples = self.X_numerical.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_num = self.X_numerical[idx]\n",
    "        X_cat = {col: values[idx] for col, values in self.X_categorical.items()}\n",
    "        y_seq = self.y[idx]\n",
    "        mask_seq = self.mask[idx]\n",
    "        unique_id = torch.tensor(self.unique_ids[idx], dtype=torch.long)\n",
    "        if unique_id.dim() == 2:\n",
    "            unique_id = unique_id[:, 0]\n",
    "        return (X_num, X_cat), y_seq, mask_seq, unique_id\n",
    "\n",
    "with open('processed_data_pytorch2.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "X_train_numerical = processed_data['X_train_numerical']\n",
    "X_train_categorical = processed_data['X_train_embedding']\n",
    "y_train = processed_data['y_train']\n",
    "train_mask = processed_data['train_mask']\n",
    "train_unique_ids = processed_data.get('train_unique_ids', [])\n",
    "X_test_numerical = processed_data['X_test_numerical']\n",
    "X_test_categorical = processed_data['X_test_embedding']\n",
    "y_test = processed_data['y_test']\n",
    "test_mask = processed_data['test_mask']\n",
    "test_unique_ids = processed_data.get('test_unique_ids', [])\n",
    "class_weight_dict = processed_data['class_weight_dict']\n",
    "max_seq_length = processed_data['max_seq_length']\n",
    "numerical_features = processed_data['numerical_features']\n",
    "categorical_features = processed_data['embedding_features']\n",
    "\n",
    "print(\"Processed data loaded successfully.\")\n",
    "\n",
    "train_dataset = UserSequenceDataset(X_train_numerical, X_train_categorical, y_train, train_mask, train_unique_ids)\n",
    "test_dataset = UserSequenceDataset(X_test_numerical, X_test_categorical, y_test, test_mask, test_unique_ids)\n",
    "\n",
    "num_workers = 20\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "class MockLabelEncoder:\n",
    "    def __init__(self, num_classes):\n",
    "        self.classes_ = list(range(num_classes))\n",
    "\n",
    "mock_label_encoders = {col: MockLabelEncoder(num_classes=int(np.max(X_train_categorical[col]) + 1))\n",
    "                       for col in categorical_features}\n",
    "\n",
    "embedding_dims = {col: int(min(50, np.ceil((np.max(X_train_categorical[col]) + 1) / 2)))\n",
    "                  for col in categorical_features}\n",
    "\n",
    "model = NASSequenceModel(numerical_features, categorical_features, embedding_dims, mock_label_encoders)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=20, verbose=True)\n",
    "\n",
    "y_train_flat = np.array(y_train).flatten()\n",
    "train_mask_flat = np.array(train_mask).flatten()\n",
    "y_train_valid = y_train_flat[train_mask_flat == 1]\n",
    "baseline_ctr = y_train_valid.mean()\n",
    "baseline_loss = - (baseline_ctr * np.log(baseline_ctr + 1e-9) +\n",
    "                   (1 - baseline_ctr) * np.log((1 - baseline_ctr) + 1e-9))\n",
    "baseline_loss = max(baseline_loss, 1e-12)\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_auc = 0.0\n",
    "epochs_list, train_loss_list, val_loss_list = [], [], []\n",
    "train_auc_list, val_auc_list = [], []\n",
    "train_ap_list,  val_ap_list  = [], []\n",
    "train_gini_list, val_gini_list = [], []\n",
    "train_rig_list,  val_rig_list  = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses, train_y_true, train_y_pred = [], [], []\n",
    "\n",
    "    for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "            train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training'):\n",
    "\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "        y_batch     = y_batch.to(device)\n",
    "        mask_batch  = mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "        logits_flat    = logits.view(-1)\n",
    "        y_batch_flat   = y_batch.view(-1)\n",
    "        mask_flat      = mask_batch.view(-1)\n",
    "        valid_idx      = mask_flat == 1\n",
    "        logits_valid   = logits_flat[valid_idx]\n",
    "        y_valid        = y_batch_flat[valid_idx]\n",
    "\n",
    "        loss = criterion(logits_valid, y_valid.float())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_y_true.extend(y_valid.detach().cpu().numpy())\n",
    "        train_y_pred.extend(torch.sigmoid(logits_valid.detach()).cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_auc  = roc_auc_score(train_y_true, train_y_pred)\n",
    "    train_ap   = average_precision_score(train_y_true, train_y_pred)\n",
    "    train_gini = 2 * train_auc - 1\n",
    "\n",
    "    optimal_threshold_train = 0.5\n",
    "\n",
    "    train_pred_labels = (np.array(train_y_pred) >= 0.5).astype(int)\n",
    "    train_accuracy    = accuracy_score(train_y_true, train_pred_labels)\n",
    "    train_precision   = precision_score(train_y_true, train_pred_labels, zero_division=0)\n",
    "    train_recall      = recall_score(train_y_true, train_pred_labels,  zero_division=0)\n",
    "    train_f1          = f1_score(train_y_true,   train_pred_labels,  zero_division=0)\n",
    "    train_cm = confusion_matrix(train_y_true, train_pred_labels)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses, y_true_val, y_pred_val, val_predictions = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "                test_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Validation'):\n",
    "\n",
    "            X_num_batch = X_num_batch.to(device)\n",
    "            X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "            y_batch     = y_batch.to(device)\n",
    "            mask_batch  = mask_batch.to(device)\n",
    "\n",
    "            actual_ad_ids = X_cat_batch[\"CURRENT_AD_ID\"].view(-1)\n",
    "            logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "\n",
    "            logits_flat    = logits.view(-1)\n",
    "            y_batch_flat   = y_batch.view(-1)\n",
    "            mask_flat      = mask_batch.view(-1)\n",
    "            unique_id_flat = unique_id_batch.view(-1)\n",
    "\n",
    "            valid_idx      = mask_flat == 1\n",
    "            logits_valid   = logits_flat[valid_idx]\n",
    "            y_valid        = y_batch_flat[valid_idx]\n",
    "            uid_valid      = unique_id_flat[valid_idx]\n",
    "\n",
    "            ad_ids_valid = actual_ad_ids[valid_idx].cpu().numpy()\n",
    "            preds_valid  = torch.sigmoid(logits_valid).cpu().numpy()\n",
    "            actual_y_val = y_valid.cpu().numpy()\n",
    "\n",
    "            for uid, pred, actual, ad_id in zip(uid_valid.cpu().numpy(),\n",
    "                                                preds_valid, actual_y_val, ad_ids_valid):\n",
    "                val_predictions.append({\n",
    "                    'Unique_ID': uid,\n",
    "                    'Predicted_Y': pred,\n",
    "                    'Actual_Y': actual,\n",
    "                    'Actual_Ad_ID': ad_id\n",
    "                })\n",
    "\n",
    "            loss = criterion(logits_valid, y_valid.float())\n",
    "            val_losses.append(loss.item())\n",
    "            y_true_val.extend(actual_y_val)\n",
    "            y_pred_val.extend(preds_valid)\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_auc  = roc_auc_score(y_true_val, y_pred_val)\n",
    "    val_ap   = average_precision_score(y_true_val, y_pred_val)\n",
    "    val_gini = 2 * val_auc - 1\n",
    "\n",
    "    fpr_val, tpr_val, thresholds_val = roc_curve(y_true_val, y_pred_val)\n",
    "    youdens_j_val = tpr_val - fpr_val\n",
    "    optimal_idx_val = np.argmax(youdens_j_val)\n",
    "    optimal_threshold_val = thresholds_val[optimal_idx_val]\n",
    "    optimal_threshold_val = 0.5\n",
    "    val_pred_labels = (np.array(y_pred_val) >= optimal_threshold_val).astype(int)\n",
    "    val_accuracy = accuracy_score(y_true_val, val_pred_labels)\n",
    "    val_precision = precision_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_recall = recall_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_f1 = f1_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_cm = confusion_matrix(y_true_val, val_pred_labels)\n",
    "    val_pred_mean = np.mean(y_pred_val)\n",
    "\n",
    "    scheduler.step(val_auc)\n",
    "    model_save_path = f\"Models2/model_epoch_{epoch+1}.pth\"\n",
    "    thresholds_save_path = f\"Models2/thresholds_epoch_{epoch+1}.pkl\"\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_auc': train_auc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_auc': val_auc,\n",
    "    }, model_save_path)\n",
    "\n",
    "    thresholds_info = {\n",
    "        'optimal_threshold_train': float(optimal_threshold_train),\n",
    "        'optimal_threshold_val': float(optimal_threshold_val),\n",
    "    }\n",
    "\n",
    "    with open(thresholds_save_path, 'wb') as f:\n",
    "        pickle.dump(thresholds_info, f)\n",
    "\n",
    "    val_preds_df = pd.DataFrame(val_predictions)\n",
    "    val_preds_save_path = f\"Models2/val_predictions_epoch_{epoch+1}.csv\"\n",
    "    val_preds_df.to_csv(val_preds_save_path, index=False)\n",
    "    print(f\"Validation predictions saved to {val_preds_save_path}\")\n",
    "\n",
    "    epochs_list.append(epoch + 1)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    train_auc_list.append(train_auc)\n",
    "    val_auc_list.append(val_auc)\n",
    "    train_ap_list.append(train_ap)\n",
    "    val_ap_list.append(val_ap)\n",
    "    train_gini_list.append(train_gini)\n",
    "    val_gini_list.append(val_gini)\n",
    "    train_rig_list.append((1 - (train_loss / baseline_loss)) * 100)\n",
    "    val_rig_list.append((1 - (val_loss / baseline_loss)) * 100)\n",
    "\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train AP: {train_ap:.4f}, Train Gini: {train_gini:.4f}')\n",
    "    print(f'Train Acc: {train_accuracy:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val AP: {val_ap:.4f}, Val Gini: {val_gini:.4f}, Mean Y Predicted: {val_pred_mean:.4f}')\n",
    "    print(f'Val Acc: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n",
    "    print(f'Train Confusion Matrix:\\n{train_cm}')\n",
    "    print(f'Validation Confusion Matrix:\\n{val_cm}')\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    axs[0, 0].plot(epochs_list, train_loss_list, label='Train Loss', marker='o')\n",
    "    axs[0, 0].plot(epochs_list, val_loss_list, label='Validation Loss', marker='o')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].set_title('Loss over Epochs')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(epochs_list, train_auc_list, label='Train AUC', marker='o')\n",
    "    axs[0, 1].plot(epochs_list, val_auc_list, label='Validation AUC', marker='o')\n",
    "    axs[0, 1].set_xlabel('Epoch')\n",
    "    axs[0, 1].set_ylabel('AUC')\n",
    "    axs[0, 1].set_title('AUC over Epochs')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[1, 0].plot(epochs_list, train_gini_list, label='Train Gini', marker='o')\n",
    "    axs[1, 0].plot(epochs_list, val_gini_list, label='Validation Gini', marker='o')\n",
    "    axs[1, 0].set_xlabel('Epoch')\n",
    "    axs[1, 0].set_ylabel('Gini Coefficient')\n",
    "    axs[1, 0].set_title('Gini Coefficient over Epochs')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(epochs_list, train_rig_list, label='Train RIG')\n",
    "    axs[1, 1].plot(epochs_list, val_rig_list, label='Validation RIG')\n",
    "    axs[1, 1].set_xlabel('Epoch')\n",
    "    axs[1, 1].set_ylabel('RIG (%)')\n",
    "    axs[1, 1].set_title('Relative Information Gain over Epochs')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_save_path = f'plots2/epoch_{epoch+1}_metrics.png'\n",
    "    plt.savefig(plot_save_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"Metrics plots saved to {plot_save_path}\")\n",
    "\n",
    "print(\"Training complete. All models and plots are saved in their respective directories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479c61f-e919-4a14-a024-fd176ba7580e",
   "metadata": {},
   "source": [
    "### Counterfactual Prediction on the Test Set (Full Model)\n",
    "\n",
    "After loading the selected best trained model, counterfactual predictions are computed on the **test set**.\n",
    "\n",
    "For each valid timestep, the user’s full past sequence is kept fixed and only the `CURRENT_AD_ID` at that timestep is replaced with every possible ad. The model then predicts click probabilities for each alternative. Sequence logic is preserved because:\n",
    "- Data are time-ordered and truncated consistently.\n",
    "- Padding is excluded via the mask.\n",
    "- Causal attention prevents using future information.\n",
    "\n",
    "Thus, each counterfactual prediction reflects: given the user’s history up to time *t*, what would happen if a different ad were shown?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3afef31c-8c84-41de-bc2f-5de1437e025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features Columns:\n",
      "['MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING', 'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING', 'ISP_ID_EMBEDDING', 'CURRENT_AD_ID', 'CITY', 'PROVINCE']\n",
      "Numerical Features Columns:\n",
      "['HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS', 'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall', 'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad', 'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App', 'Overall_Usage_App', 'LATITUDE', 'LONGITUDE']\n",
      "Current numerical features: 22\n",
      "Current embedding dimension sum: 168\n",
      "Expected LSTM input size: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regular Eval for Epoch 29: 100%|██████████| 554/554 [00:31<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Validation Performance Metrics:\n",
      "Val AUC: 0.8115\n",
      "Val AP: 0.3296\n",
      "Val Accuracy: 0.9853\n",
      "Val Precision: 0.7887\n",
      "Val Recall: 0.2230\n",
      "Val F1: 0.3477\n",
      "Val Gini: 0.6231\n",
      "Val Predicted Y Mean: 0.0184\n",
      "Val Confusion Matrix:\n",
      "[[3103421    3323]\n",
      " [  43225   12407]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counterfactual Eval for Epoch 29: 100%|██████████| 554/554 [1:25:15<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual validation predictions saved to Models2/val_counterfactual_predictions_epoch_BehavioralGeographical.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "desired_epoch = 29\n",
    "csv_path = f\"Models2/val_predictions_epoch_{desired_epoch}.csv\"\n",
    "val_df = pd.read_csv(csv_path).copy()\n",
    "val_df['Unique_ID'] = val_df['Unique_ID'].astype(int)\n",
    "\n",
    "with open('processed_data_pytorch2.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "X_test_numerical = processed_data['X_test_numerical']\n",
    "X_test_categorical = processed_data['X_test_embedding']\n",
    "y_test = processed_data['y_test']\n",
    "test_mask = processed_data['test_mask']\n",
    "test_unique_ids = processed_data.get('test_unique_ids', [])\n",
    "class_weight_dict = processed_data['class_weight_dict']\n",
    "max_seq_length = processed_data['max_seq_length']\n",
    "numerical_features = processed_data['numerical_features']\n",
    "categorical_features = processed_data['embedding_features']\n",
    "\n",
    "class MockLabelEncoder:\n",
    "    def __init__(self, num_classes):\n",
    "        self.classes_ = list(range(num_classes))\n",
    "\n",
    "mock_label_encoders = {\n",
    "    col: MockLabelEncoder(num_classes=int(np.max(X_test_categorical[col]) + 1))\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "embedding_dims = {\n",
    "    col: int(min(50, np.ceil((np.max(X_test_categorical[col]) + 1) / 2)))\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "print(\"Categorical Features Columns:\")\n",
    "print(categorical_features)\n",
    "\n",
    "print(\"Numerical Features Columns:\")\n",
    "print(numerical_features)\n",
    "\n",
    "print(f\"Current numerical features: {len(numerical_features)}\")\n",
    "print(f\"Current embedding dimension sum: {sum(embedding_dims.values())}\")\n",
    "print(f\"Expected LSTM input size: {len(numerical_features) + sum(embedding_dims.values())}\")\n",
    "\n",
    "class UserSequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_numerical, X_categorical, y, mask, unique_ids):\n",
    "        self.X_numerical = torch.tensor(X_numerical, dtype=torch.float32)\n",
    "        self.X_categorical = {\n",
    "            col: torch.tensor(vals, dtype=torch.long)\n",
    "            for col, vals in X_categorical.items()\n",
    "        }\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.unique_ids = unique_ids\n",
    "        self.num_samples = self.X_numerical.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_num = self.X_numerical[idx]\n",
    "        X_cat = {col: vals[idx] for col, vals in self.X_categorical.items()}\n",
    "        y_seq = self.y[idx]\n",
    "        mask_seq = self.mask[idx]\n",
    "        unique_id = torch.tensor(self.unique_ids[idx], dtype=torch.long)\n",
    "        if unique_id.dim() == 2:\n",
    "            unique_id = unique_id[:, 0]\n",
    "        return (X_num, X_cat), y_seq, mask_seq, unique_id\n",
    "\n",
    "test_dataset = UserSequenceDataset(\n",
    "    X_test_numerical,\n",
    "    X_test_categorical,\n",
    "    y_test,\n",
    "    test_mask,\n",
    "    test_unique_ids\n",
    ")\n",
    "\n",
    "num_workers = 10\n",
    "batch_size = 256\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "class NASSequenceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        numerical_features,\n",
    "        categorical_features,\n",
    "        embedding_dims,\n",
    "        label_encoders,\n",
    "        hidden_size=512,\n",
    "        lstm_layers=4,\n",
    "        attention_heads=4,\n",
    "        attention_dropout=0.2,\n",
    "        fc_dropout=0.2,\n",
    "        max_seq_len=150\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            col: nn.Embedding(\n",
    "                len(label_encoders[col].classes_) + 1,\n",
    "                embedding_dims[col],\n",
    "                padding_idx=0\n",
    "            )\n",
    "            for col in categorical_features\n",
    "        })\n",
    "\n",
    "        total_embed_dim = sum(embedding_dims[c] for c in categorical_features)\n",
    "        input_dim = total_embed_dim + len(numerical_features)\n",
    "\n",
    "        self.abs_pos_emb = nn.Parameter(torch.zeros(1, max_seq_len, input_dim))\n",
    "        self.time_gap_proj = nn.Linear(1, input_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.layer_norm_pre_attn = nn.LayerNorm(hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            hidden_size,\n",
    "            attention_heads,\n",
    "            attention_dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.layer_norm_post_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.gate_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.body_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, X_num, X_cat, mask=None, delta_t=None):\n",
    "        cat_parts = [\n",
    "            self.embeddings[col](X_cat[col])\n",
    "            for col in self.categorical_features\n",
    "        ]\n",
    "        x_cat = torch.cat(cat_parts, dim=-1)\n",
    "        x = torch.cat([X_num, x_cat], dim=-1)\n",
    "\n",
    "        x = x + self.abs_pos_emb[:, :x.size(1), :]\n",
    "\n",
    "        if delta_t is not None:\n",
    "            x = x + self.time_gap_proj(torch.log1p(delta_t))\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm_pre_attn(x)\n",
    "        key_padding = None if mask is None else (mask == 0)\n",
    "        seq_len = x.size(1)\n",
    "        causal_mask = torch.triu(\n",
    "            torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool),\n",
    "            diagonal=1\n",
    "        )\n",
    "\n",
    "        attn_out, _ = self.multihead_attn(\n",
    "            x, x, x,\n",
    "            attn_mask=causal_mask,\n",
    "            key_padding_mask=key_padding\n",
    "        )\n",
    "\n",
    "        x = residual + attn_out\n",
    "        x = self.layer_norm_post_attn(x)\n",
    "\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        body = torch.tanh(self.body_proj(x))\n",
    "        x = self.dropout(gate * body)\n",
    "        logits = self.fc_out(x).squeeze(-1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "mock_label_encoders = {\n",
    "    col: MockLabelEncoder(\n",
    "        num_classes=int(np.max(processed_data['X_train_embedding'][col]) + 1)\n",
    "    )\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "embedding_dims = {\n",
    "    col: int(\n",
    "        min(\n",
    "            50,\n",
    "            np.ceil(\n",
    "                (np.max(processed_data['X_train_embedding'][col]) + 1) / 2\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "numerical_features = processed_data['numerical_features']\n",
    "\n",
    "model = NASSequenceModel(\n",
    "    numerical_features,\n",
    "    categorical_features,\n",
    "    embedding_dims,\n",
    "    mock_label_encoders\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint_path = f\"Models2/model_epoch_{desired_epoch}.pth\"\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    checkpoint_path,\n",
    "    map_location=torch.device('cpu'),\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "        test_loader,\n",
    "        desc=f'Regular Eval for Epoch {desired_epoch}'\n",
    "    ):\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "        y_batch = y_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "\n",
    "        actual_ad_ids = X_cat_batch[\"CURRENT_AD_ID\"].view(-1)\n",
    "\n",
    "        logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "\n",
    "        logits_flat = logits.view(-1)\n",
    "        y_flat = y_batch.view(-1)\n",
    "        mask_flat = mask_batch.view(-1)\n",
    "        unique_id_flat = unique_id_batch.view(-1)\n",
    "\n",
    "        valid_idx = mask_flat == 1\n",
    "\n",
    "        preds = torch.sigmoid(logits_flat[valid_idx]).detach().cpu().numpy()\n",
    "        y_true = y_flat[valid_idx].detach().cpu().numpy()\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(preds)\n",
    "\n",
    "val_auc = roc_auc_score(all_y_true, all_y_pred)\n",
    "val_ap = average_precision_score(all_y_true, all_y_pred)\n",
    "optimal_threshold = 0.5\n",
    "val_pred_labels = (np.array(all_y_pred) >= optimal_threshold).astype(int)\n",
    "val_accuracy = accuracy_score(all_y_true, val_pred_labels)\n",
    "val_precision = precision_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_recall = recall_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_f1 = f1_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_cm = confusion_matrix(all_y_true, val_pred_labels)\n",
    "val_gini = 2 * val_auc - 1\n",
    "val_pred_mean = np.mean(all_y_pred)\n",
    "\n",
    "print(\"Regular Validation Performance Metrics:\")\n",
    "print(f\"Val AUC: {val_auc:.4f}\")\n",
    "print(f\"Val AP: {val_ap:.4f}\")\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Val Precision: {val_precision:.4f}\")\n",
    "print(f\"Val Recall: {val_recall:.4f}\")\n",
    "print(f\"Val F1: {val_f1:.4f}\")\n",
    "print(f\"Val Gini: {val_gini:.4f}\")\n",
    "print(f'Val Predicted Y Mean: {val_pred_mean:.4f}')\n",
    "print(\"Val Confusion Matrix:\")\n",
    "print(val_cm)\n",
    "\n",
    "num_ads = len(mock_label_encoders[\"CURRENT_AD_ID\"].classes_)\n",
    "cf_results = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_num_batch, X_cat_batch), _, mask_batch, unique_id_batch in tqdm(\n",
    "        test_loader,\n",
    "        desc=f'Counterfactual Eval for Epoch {desired_epoch}'\n",
    "    ):\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {c: X_cat_batch[c].to(device) for c in X_cat_batch}\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        unique_id_batch = unique_id_batch.to(device)\n",
    "\n",
    "        B, L, _ = X_num_batch.size()\n",
    "\n",
    "        for t in range(L):\n",
    "            valid_idx = (mask_batch[:, t] == 1).nonzero(as_tuple=False).squeeze()\n",
    "            if valid_idx.numel() == 0:\n",
    "                continue\n",
    "            if valid_idx.dim() == 0:\n",
    "                valid_idx = valid_idx.unsqueeze(0)\n",
    "\n",
    "            X_num_v = X_num_batch[valid_idx]\n",
    "            X_cat_v = {c: X_cat_batch[c][valid_idx] for c in X_cat_batch}\n",
    "            uids_v = unique_id_batch[valid_idx, t]\n",
    "\n",
    "            X_num_rep = X_num_v.repeat_interleave(num_ads, dim=0)\n",
    "            X_cat_rep = {\n",
    "                c: X_cat_v[c].repeat_interleave(num_ads, dim=0)\n",
    "                for c in X_cat_v\n",
    "            }\n",
    "\n",
    "            ad_vals = torch.arange(num_ads, device=device).repeat(X_num_v.size(0))\n",
    "\n",
    "            if X_cat_rep[\"CURRENT_AD_ID\"].dim() == 1:\n",
    "                X_cat_rep[\"CURRENT_AD_ID\"] = X_cat_rep[\"CURRENT_AD_ID\"].unsqueeze(1)\n",
    "\n",
    "            X_cat_rep[\"CURRENT_AD_ID\"][:, t] = ad_vals\n",
    "\n",
    "            logits_cf = model(X_num_rep, X_cat_rep)\n",
    "            preds_cf = torch.sigmoid(logits_cf[:, t]).view(\n",
    "                X_num_v.size(0),\n",
    "                num_ads\n",
    "            )\n",
    "\n",
    "            for i, uid_tensor in enumerate(uids_v):\n",
    "                uid = int(uid_tensor.item())\n",
    "                cf_results[uid] = {\n",
    "                    f\"cf_ad_{a}\": preds_cf[i, a].item()\n",
    "                    for a in range(num_ads)\n",
    "                }\n",
    "\n",
    "cf_df = pd.DataFrame.from_dict(cf_results, orient='index')\n",
    "cf_df.index.name = \"Unique_ID\"\n",
    "cf_df.reset_index(inplace=True)\n",
    "\n",
    "merged_df = pd.merge(val_df, cf_df, on=\"Unique_ID\", how=\"left\")\n",
    "\n",
    "output_csv = \"Models2/val_counterfactual_predictions_BehavioralGeographical.csv\"\n",
    "merged_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Counterfactual validation predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916b3d0-f30e-4646-8a99-76ba0ae1f500",
   "metadata": {},
   "source": [
    "## Train LSTM with Attention for Behavioral Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c876c3f9-6ba0-4dfb-94c6-26423fea8fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.62it/s]\n",
      "Epoch 1/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_1.csv\n",
      "\n",
      "Epoch [1/50]\n",
      "Train Loss: 0.0176, Train AUC: 0.5843, Train AP: 0.0293, Train Gini: 0.1687\n",
      "Train Acc: 0.9818, Train Precision: 0.1393, Train Recall: 0.0047, Train F1: 0.0090\n",
      "Val Loss: 0.0169, Val AUC: 0.6568, Val AP: 0.0692, Val Gini: 0.3136, Mean Y Predicted: 0.0190\n",
      "Val Acc: 0.9828, Val Precision: 0.9375, Val Recall: 0.0232, Val F1: 0.0453\n",
      "Train Confusion Matrix:\n",
      "[[4779039    2491]\n",
      " [  85974     403]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106658      86]\n",
      " [  54342    1290]]\n",
      "Metrics plots saved to plots0/epoch_1_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|██████████| 1164/1164 [02:12<00:00,  8.79it/s]\n",
      "Epoch 2/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_2.csv\n",
      "\n",
      "Epoch [2/50]\n",
      "Train Loss: 0.0172, Train AUC: 0.6214, Train AP: 0.0579, Train Gini: 0.2428\n",
      "Train Acc: 0.9825, Train Precision: 0.8077, Train Recall: 0.0176, Train F1: 0.0344\n",
      "Val Loss: 0.0168, Val AUC: 0.6715, Val AP: 0.0801, Val Gini: 0.3430, Mean Y Predicted: 0.0199\n",
      "Val Acc: 0.9828, Val Precision: 0.9550, Val Recall: 0.0214, Val F1: 0.0418\n",
      "Train Confusion Matrix:\n",
      "[[4781168     362]\n",
      " [  84857    1520]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106688      56]\n",
      " [  54443    1189]]\n",
      "Metrics plots saved to plots0/epoch_2_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.73it/s]\n",
      "Epoch 3/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_3.csv\n",
      "\n",
      "Epoch [3/50]\n",
      "Train Loss: 0.0170, Train AUC: 0.6387, Train AP: 0.0724, Train Gini: 0.2773\n",
      "Train Acc: 0.9826, Train Precision: 0.7336, Train Recall: 0.0268, Train F1: 0.0517\n",
      "Val Loss: 0.0167, Val AUC: 0.6663, Val AP: 0.0882, Val Gini: 0.3326, Mean Y Predicted: 0.0175\n",
      "Val Acc: 0.9828, Val Precision: 0.9785, Val Recall: 0.0213, Val F1: 0.0416\n",
      "Train Confusion Matrix:\n",
      "[[4780689     841]\n",
      " [  84061    2316]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106718      26]\n",
      " [  54449    1183]]\n",
      "Metrics plots saved to plots0/epoch_3_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.64it/s]\n",
      "Epoch 4/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_4.csv\n",
      "\n",
      "Epoch [4/50]\n",
      "Train Loss: 0.0169, Train AUC: 0.6546, Train AP: 0.0838, Train Gini: 0.3091\n",
      "Train Acc: 0.9826, Train Precision: 0.7779, Train Recall: 0.0265, Train F1: 0.0513\n",
      "Val Loss: 0.0166, Val AUC: 0.6791, Val AP: 0.1012, Val Gini: 0.3582, Mean Y Predicted: 0.0179\n",
      "Val Acc: 0.9827, Val Precision: 0.6947, Val Recall: 0.0310, Val F1: 0.0594\n",
      "Train Confusion Matrix:\n",
      "[[4780876     654]\n",
      " [  84086    2291]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105985     759]\n",
      " [  53905    1727]]\n",
      "Metrics plots saved to plots0/epoch_4_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.74it/s]\n",
      "Epoch 5/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_5.csv\n",
      "\n",
      "Epoch [5/50]\n",
      "Train Loss: 0.0169, Train AUC: 0.6532, Train AP: 0.0824, Train Gini: 0.3064\n",
      "Train Acc: 0.9826, Train Precision: 0.7783, Train Recall: 0.0273, Train F1: 0.0528\n",
      "Val Loss: 0.0169, Val AUC: 0.6759, Val AP: 0.0804, Val Gini: 0.3519, Mean Y Predicted: 0.0128\n",
      "Val Acc: 0.9828, Val Precision: 0.9614, Val Recall: 0.0215, Val F1: 0.0420\n",
      "Train Confusion Matrix:\n",
      "[[4780858     672]\n",
      " [  84018    2359]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106696      48]\n",
      " [  54437    1195]]\n",
      "Metrics plots saved to plots0/epoch_5_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.75it/s]\n",
      "Epoch 6/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_6.csv\n",
      "\n",
      "Epoch [6/50]\n",
      "Train Loss: 0.0169, Train AUC: 0.6450, Train AP: 0.0806, Train Gini: 0.2900\n",
      "Train Acc: 0.9826, Train Precision: 0.8346, Train Recall: 0.0245, Train F1: 0.0476\n",
      "Val Loss: 0.0168, Val AUC: 0.6678, Val AP: 0.0850, Val Gini: 0.3356, Mean Y Predicted: 0.0131\n",
      "Val Acc: 0.9828, Val Precision: 0.7837, Val Recall: 0.0343, Val F1: 0.0657\n",
      "Train Confusion Matrix:\n",
      "[[4781111     419]\n",
      " [  84263    2114]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106218     526]\n",
      " [  53726    1906]]\n",
      "Metrics plots saved to plots0/epoch_6_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Training: 100%|██████████| 1164/1164 [02:12<00:00,  8.77it/s]\n",
      "Epoch 7/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_7.csv\n",
      "\n",
      "Epoch [7/50]\n",
      "Train Loss: 0.0167, Train AUC: 0.6688, Train AP: 0.1067, Train Gini: 0.3376\n",
      "Train Acc: 0.9826, Train Precision: 0.7453, Train Recall: 0.0312, Train F1: 0.0600\n",
      "Val Loss: 0.0163, Val AUC: 0.7080, Val AP: 0.1401, Val Gini: 0.4160, Mean Y Predicted: 0.0152\n",
      "Val Acc: 0.9828, Val Precision: 0.6473, Val Recall: 0.0528, Val F1: 0.0976\n",
      "Train Confusion Matrix:\n",
      "[[4780608     922]\n",
      " [  83679    2698]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105144    1600]\n",
      " [  52696    2936]]\n",
      "Metrics plots saved to plots0/epoch_7_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Training: 100%|██████████| 1164/1164 [02:12<00:00,  8.81it/s]\n",
      "Epoch 8/50 - Validation: 100%|██████████| 554/554 [00:34<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_8.csv\n",
      "\n",
      "Epoch [8/50]\n",
      "Train Loss: 0.0166, Train AUC: 0.6895, Train AP: 0.1185, Train Gini: 0.3791\n",
      "Train Acc: 0.9826, Train Precision: 0.7549, Train Recall: 0.0277, Train F1: 0.0534\n",
      "Val Loss: 0.0168, Val AUC: 0.7107, Val AP: 0.0999, Val Gini: 0.4215, Mean Y Predicted: 0.0202\n",
      "Val Acc: 0.9828, Val Precision: 0.9674, Val Recall: 0.0213, Val F1: 0.0417\n",
      "Train Confusion Matrix:\n",
      "[[4780753     777]\n",
      " [  83984    2393]]\n",
      "Validation Confusion Matrix:\n",
      "[[3106704      40]\n",
      " [  54446    1186]]\n",
      "Metrics plots saved to plots0/epoch_8_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.70it/s]\n",
      "Epoch 9/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_9.csv\n",
      "\n",
      "Epoch [9/50]\n",
      "Train Loss: 0.0164, Train AUC: 0.6987, Train AP: 0.1416, Train Gini: 0.3974\n",
      "Train Acc: 0.9827, Train Precision: 0.6991, Train Recall: 0.0396, Train F1: 0.0749\n",
      "Val Loss: 0.0157, Val AUC: 0.7662, Val AP: 0.1865, Val Gini: 0.5323, Mean Y Predicted: 0.0183\n",
      "Val Acc: 0.9831, Val Precision: 0.6910, Val Recall: 0.0696, Val F1: 0.1265\n",
      "Train Confusion Matrix:\n",
      "[[4780059    1471]\n",
      " [  82960    3417]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105012    1732]\n",
      " [  51758    3874]]\n",
      "Metrics plots saved to plots0/epoch_9_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.72it/s]\n",
      "Epoch 10/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_10.csv\n",
      "\n",
      "Epoch [10/50]\n",
      "Train Loss: 0.0159, Train AUC: 0.7575, Train AP: 0.1861, Train Gini: 0.5151\n",
      "Train Acc: 0.9828, Train Precision: 0.6663, Train Recall: 0.0656, Train F1: 0.1194\n",
      "Val Loss: 0.0157, Val AUC: 0.7572, Val AP: 0.1988, Val Gini: 0.5144, Mean Y Predicted: 0.0104\n",
      "Val Acc: 0.9832, Val Precision: 0.7076, Val Recall: 0.0746, Val F1: 0.1350\n",
      "Train Confusion Matrix:\n",
      "[[4778693    2837]\n",
      " [  80713    5664]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105029    1715]\n",
      " [  51481    4151]]\n",
      "Metrics plots saved to plots0/epoch_10_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.69it/s]\n",
      "Epoch 11/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_11.csv\n",
      "\n",
      "Epoch [11/50]\n",
      "Train Loss: 0.0157, Train AUC: 0.7626, Train AP: 0.1994, Train Gini: 0.5251\n",
      "Train Acc: 0.9830, Train Precision: 0.6618, Train Recall: 0.0828, Train F1: 0.1472\n",
      "Val Loss: 0.0155, Val AUC: 0.7875, Val AP: 0.2124, Val Gini: 0.5750, Mean Y Predicted: 0.0152\n",
      "Val Acc: 0.9832, Val Precision: 0.7089, Val Recall: 0.0747, Val F1: 0.1351\n",
      "Train Confusion Matrix:\n",
      "[[4777874    3656]\n",
      " [  79223    7154]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105038    1706]\n",
      " [  51478    4154]]\n",
      "Metrics plots saved to plots0/epoch_11_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.67it/s]\n",
      "Epoch 12/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_12.csv\n",
      "\n",
      "Epoch [12/50]\n",
      "Train Loss: 0.0156, Train AUC: 0.7714, Train AP: 0.2070, Train Gini: 0.5428\n",
      "Train Acc: 0.9830, Train Precision: 0.6661, Train Recall: 0.0835, Train F1: 0.1484\n",
      "Val Loss: 0.0155, Val AUC: 0.7916, Val AP: 0.2187, Val Gini: 0.5832, Mean Y Predicted: 0.0176\n",
      "Val Acc: 0.9830, Val Precision: 0.5664, Val Recall: 0.1339, Val F1: 0.2166\n",
      "Train Confusion Matrix:\n",
      "[[4777915    3615]\n",
      " [  79167    7210]]\n",
      "Validation Confusion Matrix:\n",
      "[[3101039    5705]\n",
      " [  48181    7451]]\n",
      "Metrics plots saved to plots0/epoch_12_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Training: 100%|██████████| 1164/1164 [02:07<00:00,  9.11it/s]\n",
      "Epoch 13/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_13.csv\n",
      "\n",
      "Epoch [13/50]\n",
      "Train Loss: 0.0154, Train AUC: 0.7777, Train AP: 0.2193, Train Gini: 0.5553\n",
      "Train Acc: 0.9831, Train Precision: 0.6493, Train Recall: 0.1062, Train F1: 0.1825\n",
      "Val Loss: 0.0153, Val AUC: 0.7872, Val AP: 0.2311, Val Gini: 0.5744, Mean Y Predicted: 0.0148\n",
      "Val Acc: 0.9834, Val Precision: 0.6156, Val Recall: 0.1487, Val F1: 0.2395\n",
      "Train Confusion Matrix:\n",
      "[[4776578    4952]\n",
      " [  77207    9170]]\n",
      "Validation Confusion Matrix:\n",
      "[[3101577    5167]\n",
      " [  47359    8273]]\n",
      "Metrics plots saved to plots0/epoch_13_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.68it/s]\n",
      "Epoch 14/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_14.csv\n",
      "\n",
      "Epoch [14/50]\n",
      "Train Loss: 0.0152, Train AUC: 0.7803, Train AP: 0.2411, Train Gini: 0.5606\n",
      "Train Acc: 0.9834, Train Precision: 0.6888, Train Recall: 0.1227, Train F1: 0.2083\n",
      "Val Loss: 0.0148, Val AUC: 0.7961, Val AP: 0.2620, Val Gini: 0.5922, Mean Y Predicted: 0.0205\n",
      "Val Acc: 0.9839, Val Precision: 0.6764, Val Recall: 0.1618, Val F1: 0.2612\n",
      "Train Confusion Matrix:\n",
      "[[4776740    4790]\n",
      " [  75776   10601]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102437    4307]\n",
      " [  46630    9002]]\n",
      "Metrics plots saved to plots0/epoch_14_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.57it/s]\n",
      "Epoch 15/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_15.csv\n",
      "\n",
      "Epoch [15/50]\n",
      "Train Loss: 0.0148, Train AUC: 0.7775, Train AP: 0.2684, Train Gini: 0.5549\n",
      "Train Acc: 0.9840, Train Precision: 0.7509, Train Recall: 0.1491, Train F1: 0.2488\n",
      "Val Loss: 0.0145, Val AUC: 0.7933, Val AP: 0.2800, Val Gini: 0.5866, Mean Y Predicted: 0.0146\n",
      "Val Acc: 0.9843, Val Precision: 0.7551, Val Recall: 0.1601, Val F1: 0.2641\n",
      "Train Confusion Matrix:\n",
      "[[4777256    4274]\n",
      " [  73495   12882]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103856    2888]\n",
      " [  46727    8905]]\n",
      "Metrics plots saved to plots0/epoch_15_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.73it/s]\n",
      "Epoch 16/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_16.csv\n",
      "\n",
      "Epoch [16/50]\n",
      "Train Loss: 0.0147, Train AUC: 0.7818, Train AP: 0.2731, Train Gini: 0.5635\n",
      "Train Acc: 0.9842, Train Precision: 0.7744, Train Recall: 0.1538, Train F1: 0.2566\n",
      "Val Loss: 0.0145, Val AUC: 0.7972, Val AP: 0.2901, Val Gini: 0.5945, Mean Y Predicted: 0.0087\n",
      "Val Acc: 0.9845, Val Precision: 0.8186, Val Recall: 0.1520, Val F1: 0.2564\n",
      "Train Confusion Matrix:\n",
      "[[4777662    3868]\n",
      " [  73096   13281]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104870    1874]\n",
      " [  47175    8457]]\n",
      "Metrics plots saved to plots0/epoch_16_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.68it/s]\n",
      "Epoch 17/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_17.csv\n",
      "\n",
      "Epoch [17/50]\n",
      "Train Loss: 0.0144, Train AUC: 0.7850, Train AP: 0.2880, Train Gini: 0.5700\n",
      "Train Acc: 0.9845, Train Precision: 0.7927, Train Recall: 0.1691, Train F1: 0.2787\n",
      "Val Loss: 0.0144, Val AUC: 0.7964, Val AP: 0.2913, Val Gini: 0.5929, Mean Y Predicted: 0.0160\n",
      "Val Acc: 0.9845, Val Precision: 0.7561, Val Recall: 0.1785, Val F1: 0.2889\n",
      "Train Confusion Matrix:\n",
      "[[4777711    3819]\n",
      " [  71771   14606]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103541    3203]\n",
      " [  45700    9932]]\n",
      "Metrics plots saved to plots0/epoch_17_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.71it/s]\n",
      "Epoch 18/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_18.csv\n",
      "\n",
      "Epoch [18/50]\n",
      "Train Loss: 0.0145, Train AUC: 0.7797, Train AP: 0.2833, Train Gini: 0.5594\n",
      "Train Acc: 0.9844, Train Precision: 0.7997, Train Recall: 0.1621, Train F1: 0.2695\n",
      "Val Loss: 0.0145, Val AUC: 0.7940, Val AP: 0.2826, Val Gini: 0.5881, Mean Y Predicted: 0.0158\n",
      "Val Acc: 0.9843, Val Precision: 0.7599, Val Recall: 0.1604, Val F1: 0.2649\n",
      "Train Confusion Matrix:\n",
      "[[4778024    3506]\n",
      " [  72377   14000]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103924    2820]\n",
      " [  46709    8923]]\n",
      "Metrics plots saved to plots0/epoch_18_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.69it/s]\n",
      "Epoch 19/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_19.csv\n",
      "\n",
      "Epoch [19/50]\n",
      "Train Loss: 0.0144, Train AUC: 0.7890, Train AP: 0.2919, Train Gini: 0.5781\n",
      "Train Acc: 0.9845, Train Precision: 0.8084, Train Recall: 0.1690, Train F1: 0.2795\n",
      "Val Loss: 0.0143, Val AUC: 0.8003, Val AP: 0.2970, Val Gini: 0.6005, Mean Y Predicted: 0.0169\n",
      "Val Acc: 0.9847, Val Precision: 0.7835, Val Recall: 0.1764, Val F1: 0.2879\n",
      "Train Confusion Matrix:\n",
      "[[4778071    3459]\n",
      " [  71782   14595]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104032    2712]\n",
      " [  45820    9812]]\n",
      "Metrics plots saved to plots0/epoch_19_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.62it/s]\n",
      "Epoch 20/50 - Validation: 100%|██████████| 554/554 [00:38<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_20.csv\n",
      "\n",
      "Epoch [20/50]\n",
      "Train Loss: 0.0141, Train AUC: 0.7943, Train AP: 0.3075, Train Gini: 0.5887\n",
      "Train Acc: 0.9848, Train Precision: 0.8134, Train Recall: 0.1863, Train F1: 0.3031\n",
      "Val Loss: 0.0142, Val AUC: 0.8023, Val AP: 0.3063, Val Gini: 0.6047, Mean Y Predicted: 0.0139\n",
      "Val Acc: 0.9848, Val Precision: 0.8267, Val Recall: 0.1738, Val F1: 0.2872\n",
      "Train Confusion Matrix:\n",
      "[[4777839    3691]\n",
      " [  70288   16089]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104717    2027]\n",
      " [  45962    9670]]\n",
      "Metrics plots saved to plots0/epoch_20_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.67it/s]\n",
      "Epoch 21/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_21.csv\n",
      "\n",
      "Epoch [21/50]\n",
      "Train Loss: 0.0142, Train AUC: 0.7906, Train AP: 0.3059, Train Gini: 0.5811\n",
      "Train Acc: 0.9848, Train Precision: 0.8268, Train Recall: 0.1831, Train F1: 0.2998\n",
      "Val Loss: 0.0142, Val AUC: 0.7975, Val AP: 0.3008, Val Gini: 0.5951, Mean Y Predicted: 0.0152\n",
      "Val Acc: 0.9848, Val Precision: 0.8136, Val Recall: 0.1766, Val F1: 0.2902\n",
      "Train Confusion Matrix:\n",
      "[[4778218    3312]\n",
      " [  70564   15813]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104493    2251]\n",
      " [  45806    9826]]\n",
      "Metrics plots saved to plots0/epoch_21_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.66it/s]\n",
      "Epoch 22/50 - Validation: 100%|██████████| 554/554 [00:35<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_22.csv\n",
      "\n",
      "Epoch [22/50]\n",
      "Train Loss: 0.0141, Train AUC: 0.7974, Train AP: 0.3115, Train Gini: 0.5949\n",
      "Train Acc: 0.9849, Train Precision: 0.8300, Train Recall: 0.1889, Train F1: 0.3078\n",
      "Val Loss: 0.0140, Val AUC: 0.8048, Val AP: 0.3137, Val Gini: 0.6097, Mean Y Predicted: 0.0173\n",
      "Val Acc: 0.9850, Val Precision: 0.8062, Val Recall: 0.1928, Val F1: 0.3112\n",
      "Train Confusion Matrix:\n",
      "[[4778189    3341]\n",
      " [  70060   16317]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104166    2578]\n",
      " [  44907   10725]]\n",
      "Metrics plots saved to plots0/epoch_22_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.66it/s]\n",
      "Epoch 23/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_23.csv\n",
      "\n",
      "Epoch [23/50]\n",
      "Train Loss: 0.0140, Train AUC: 0.7996, Train AP: 0.3161, Train Gini: 0.5992\n",
      "Train Acc: 0.9850, Train Precision: 0.8237, Train Recall: 0.1957, Train F1: 0.3162\n",
      "Val Loss: 0.0142, Val AUC: 0.8024, Val AP: 0.3031, Val Gini: 0.6049, Mean Y Predicted: 0.0168\n",
      "Val Acc: 0.9848, Val Precision: 0.8142, Val Recall: 0.1766, Val F1: 0.2902\n",
      "Train Confusion Matrix:\n",
      "[[4777913    3617]\n",
      " [  69477   16900]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104502    2242]\n",
      " [  45810    9822]]\n",
      "Metrics plots saved to plots0/epoch_23_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.60it/s]\n",
      "Epoch 24/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_24.csv\n",
      "\n",
      "Epoch [24/50]\n",
      "Train Loss: 0.0145, Train AUC: 0.7842, Train AP: 0.2871, Train Gini: 0.5683\n",
      "Train Acc: 0.9844, Train Precision: 0.7914, Train Recall: 0.1670, Train F1: 0.2759\n",
      "Val Loss: 0.0142, Val AUC: 0.8025, Val AP: 0.3016, Val Gini: 0.6050, Mean Y Predicted: 0.0162\n",
      "Val Acc: 0.9846, Val Precision: 0.8713, Val Recall: 0.1478, Val F1: 0.2527\n",
      "Train Confusion Matrix:\n",
      "[[4777728    3802]\n",
      " [  71949   14428]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105530    1214]\n",
      " [  47412    8220]]\n",
      "Metrics plots saved to plots0/epoch_24_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.73it/s]\n",
      "Epoch 25/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_25.csv\n",
      "\n",
      "Epoch [25/50]\n",
      "Train Loss: 0.0140, Train AUC: 0.7947, Train AP: 0.3184, Train Gini: 0.5894\n",
      "Train Acc: 0.9850, Train Precision: 0.8362, Train Recall: 0.1930, Train F1: 0.3137\n",
      "Val Loss: 0.0139, Val AUC: 0.8086, Val AP: 0.3220, Val Gini: 0.6172, Mean Y Predicted: 0.0145\n",
      "Val Acc: 0.9851, Val Precision: 0.8581, Val Recall: 0.1824, Val F1: 0.3008\n",
      "Train Confusion Matrix:\n",
      "[[4778264    3266]\n",
      " [  69703   16674]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105066    1678]\n",
      " [  45487   10145]]\n",
      "Metrics plots saved to plots0/epoch_25_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.64it/s]\n",
      "Epoch 26/50 - Validation: 100%|██████████| 554/554 [00:38<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_26.csv\n",
      "\n",
      "Epoch [26/50]\n",
      "Train Loss: 0.0139, Train AUC: 0.7995, Train AP: 0.3206, Train Gini: 0.5991\n",
      "Train Acc: 0.9852, Train Precision: 0.8388, Train Recall: 0.2042, Train F1: 0.3284\n",
      "Val Loss: 0.0143, Val AUC: 0.7889, Val AP: 0.2954, Val Gini: 0.5778, Mean Y Predicted: 0.0188\n",
      "Val Acc: 0.9847, Val Precision: 0.7362, Val Recall: 0.2022, Val F1: 0.3172\n",
      "Train Confusion Matrix:\n",
      "[[4778140    3390]\n",
      " [  68742   17635]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102714    4030]\n",
      " [  44385   11247]]\n",
      "Metrics plots saved to plots0/epoch_26_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.69it/s]\n",
      "Epoch 27/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_27.csv\n",
      "\n",
      "Epoch [27/50]\n",
      "Train Loss: 0.0139, Train AUC: 0.8010, Train AP: 0.3236, Train Gini: 0.6021\n",
      "Train Acc: 0.9852, Train Precision: 0.8524, Train Recall: 0.1994, Train F1: 0.3232\n",
      "Val Loss: 0.0139, Val AUC: 0.8075, Val AP: 0.3206, Val Gini: 0.6149, Mean Y Predicted: 0.0157\n",
      "Val Acc: 0.9852, Val Precision: 0.8555, Val Recall: 0.1888, Val F1: 0.3094\n",
      "Train Confusion Matrix:\n",
      "[[4778547    2983]\n",
      " [  69151   17226]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104970    1774]\n",
      " [  45127   10505]]\n",
      "Metrics plots saved to plots0/epoch_27_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Training: 100%|██████████| 1164/1164 [02:16<00:00,  8.52it/s]\n",
      "Epoch 28/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_28.csv\n",
      "\n",
      "Epoch [28/50]\n",
      "Train Loss: 0.0138, Train AUC: 0.8004, Train AP: 0.3298, Train Gini: 0.6007\n",
      "Train Acc: 0.9853, Train Precision: 0.8483, Train Recall: 0.2113, Train F1: 0.3383\n",
      "Val Loss: 0.0139, Val AUC: 0.8067, Val AP: 0.3236, Val Gini: 0.6135, Mean Y Predicted: 0.0136\n",
      "Val Acc: 0.9852, Val Precision: 0.8361, Val Recall: 0.1960, Val F1: 0.3175\n",
      "Train Confusion Matrix:\n",
      "[[4778266    3264]\n",
      " [  68128   18249]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104607    2137]\n",
      " [  44730   10902]]\n",
      "Metrics plots saved to plots0/epoch_28_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.66it/s]\n",
      "Epoch 29/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_29.csv\n",
      "\n",
      "Epoch [29/50]\n",
      "Train Loss: 0.0137, Train AUC: 0.8007, Train AP: 0.3338, Train Gini: 0.6014\n",
      "Train Acc: 0.9854, Train Precision: 0.8536, Train Recall: 0.2141, Train F1: 0.3423\n",
      "Val Loss: 0.0139, Val AUC: 0.8100, Val AP: 0.3232, Val Gini: 0.6201, Mean Y Predicted: 0.0168\n",
      "Val Acc: 0.9852, Val Precision: 0.8444, Val Recall: 0.1946, Val F1: 0.3163\n",
      "Train Confusion Matrix:\n",
      "[[4778359    3171]\n",
      " [  67888   18489]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104749    1995]\n",
      " [  44806   10826]]\n",
      "Metrics plots saved to plots0/epoch_29_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.62it/s]\n",
      "Epoch 30/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_30.csv\n",
      "\n",
      "Epoch [30/50]\n",
      "Train Loss: 0.0135, Train AUC: 0.8040, Train AP: 0.3437, Train Gini: 0.6081\n",
      "Train Acc: 0.9856, Train Precision: 0.8641, Train Recall: 0.2259, Train F1: 0.3582\n",
      "Val Loss: 0.0139, Val AUC: 0.8097, Val AP: 0.3214, Val Gini: 0.6194, Mean Y Predicted: 0.0200\n",
      "Val Acc: 0.9852, Val Precision: 0.7985, Val Recall: 0.2087, Val F1: 0.3309\n",
      "Train Confusion Matrix:\n",
      "[[4778462    3068]\n",
      " [  66864   19513]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103814    2930]\n",
      " [  44022   11610]]\n",
      "Metrics plots saved to plots0/epoch_30_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.63it/s]\n",
      "Epoch 31/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_31.csv\n",
      "\n",
      "Epoch [31/50]\n",
      "Train Loss: 0.0135, Train AUC: 0.8026, Train AP: 0.3456, Train Gini: 0.6052\n",
      "Train Acc: 0.9857, Train Precision: 0.8651, Train Recall: 0.2300, Train F1: 0.3634\n",
      "Val Loss: 0.0140, Val AUC: 0.8061, Val AP: 0.3173, Val Gini: 0.6122, Mean Y Predicted: 0.0170\n",
      "Val Acc: 0.9851, Val Precision: 0.7931, Val Recall: 0.2062, Val F1: 0.3273\n",
      "Train Confusion Matrix:\n",
      "[[4778431    3099]\n",
      " [  66508   19869]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103751    2993]\n",
      " [  44159   11473]]\n",
      "Metrics plots saved to plots0/epoch_31_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.59it/s]\n",
      "Epoch 32/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_32.csv\n",
      "\n",
      "Epoch [32/50]\n",
      "Train Loss: 0.0137, Train AUC: 0.7986, Train AP: 0.3337, Train Gini: 0.5973\n",
      "Train Acc: 0.9854, Train Precision: 0.8490, Train Recall: 0.2179, Train F1: 0.3468\n",
      "Val Loss: 0.0143, Val AUC: 0.8047, Val AP: 0.3105, Val Gini: 0.6093, Mean Y Predicted: 0.0098\n",
      "Val Acc: 0.9849, Val Precision: 0.7811, Val Recall: 0.1977, Val F1: 0.3156\n",
      "Train Confusion Matrix:\n",
      "[[4778183    3347]\n",
      " [  67554   18823]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103662    3082]\n",
      " [  44633   10999]]\n",
      "Metrics plots saved to plots0/epoch_32_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.68it/s]\n",
      "Epoch 33/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_33.csv\n",
      "\n",
      "Epoch [33/50]\n",
      "Train Loss: 0.0138, Train AUC: 0.7978, Train AP: 0.3296, Train Gini: 0.5956\n",
      "Train Acc: 0.9853, Train Precision: 0.8493, Train Recall: 0.2097, Train F1: 0.3364\n",
      "Val Loss: 0.0140, Val AUC: 0.8059, Val AP: 0.3143, Val Gini: 0.6118, Mean Y Predicted: 0.0161\n",
      "Val Acc: 0.9850, Val Precision: 0.8538, Val Recall: 0.1764, Val F1: 0.2923\n",
      "Train Confusion Matrix:\n",
      "[[4778316    3214]\n",
      " [  68262   18115]]\n",
      "Validation Confusion Matrix:\n",
      "[[3105064    1680]\n",
      " [  45821    9811]]\n",
      "Metrics plots saved to plots0/epoch_33_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.68it/s]\n",
      "Epoch 34/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_34.csv\n",
      "\n",
      "Epoch [34/50]\n",
      "Train Loss: 0.0140, Train AUC: 0.7926, Train AP: 0.3161, Train Gini: 0.5852\n",
      "Train Acc: 0.9851, Train Precision: 0.8351, Train Recall: 0.1963, Train F1: 0.3179\n",
      "Val Loss: 0.0141, Val AUC: 0.8014, Val AP: 0.3098, Val Gini: 0.6028, Mean Y Predicted: 0.0170\n",
      "Val Acc: 0.9848, Val Precision: 0.8225, Val Recall: 0.1751, Val F1: 0.2887\n",
      "Train Confusion Matrix:\n",
      "[[4778181    3349]\n",
      " [  69419   16958]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104642    2102]\n",
      " [  45893    9739]]\n",
      "Metrics plots saved to plots0/epoch_34_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Training: 100%|██████████| 1164/1164 [02:13<00:00,  8.71it/s]\n",
      "Epoch 35/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_35.csv\n",
      "\n",
      "Epoch [35/50]\n",
      "Train Loss: 0.0137, Train AUC: 0.7975, Train AP: 0.3335, Train Gini: 0.5950\n",
      "Train Acc: 0.9854, Train Precision: 0.8455, Train Recall: 0.2163, Train F1: 0.3444\n",
      "Val Loss: 0.0139, Val AUC: 0.8064, Val AP: 0.3228, Val Gini: 0.6128, Mean Y Predicted: 0.0155\n",
      "Val Acc: 0.9852, Val Precision: 0.7989, Val Recall: 0.2088, Val F1: 0.3310\n",
      "Train Confusion Matrix:\n",
      "[[4778116    3414]\n",
      " [  67697   18680]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103820    2924]\n",
      " [  44017   11615]]\n",
      "Metrics plots saved to plots0/epoch_35_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Training: 100%|██████████| 1164/1164 [02:17<00:00,  8.46it/s]\n",
      "Epoch 36/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_36.csv\n",
      "\n",
      "Epoch [36/50]\n",
      "Train Loss: 0.0135, Train AUC: 0.8063, Train AP: 0.3463, Train Gini: 0.6125\n",
      "Train Acc: 0.9857, Train Precision: 0.8568, Train Recall: 0.2332, Train F1: 0.3666\n",
      "Val Loss: 0.0138, Val AUC: 0.8087, Val AP: 0.3231, Val Gini: 0.6174, Mean Y Predicted: 0.0151\n",
      "Val Acc: 0.9852, Val Precision: 0.8339, Val Recall: 0.2002, Val F1: 0.3229\n",
      "Train Confusion Matrix:\n",
      "[[4778165    3365]\n",
      " [  66237   20140]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104525    2219]\n",
      " [  44492   11140]]\n",
      "Metrics plots saved to plots0/epoch_36_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.67it/s]\n",
      "Epoch 37/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_37.csv\n",
      "\n",
      "Epoch [37/50]\n",
      "Train Loss: 0.0134, Train AUC: 0.8070, Train AP: 0.3514, Train Gini: 0.6140\n",
      "Train Acc: 0.9858, Train Precision: 0.8783, Train Recall: 0.2349, Train F1: 0.3706\n",
      "Val Loss: 0.0140, Val AUC: 0.8084, Val AP: 0.3199, Val Gini: 0.6168, Mean Y Predicted: 0.0158\n",
      "Val Acc: 0.9851, Val Precision: 0.8090, Val Recall: 0.1988, Val F1: 0.3191\n",
      "Train Confusion Matrix:\n",
      "[[4778718    2812]\n",
      " [  66088   20289]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104134    2610]\n",
      " [  44574   11058]]\n",
      "Metrics plots saved to plots0/epoch_37_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.65it/s]\n",
      "Epoch 38/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_38.csv\n",
      "\n",
      "Epoch [38/50]\n",
      "Train Loss: 0.0133, Train AUC: 0.8044, Train AP: 0.3539, Train Gini: 0.6088\n",
      "Train Acc: 0.9859, Train Precision: 0.8762, Train Recall: 0.2415, Train F1: 0.3787\n",
      "Val Loss: 0.0138, Val AUC: 0.8109, Val AP: 0.3271, Val Gini: 0.6217, Mean Y Predicted: 0.0209\n",
      "Val Acc: 0.9853, Val Precision: 0.8175, Val Recall: 0.2106, Val F1: 0.3349\n",
      "Train Confusion Matrix:\n",
      "[[4778583    2947]\n",
      " [  65514   20863]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104129    2615]\n",
      " [  43917   11715]]\n",
      "Metrics plots saved to plots0/epoch_38_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.58it/s]\n",
      "Epoch 39/50 - Validation: 100%|██████████| 554/554 [00:38<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_39.csv\n",
      "\n",
      "Epoch [39/50]\n",
      "Train Loss: 0.0132, Train AUC: 0.8062, Train AP: 0.3568, Train Gini: 0.6125\n",
      "Train Acc: 0.9860, Train Precision: 0.8787, Train Recall: 0.2460, Train F1: 0.3844\n",
      "Val Loss: 0.0140, Val AUC: 0.8065, Val AP: 0.3181, Val Gini: 0.6130, Mean Y Predicted: 0.0163\n",
      "Val Acc: 0.9851, Val Precision: 0.8013, Val Recall: 0.2055, Val F1: 0.3271\n",
      "Train Confusion Matrix:\n",
      "[[4778596    2934]\n",
      " [  65126   21251]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103909    2835]\n",
      " [  44201   11431]]\n",
      "Metrics plots saved to plots0/epoch_39_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.64it/s]\n",
      "Epoch 40/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_40.csv\n",
      "\n",
      "Epoch [40/50]\n",
      "Train Loss: 0.0132, Train AUC: 0.8061, Train AP: 0.3580, Train Gini: 0.6121\n",
      "Train Acc: 0.9861, Train Precision: 0.8780, Train Recall: 0.2486, Train F1: 0.3875\n",
      "Val Loss: 0.0139, Val AUC: 0.8098, Val AP: 0.3211, Val Gini: 0.6197, Mean Y Predicted: 0.0173\n",
      "Val Acc: 0.9852, Val Precision: 0.8401, Val Recall: 0.1937, Val F1: 0.3148\n",
      "Train Confusion Matrix:\n",
      "[[4778546    2984]\n",
      " [  64902   21475]]\n",
      "Validation Confusion Matrix:\n",
      "[[3104694    2050]\n",
      " [  44858   10774]]\n",
      "Metrics plots saved to plots0/epoch_40_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.63it/s]\n",
      "Epoch 41/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_41.csv\n",
      "\n",
      "Epoch [41/50]\n",
      "Train Loss: 0.0132, Train AUC: 0.8054, Train AP: 0.3588, Train Gini: 0.6109\n",
      "Train Acc: 0.9861, Train Precision: 0.8812, Train Recall: 0.2497, Train F1: 0.3891\n",
      "Val Loss: 0.0143, Val AUC: 0.8096, Val AP: 0.3161, Val Gini: 0.6193, Mean Y Predicted: 0.0132\n",
      "Val Acc: 0.9846, Val Precision: 0.6783, Val Recall: 0.2352, Val F1: 0.3492\n",
      "Train Confusion Matrix:\n",
      "[[4778624    2906]\n",
      " [  64812   21565]]\n",
      "Validation Confusion Matrix:\n",
      "[[3100539    6205]\n",
      " [  42550   13082]]\n",
      "Metrics plots saved to plots0/epoch_41_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.63it/s]\n",
      "Epoch 42/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_42.csv\n",
      "\n",
      "Epoch [42/50]\n",
      "Train Loss: 0.0134, Train AUC: 0.8069, Train AP: 0.3494, Train Gini: 0.6139\n",
      "Train Acc: 0.9858, Train Precision: 0.8559, Train Recall: 0.2434, Train F1: 0.3790\n",
      "Val Loss: 0.0143, Val AUC: 0.8067, Val AP: 0.2981, Val Gini: 0.6134, Mean Y Predicted: 0.0184\n",
      "Val Acc: 0.9846, Val Precision: 0.7299, Val Recall: 0.2015, Val F1: 0.3158\n",
      "Train Confusion Matrix:\n",
      "[[4777991    3539]\n",
      " [  65357   21020]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102596    4148]\n",
      " [  44423   11209]]\n",
      "Metrics plots saved to plots0/epoch_42_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Training: 100%|██████████| 1164/1164 [02:14<00:00,  8.65it/s]\n",
      "Epoch 43/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_43.csv\n",
      "\n",
      "Epoch [43/50]\n",
      "Train Loss: 0.0132, Train AUC: 0.8102, Train AP: 0.3589, Train Gini: 0.6205\n",
      "Train Acc: 0.9861, Train Precision: 0.8766, Train Recall: 0.2493, Train F1: 0.3883\n",
      "Val Loss: 0.0140, Val AUC: 0.8110, Val AP: 0.3208, Val Gini: 0.6219, Mean Y Predicted: 0.0159\n",
      "Val Acc: 0.9850, Val Precision: 0.7529, Val Recall: 0.2231, Val F1: 0.3442\n",
      "Train Confusion Matrix:\n",
      "[[4778499    3031]\n",
      " [  64839   21538]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102670    4074]\n",
      " [  43219   12413]]\n",
      "Metrics plots saved to plots0/epoch_43_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.57it/s]\n",
      "Epoch 44/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_44.csv\n",
      "\n",
      "Epoch [44/50]\n",
      "Train Loss: 0.0131, Train AUC: 0.8103, Train AP: 0.3645, Train Gini: 0.6205\n",
      "Train Acc: 0.9862, Train Precision: 0.8839, Train Recall: 0.2586, Train F1: 0.4002\n",
      "Val Loss: 0.0140, Val AUC: 0.8102, Val AP: 0.3145, Val Gini: 0.6204, Mean Y Predicted: 0.0172\n",
      "Val Acc: 0.9851, Val Precision: 0.7845, Val Recall: 0.2086, Val F1: 0.3296\n",
      "Train Confusion Matrix:\n",
      "[[4778595    2935]\n",
      " [  64038   22339]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103555    3189]\n",
      " [  44025   11607]]\n",
      "Metrics plots saved to plots0/epoch_44_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Training: 100%|██████████| 1164/1164 [02:16<00:00,  8.52it/s]\n",
      "Epoch 45/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_45.csv\n",
      "\n",
      "Epoch [45/50]\n",
      "Train Loss: 0.0130, Train AUC: 0.8109, Train AP: 0.3688, Train Gini: 0.6218\n",
      "Train Acc: 0.9864, Train Precision: 0.8962, Train Recall: 0.2621, Train F1: 0.4056\n",
      "Val Loss: 0.0140, Val AUC: 0.8088, Val AP: 0.3167, Val Gini: 0.6176, Mean Y Predicted: 0.0196\n",
      "Val Acc: 0.9851, Val Precision: 0.7550, Val Recall: 0.2226, Val F1: 0.3439\n",
      "Train Confusion Matrix:\n",
      "[[4778908    2622]\n",
      " [  63737   22640]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102725    4019]\n",
      " [  43247   12385]]\n",
      "Metrics plots saved to plots0/epoch_45_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.62it/s]\n",
      "Epoch 46/50 - Validation: 100%|██████████| 554/554 [00:36<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_46.csv\n",
      "\n",
      "Epoch [46/50]\n",
      "Train Loss: 0.0131, Train AUC: 0.8062, Train AP: 0.3609, Train Gini: 0.6123\n",
      "Train Acc: 0.9862, Train Precision: 0.8774, Train Recall: 0.2554, Train F1: 0.3956\n",
      "Val Loss: 0.0141, Val AUC: 0.8101, Val AP: 0.3109, Val Gini: 0.6201, Mean Y Predicted: 0.0175\n",
      "Val Acc: 0.9850, Val Precision: 0.7886, Val Recall: 0.1984, Val F1: 0.3170\n",
      "Train Confusion Matrix:\n",
      "[[4778448    3082]\n",
      " [  64318   22059]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103786    2958]\n",
      " [  44595   11037]]\n",
      "Metrics plots saved to plots0/epoch_46_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.61it/s]\n",
      "Epoch 47/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_47.csv\n",
      "\n",
      "Epoch [47/50]\n",
      "Train Loss: 0.0130, Train AUC: 0.8085, Train AP: 0.3667, Train Gini: 0.6169\n",
      "Train Acc: 0.9863, Train Precision: 0.8876, Train Recall: 0.2616, Train F1: 0.4041\n",
      "Val Loss: 0.0140, Val AUC: 0.8107, Val AP: 0.3183, Val Gini: 0.6215, Mean Y Predicted: 0.0177\n",
      "Val Acc: 0.9851, Val Precision: 0.7621, Val Recall: 0.2210, Val F1: 0.3427\n",
      "Train Confusion Matrix:\n",
      "[[4778669    2861]\n",
      " [  63781   22596]]\n",
      "Validation Confusion Matrix:\n",
      "[[3102905    3839]\n",
      " [  43335   12297]]\n",
      "Metrics plots saved to plots0/epoch_47_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.61it/s]\n",
      "Epoch 48/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_48.csv\n",
      "\n",
      "Epoch [48/50]\n",
      "Train Loss: 0.0131, Train AUC: 0.8081, Train AP: 0.3652, Train Gini: 0.6162\n",
      "Train Acc: 0.9863, Train Precision: 0.8925, Train Recall: 0.2568, Train F1: 0.3989\n",
      "Val Loss: 0.0142, Val AUC: 0.8045, Val AP: 0.3107, Val Gini: 0.6091, Mean Y Predicted: 0.0135\n",
      "Val Acc: 0.9849, Val Precision: 0.7632, Val Recall: 0.2045, Val F1: 0.3225\n",
      "Train Confusion Matrix:\n",
      "[[4778858    2672]\n",
      " [  64192   22185]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103215    3529]\n",
      " [  44258   11374]]\n",
      "Metrics plots saved to plots0/epoch_48_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Training: 100%|██████████| 1164/1164 [02:15<00:00,  8.58it/s]\n",
      "Epoch 49/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_49.csv\n",
      "\n",
      "Epoch [49/50]\n",
      "Train Loss: 0.0130, Train AUC: 0.8118, Train AP: 0.3695, Train Gini: 0.6236\n",
      "Train Acc: 0.9864, Train Precision: 0.8902, Train Recall: 0.2662, Train F1: 0.4098\n",
      "Val Loss: 0.0140, Val AUC: 0.8112, Val AP: 0.3164, Val Gini: 0.6224, Mean Y Predicted: 0.0169\n",
      "Val Acc: 0.9851, Val Precision: 0.8010, Val Recall: 0.2060, Val F1: 0.3277\n",
      "Train Confusion Matrix:\n",
      "[[4778695    2835]\n",
      " [  63384   22993]]\n",
      "Validation Confusion Matrix:\n",
      "[[3103898    2846]\n",
      " [  44173   11459]]\n",
      "Metrics plots saved to plots0/epoch_49_metrics.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Training: 100%|██████████| 1164/1164 [02:16<00:00,  8.51it/s]\n",
      "Epoch 50/50 - Validation: 100%|██████████| 554/554 [00:37<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions saved to Models0/val_predictions_epoch_50.csv\n",
      "\n",
      "Epoch [50/50]\n",
      "Train Loss: 0.0127, Train AUC: 0.8132, Train AP: 0.3806, Train Gini: 0.6264\n",
      "Train Acc: 0.9867, Train Precision: 0.9102, Train Recall: 0.2783, Train F1: 0.4263\n",
      "Val Loss: 0.0141, Val AUC: 0.8110, Val AP: 0.3182, Val Gini: 0.6220, Mean Y Predicted: 0.0217\n",
      "Val Acc: 0.9849, Val Precision: 0.7262, Val Recall: 0.2279, Val F1: 0.3470\n",
      "Train Confusion Matrix:\n",
      "[[4779159    2371]\n",
      " [  62339   24038]]\n",
      "Validation Confusion Matrix:\n",
      "[[3101962    4782]\n",
      " [  42951   12681]]\n",
      "Metrics plots saved to plots0/epoch_50_metrics.png\n",
      "Training complete. All models and plots are saved in their respective directories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "os.makedirs(\"Models0\", exist_ok=True)\n",
    "os.makedirs(\"plots0\", exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "class NASSequenceModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 numerical_features,\n",
    "                 categorical_features,\n",
    "                 embedding_dims,\n",
    "                 label_encoders,\n",
    "                 hidden_size=512,\n",
    "                 lstm_layers=4,\n",
    "                 attention_heads=4,\n",
    "                 attention_dropout=0.2,\n",
    "                 fc_dropout=0.2,\n",
    "                 max_seq_len=150):\n",
    "        super().__init__()\n",
    "\n",
    "        self.numerical_features   = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            col: nn.Embedding(\n",
    "                len(label_encoders[col].classes_) + 1,\n",
    "                embedding_dims[col],\n",
    "                padding_idx=0\n",
    "            )\n",
    "            for col in categorical_features\n",
    "        })\n",
    "        total_embed_dim = sum(embedding_dims[c] for c in categorical_features)\n",
    "        input_dim       = total_embed_dim + len(numerical_features)\n",
    "\n",
    "        self.abs_pos_emb   = nn.Parameter(torch.zeros(1, max_seq_len, input_dim))\n",
    "        self.time_gap_proj = nn.Linear(1, input_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "\n",
    "        self.layer_norm_pre_attn  = nn.LayerNorm(hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            hidden_size, attention_heads, attention_dropout, batch_first=True\n",
    "        )\n",
    "        self.layer_norm_post_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.gate_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.body_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out    = nn.Linear(hidden_size, 1)\n",
    "        self.dropout   = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, X_num, X_cat, mask=None, delta_t=None):\n",
    "        cat_parts = [self.embeddings[col](X_cat[col]) for col in self.categorical_features]\n",
    "        x_cat  = torch.cat(cat_parts, dim=-1)\n",
    "        x      = torch.cat([X_num, x_cat], dim=-1)\n",
    "\n",
    "        x = x + self.abs_pos_emb[:, :x.size(1), :]\n",
    "\n",
    "        if delta_t is not None:\n",
    "            x = x + self.time_gap_proj(torch.log1p(delta_t))\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm_pre_attn(x)\n",
    "        key_padding = None if mask is None else (mask == 0)\n",
    "        seq_len = x.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool),\n",
    "                                 diagonal=1)\n",
    "        attn_out, _ = self.multihead_attn(x, x, x,\n",
    "                                          attn_mask=causal_mask,\n",
    "                                          key_padding_mask=key_padding)\n",
    "        x = residual + attn_out\n",
    "        x = self.layer_norm_post_attn(x)\n",
    "\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        body = torch.tanh(self.body_proj(x))\n",
    "        x = self.dropout(gate * body)\n",
    "        logits = self.fc_out(x).squeeze(-1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "class UserSequenceDataset(Dataset):\n",
    "    def __init__(self, X_numerical, X_categorical, y, mask, unique_ids):\n",
    "        self.X_numerical = torch.tensor(X_numerical, dtype=torch.float32)\n",
    "        self.X_categorical = {col: torch.tensor(values, dtype=torch.long) for col, values in X_categorical.items()}\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.unique_ids = unique_ids\n",
    "        self.num_samples = self.X_numerical.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_num = self.X_numerical[idx]\n",
    "        X_cat = {col: values[idx] for col, values in self.X_categorical.items()}\n",
    "        y_seq = self.y[idx]\n",
    "        mask_seq = self.mask[idx]\n",
    "        unique_id = torch.tensor(self.unique_ids[idx], dtype=torch.long)\n",
    "        if unique_id.dim() == 2:\n",
    "            unique_id = unique_id[:, 0]\n",
    "        return (X_num, X_cat), y_seq, mask_seq, unique_id\n",
    "\n",
    "with open('processed_data_pytorch.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "X_train_numerical = processed_data['X_train_numerical']\n",
    "X_train_categorical = processed_data['X_train_embedding']\n",
    "y_train = processed_data['y_train']\n",
    "train_mask = processed_data['train_mask']\n",
    "train_unique_ids = processed_data.get('train_unique_ids', [])\n",
    "X_test_numerical = processed_data['X_test_numerical']\n",
    "X_test_categorical = processed_data['X_test_embedding']\n",
    "y_test = processed_data['y_test']\n",
    "test_mask = processed_data['test_mask']\n",
    "test_unique_ids = processed_data.get('test_unique_ids', [])\n",
    "class_weight_dict = processed_data['class_weight_dict']\n",
    "max_seq_length = processed_data['max_seq_length']\n",
    "numerical_features = processed_data['numerical_features']\n",
    "categorical_features = processed_data['embedding_features']\n",
    "\n",
    "print(\"Processed data loaded successfully.\")\n",
    "\n",
    "train_dataset = UserSequenceDataset(X_train_numerical, X_train_categorical, y_train, train_mask, train_unique_ids)\n",
    "test_dataset = UserSequenceDataset(X_test_numerical, X_test_categorical, y_test, test_mask, test_unique_ids)\n",
    "\n",
    "num_workers = 20\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "class MockLabelEncoder:\n",
    "    def __init__(self, num_classes):\n",
    "        self.classes_ = list(range(num_classes))\n",
    "\n",
    "mock_label_encoders = {col: MockLabelEncoder(num_classes=int(np.max(X_train_categorical[col]) + 1))\n",
    "                       for col in categorical_features}\n",
    "\n",
    "embedding_dims = {col: int(min(50, np.ceil((np.max(X_train_categorical[col]) + 1) / 2)))\n",
    "                  for col in categorical_features}\n",
    "\n",
    "model = NASSequenceModel(numerical_features, categorical_features, embedding_dims, mock_label_encoders)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    def forward(self, logits, targets):\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        return self.mse_loss(probabilities, targets)\n",
    "\n",
    "criterion = MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=20, verbose=True)\n",
    "\n",
    "y_train_flat = np.array(y_train).flatten()\n",
    "train_mask_flat = np.array(train_mask).flatten()\n",
    "y_train_valid = y_train_flat[train_mask_flat == 1]\n",
    "baseline_ctr = y_train_valid.mean()\n",
    "baseline_loss = - (baseline_ctr * np.log(baseline_ctr + 1e-9) +\n",
    "                   (1 - baseline_ctr) * np.log((1 - baseline_ctr) + 1e-9))\n",
    "baseline_loss = max(baseline_loss, 1e-12)\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_auc = 0.0\n",
    "epochs_list, train_loss_list, val_loss_list = [], [], []\n",
    "train_auc_list, val_auc_list = [], []\n",
    "train_ap_list,  val_ap_list  = [], []\n",
    "train_gini_list, val_gini_list = [], []\n",
    "train_rig_list,  val_rig_list  = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses, train_y_true, train_y_pred = [], [], []\n",
    "\n",
    "    for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "            train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training'):\n",
    "\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "        y_batch     = y_batch.to(device)\n",
    "        mask_batch  = mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "        logits_flat    = logits.view(-1)\n",
    "        y_batch_flat   = y_batch.view(-1)\n",
    "        mask_flat      = mask_batch.view(-1)\n",
    "        valid_idx      = mask_flat == 1\n",
    "        logits_valid   = logits_flat[valid_idx]\n",
    "        y_valid        = y_batch_flat[valid_idx]\n",
    "\n",
    "        loss = criterion(logits_valid, y_valid.float())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_y_true.extend(y_valid.detach().cpu().numpy())\n",
    "        train_y_pred.extend(torch.sigmoid(logits_valid.detach()).cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_auc  = roc_auc_score(train_y_true, train_y_pred)\n",
    "    train_ap   = average_precision_score(train_y_true, train_y_pred)\n",
    "    train_gini = 2 * train_auc - 1\n",
    "\n",
    "    optimal_threshold_train = 0.5\n",
    "\n",
    "    train_pred_labels = (np.array(train_y_pred) >= 0.5).astype(int)\n",
    "    train_accuracy    = accuracy_score(train_y_true, train_pred_labels)\n",
    "    train_precision   = precision_score(train_y_true, train_pred_labels, zero_division=0)\n",
    "    train_recall      = recall_score(train_y_true, train_pred_labels,  zero_division=0)\n",
    "    train_f1          = f1_score(train_y_true,   train_pred_labels,  zero_division=0)\n",
    "    train_cm = confusion_matrix(train_y_true, train_pred_labels)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses, y_true_val, y_pred_val, val_predictions = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "                test_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Validation'):\n",
    "\n",
    "            X_num_batch = X_num_batch.to(device)\n",
    "            X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "            y_batch     = y_batch.to(device)\n",
    "            mask_batch  = mask_batch.to(device)\n",
    "\n",
    "            actual_ad_ids = X_cat_batch[\"CURRENT_AD_ID\"].view(-1)\n",
    "            logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "\n",
    "            logits_flat    = logits.view(-1)\n",
    "            y_batch_flat   = y_batch.view(-1)\n",
    "            mask_flat      = mask_batch.view(-1)\n",
    "            unique_id_flat = unique_id_batch.view(-1)\n",
    "\n",
    "            valid_idx      = mask_flat == 1\n",
    "            logits_valid   = logits_flat[valid_idx]\n",
    "            y_valid        = y_batch_flat[valid_idx]\n",
    "            uid_valid      = unique_id_flat[valid_idx]\n",
    "\n",
    "            ad_ids_valid = actual_ad_ids[valid_idx].cpu().numpy()\n",
    "            preds_valid  = torch.sigmoid(logits_valid).cpu().numpy()\n",
    "            actual_y_val = y_valid.cpu().numpy()\n",
    "\n",
    "            for uid, pred, actual, ad_id in zip(uid_valid.cpu().numpy(),\n",
    "                                                preds_valid, actual_y_val, ad_ids_valid):\n",
    "                val_predictions.append({\n",
    "                    'Unique_ID': uid,\n",
    "                    'Predicted_Y': pred,\n",
    "                    'Actual_Y': actual,\n",
    "                    'Actual_Ad_ID': ad_id\n",
    "                })\n",
    "\n",
    "            loss = criterion(logits_valid, y_valid.float())\n",
    "            val_losses.append(loss.item())\n",
    "            y_true_val.extend(actual_y_val)\n",
    "            y_pred_val.extend(preds_valid)\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_auc  = roc_auc_score(y_true_val, y_pred_val)\n",
    "    val_ap   = average_precision_score(y_true_val, y_pred_val)\n",
    "    val_gini = 2 * val_auc - 1\n",
    "\n",
    "    fpr_val, tpr_val, thresholds_val = roc_curve(y_true_val, y_pred_val)\n",
    "    youdens_j_val = tpr_val - fpr_val\n",
    "    optimal_idx_val = np.argmax(youdens_j_val)\n",
    "    optimal_threshold_val = thresholds_val[optimal_idx_val]\n",
    "    optimal_threshold_val = 0.5\n",
    "    val_pred_labels = (np.array(y_pred_val) >= optimal_threshold_val).astype(int)\n",
    "    val_accuracy = accuracy_score(y_true_val, val_pred_labels)\n",
    "    val_precision = precision_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_recall = recall_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_f1 = f1_score(y_true_val, val_pred_labels, zero_division=0)\n",
    "    val_cm = confusion_matrix(y_true_val, val_pred_labels)\n",
    "    val_pred_mean = np.mean(y_pred_val)\n",
    "\n",
    "    scheduler.step(val_auc)\n",
    "\n",
    "    model_save_path = f\"Models0/model_epoch_{epoch+1}.pth\"\n",
    "    thresholds_save_path = f\"Models0/thresholds_epoch_{epoch+1}.pkl\"\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_auc': train_auc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_auc': val_auc,\n",
    "    }, model_save_path)\n",
    "\n",
    "    thresholds_info = {\n",
    "        'optimal_threshold_train': float(optimal_threshold_train),\n",
    "        'optimal_threshold_val': float(optimal_threshold_val),\n",
    "    }\n",
    "\n",
    "    with open(thresholds_save_path, 'wb') as f:\n",
    "        pickle.dump(thresholds_info, f)\n",
    "\n",
    "    val_preds_df = pd.DataFrame(val_predictions)\n",
    "    val_preds_save_path = f\"Models0/val_predictions_epoch_{epoch+1}.csv\"\n",
    "    val_preds_df.to_csv(val_preds_save_path, index=False)\n",
    "    print(f\"Validation predictions saved to {val_preds_save_path}\")\n",
    "\n",
    "    epochs_list.append(epoch + 1)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    train_auc_list.append(train_auc)\n",
    "    val_auc_list.append(val_auc)\n",
    "    train_ap_list.append(train_ap)\n",
    "    val_ap_list.append(val_ap)\n",
    "    train_gini_list.append(train_gini)\n",
    "    val_gini_list.append(val_gini)\n",
    "    train_rig_list.append((1 - (train_loss / baseline_loss)) * 100)\n",
    "    val_rig_list.append((1 - (val_loss / baseline_loss)) * 100)\n",
    "\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train AP: {train_ap:.4f}, Train Gini: {train_gini:.4f}')\n",
    "    print(f'Train Acc: {train_accuracy:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val AP: {val_ap:.4f}, Val Gini: {val_gini:.4f}, Mean Y Predicted: {val_pred_mean:.4f}')\n",
    "    print(f'Val Acc: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n",
    "    print(f'Train Confusion Matrix:\\n{train_cm}')\n",
    "    print(f'Validation Confusion Matrix:\\n{val_cm}')\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    axs[0, 0].plot(epochs_list, train_loss_list, label='Train Loss', marker='o')\n",
    "    axs[0, 0].plot(epochs_list, val_loss_list, label='Validation Loss', marker='o')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].set_title('Loss over Epochs')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(epochs_list, train_auc_list, label='Train AUC', marker='o')\n",
    "    axs[0, 1].plot(epochs_list, val_auc_list, label='Validation AUC', marker='o')\n",
    "    axs[0, 1].set_xlabel('Epoch')\n",
    "    axs[0, 1].set_ylabel('AUC')\n",
    "    axs[0, 1].set_title('AUC over Epochs')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[1, 0].plot(epochs_list, train_gini_list, label='Train Gini', marker='o')\n",
    "    axs[1, 0].plot(epochs_list, val_gini_list, label='Validation Gini', marker='o')\n",
    "    axs[1, 0].set_xlabel('Epoch')\n",
    "    axs[1, 0].set_ylabel('Gini Coefficient')\n",
    "    axs[1, 0].set_title('Gini Coefficient over Epochs')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(epochs_list, train_rig_list, label='Train RIG')\n",
    "    axs[1, 1].plot(epochs_list, val_rig_list, label='Validation RIG')\n",
    "    axs[1, 1].set_xlabel('Epoch')\n",
    "    axs[1, 1].set_ylabel('RIG (%)')\n",
    "    axs[1, 1].set_title('Relative Information Gain over Epochs')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_save_path = f'plots0/epoch_{epoch+1}_metrics.png'\n",
    "    plt.savefig(plot_save_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"Metrics plots saved to {plot_save_path}\")\n",
    "\n",
    "print(\"Training complete. All models and plots are saved in their respective directories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c49b4-528c-4816-b2c4-63d977908696",
   "metadata": {},
   "source": [
    "### Counterfactual Prediction on the Test Set (Behavioral Model)\n",
    "\n",
    "After loading the selected best trained model, counterfactual predictions are computed on the **test set**.\n",
    "\n",
    "For each valid timestep, the user’s full past sequence is kept fixed and only the `CURRENT_AD_ID` at that timestep is replaced with every possible ad. The model then predicts click probabilities for each alternative. Sequence logic is preserved because:\n",
    "- Data are time-ordered and truncated consistently.\n",
    "- Padding is excluded via the mask.\n",
    "- Causal attention prevents using future information.\n",
    "\n",
    "Thus, each counterfactual prediction reflects: given the user’s history up to time *t*, what would happen if a different ad were shown?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0aaeb2-29fe-45fd-ba96-b5d5c9d7209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features Columns:\n",
      "['MEDIA_PACKAGE_NAME_EMBEDDING', 'MODEL_EMBEDDING', 'BRAND_ID_EMBEDDING', 'OPERATOR_ID_EMBEDDING', 'ISP_ID_EMBEDDING', 'CURRENT_AD_ID']\n",
      "Numerical Features Columns:\n",
      "['HOUR_SIN', 'HOUR_COS', 'MINUTE_SIN', 'MINUTE_COS', 'AD_FREQUENCY', 'AD_CTR', 'AD_CTR_Overall', 'EC', 'CH', 'SCTR', 'TSE', 'TSA', 'TCE', 'TCA', 'CTR_i_Ad', 'Usage_App', 'Effect_App', 'Preference_App', 'Influence_App', 'Overall_Usage_App']\n",
      "Current numerical features: 20\n",
      "Current embedding dimension sum: 68\n",
      "Expected LSTM input size: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regular Eval for Epoch 45: 100%|██████████| 554/554 [00:27<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Validation Performance Metrics:\n",
      "Val AUC: 0.8088\n",
      "Val AP: 0.3167\n",
      "Val Accuracy: 0.9851\n",
      "Val Precision: 0.7550\n",
      "Val Recall: 0.2226\n",
      "Val F1: 0.3439\n",
      "Val Gini: 0.6176\n",
      "Val Predicted Y Mean: 0.0196\n",
      "Val Confusion Matrix:\n",
      "[[3102724    4020]\n",
      " [  43247   12385]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counterfactual Eval for Epoch 45: 100%|██████████| 554/554 [1:23:20<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual validation predictions saved to Models0/val_counterfactual_predictions_epoch_Behavioral.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "desired_epoch = 45\n",
    "csv_path = f\"Models0/val_predictions_epoch_{desired_epoch}.csv\"\n",
    "val_df = pd.read_csv(csv_path).copy()\n",
    "val_df['Unique_ID'] = val_df['Unique_ID'].astype(int)\n",
    "\n",
    "with open('processed_data_pytorch.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "X_test_numerical = processed_data['X_test_numerical']\n",
    "X_test_categorical = processed_data['X_test_embedding']\n",
    "y_test = processed_data['y_test']\n",
    "test_mask = processed_data['test_mask']\n",
    "test_unique_ids = processed_data.get('test_unique_ids', [])\n",
    "class_weight_dict = processed_data['class_weight_dict']\n",
    "max_seq_length = processed_data['max_seq_length']\n",
    "numerical_features = processed_data['numerical_features']\n",
    "categorical_features = processed_data['embedding_features']\n",
    "\n",
    "class MockLabelEncoder:\n",
    "    def __init__(self, num_classes):\n",
    "        self.classes_ = list(range(num_classes))\n",
    "\n",
    "mock_label_encoders = {\n",
    "    col: MockLabelEncoder(num_classes=int(np.max(X_test_categorical[col]) + 1))\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "embedding_dims = {\n",
    "    col: int(min(50, np.ceil((np.max(X_test_categorical[col]) + 1) / 2)))\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "print(\"Categorical Features Columns:\")\n",
    "print(categorical_features)\n",
    "\n",
    "print(\"Numerical Features Columns:\")\n",
    "print(numerical_features)\n",
    "\n",
    "print(f\"Current numerical features: {len(numerical_features)}\")\n",
    "print(f\"Current embedding dimension sum: {sum(embedding_dims.values())}\")\n",
    "print(f\"Expected LSTM input size: {len(numerical_features) + sum(embedding_dims.values())}\")\n",
    "\n",
    "class UserSequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_numerical, X_categorical, y, mask, unique_ids):\n",
    "        self.X_numerical = torch.tensor(X_numerical, dtype=torch.float32)\n",
    "        self.X_categorical = {\n",
    "            col: torch.tensor(vals, dtype=torch.long)\n",
    "            for col, vals in X_categorical.items()\n",
    "        }\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.unique_ids = unique_ids\n",
    "        self.num_samples = self.X_numerical.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_num = self.X_numerical[idx]\n",
    "        X_cat = {col: vals[idx] for col, vals in self.X_categorical.items()}\n",
    "        y_seq = self.y[idx]\n",
    "        mask_seq = self.mask[idx]\n",
    "        unique_id = torch.tensor(self.unique_ids[idx], dtype=torch.long)\n",
    "        if unique_id.dim() == 2:\n",
    "            unique_id = unique_id[:, 0]\n",
    "        return (X_num, X_cat), y_seq, mask_seq, unique_id\n",
    "\n",
    "test_dataset = UserSequenceDataset(\n",
    "    X_test_numerical,\n",
    "    X_test_categorical,\n",
    "    y_test,\n",
    "    test_mask,\n",
    "    test_unique_ids\n",
    ")\n",
    "\n",
    "num_workers = 10\n",
    "batch_size = 256\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "class NASSequenceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        numerical_features,\n",
    "        categorical_features,\n",
    "        embedding_dims,\n",
    "        label_encoders,\n",
    "        hidden_size=512,\n",
    "        lstm_layers=4,\n",
    "        attention_heads=4,\n",
    "        attention_dropout=0.2,\n",
    "        fc_dropout=0.2,\n",
    "        max_seq_len=150\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            col: nn.Embedding(\n",
    "                len(label_encoders[col].classes_) + 1,\n",
    "                embedding_dims[col],\n",
    "                padding_idx=0\n",
    "            )\n",
    "            for col in categorical_features\n",
    "        })\n",
    "\n",
    "        total_embed_dim = sum(embedding_dims[c] for c in categorical_features)\n",
    "        input_dim = total_embed_dim + len(numerical_features)\n",
    "\n",
    "        self.abs_pos_emb = nn.Parameter(torch.zeros(1, max_seq_len, input_dim))\n",
    "        self.time_gap_proj = nn.Linear(1, input_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.layer_norm_pre_attn = nn.LayerNorm(hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            hidden_size,\n",
    "            attention_heads,\n",
    "            attention_dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.layer_norm_post_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.gate_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.body_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, X_num, X_cat, mask=None, delta_t=None):\n",
    "        cat_parts = [\n",
    "            self.embeddings[col](X_cat[col])\n",
    "            for col in self.categorical_features\n",
    "        ]\n",
    "        x_cat = torch.cat(cat_parts, dim=-1)\n",
    "        x = torch.cat([X_num, x_cat], dim=-1)\n",
    "\n",
    "        x = x + self.abs_pos_emb[:, :x.size(1), :]\n",
    "\n",
    "        if delta_t is not None:\n",
    "            x = x + self.time_gap_proj(torch.log1p(delta_t))\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm_pre_attn(x)\n",
    "        key_padding = None if mask is None else (mask == 0)\n",
    "        seq_len = x.size(1)\n",
    "        causal_mask = torch.triu(\n",
    "            torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool),\n",
    "            diagonal=1\n",
    "        )\n",
    "\n",
    "        attn_out, _ = self.multihead_attn(\n",
    "            x, x, x,\n",
    "            attn_mask=causal_mask,\n",
    "            key_padding_mask=key_padding\n",
    "        )\n",
    "\n",
    "        x = residual + attn_out\n",
    "        x = self.layer_norm_post_attn(x)\n",
    "\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        body = torch.tanh(self.body_proj(x))\n",
    "        x = self.dropout(gate * body)\n",
    "        logits = self.fc_out(x).squeeze(-1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "mock_label_encoders = {\n",
    "    col: MockLabelEncoder(\n",
    "        num_classes=int(np.max(processed_data['X_train_embedding'][col]) + 1)\n",
    "    )\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "embedding_dims = {\n",
    "    col: int(\n",
    "        min(\n",
    "            50,\n",
    "            np.ceil(\n",
    "                (np.max(processed_data['X_train_embedding'][col]) + 1) / 2\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    for col in categorical_features\n",
    "}\n",
    "\n",
    "numerical_features = processed_data['numerical_features']\n",
    "\n",
    "model = NASSequenceModel(\n",
    "    numerical_features,\n",
    "    categorical_features,\n",
    "    embedding_dims,\n",
    "    mock_label_encoders\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint_path = f\"Models0/model_epoch_{desired_epoch}.pth\"\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    checkpoint_path,\n",
    "    map_location=torch.device('cpu'),\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_num_batch, X_cat_batch), y_batch, mask_batch, unique_id_batch in tqdm(\n",
    "        test_loader,\n",
    "        desc=f'Regular Eval for Epoch {desired_epoch}'\n",
    "    ):\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {col: X_cat_batch[col].to(device) for col in X_cat_batch}\n",
    "        y_batch = y_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "\n",
    "        actual_ad_ids = X_cat_batch[\"CURRENT_AD_ID\"].view(-1)\n",
    "\n",
    "        logits = model(X_num_batch, X_cat_batch, mask=mask_batch)\n",
    "\n",
    "        logits_flat = logits.view(-1)\n",
    "        y_flat = y_batch.view(-1)\n",
    "        mask_flat = mask_batch.view(-1)\n",
    "        unique_id_flat = unique_id_batch.view(-1)\n",
    "\n",
    "        valid_idx = mask_flat == 1\n",
    "\n",
    "        preds = torch.sigmoid(logits_flat[valid_idx]).detach().cpu().numpy()\n",
    "        y_true = y_flat[valid_idx].detach().cpu().numpy()\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(preds)\n",
    "\n",
    "val_auc = roc_auc_score(all_y_true, all_y_pred)\n",
    "val_ap = average_precision_score(all_y_true, all_y_pred)\n",
    "optimal_threshold = 0.5\n",
    "val_pred_labels = (np.array(all_y_pred) >= optimal_threshold).astype(int)\n",
    "val_accuracy = accuracy_score(all_y_true, val_pred_labels)\n",
    "val_precision = precision_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_recall = recall_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_f1 = f1_score(all_y_true, val_pred_labels, zero_division=0)\n",
    "val_cm = confusion_matrix(all_y_true, val_pred_labels)\n",
    "val_gini = 2 * val_auc - 1\n",
    "val_pred_mean = np.mean(all_y_pred)\n",
    "\n",
    "print(\"Regular Validation Performance Metrics:\")\n",
    "print(f\"Val AUC: {val_auc:.4f}\")\n",
    "print(f\"Val AP: {val_ap:.4f}\")\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Val Precision: {val_precision:.4f}\")\n",
    "print(f\"Val Recall: {val_recall:.4f}\")\n",
    "print(f\"Val F1: {val_f1:.4f}\")\n",
    "print(f\"Val Gini: {val_gini:.4f}\")\n",
    "print(f'Val Predicted Y Mean: {val_pred_mean:.4f}')\n",
    "print(\"Val Confusion Matrix:\")\n",
    "print(val_cm)\n",
    "\n",
    "num_ads = len(mock_label_encoders[\"CURRENT_AD_ID\"].classes_)\n",
    "cf_results = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_num_batch, X_cat_batch), _, mask_batch, unique_id_batch in tqdm(\n",
    "        test_loader,\n",
    "        desc=f'Counterfactual Eval for Epoch {desired_epoch}'\n",
    "    ):\n",
    "        X_num_batch = X_num_batch.to(device)\n",
    "        X_cat_batch = {c: X_cat_batch[c].to(device) for c in X_cat_batch}\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        unique_id_batch = unique_id_batch.to(device)\n",
    "\n",
    "        B, L, _ = X_num_batch.size()\n",
    "\n",
    "        for t in range(L):\n",
    "            valid_idx = (mask_batch[:, t] == 1).nonzero(as_tuple=False).squeeze()\n",
    "            if valid_idx.numel() == 0:\n",
    "                continue\n",
    "            if valid_idx.dim() == 0:\n",
    "                valid_idx = valid_idx.unsqueeze(0)\n",
    "\n",
    "            X_num_v = X_num_batch[valid_idx]\n",
    "            X_cat_v = {c: X_cat_batch[c][valid_idx] for c in X_cat_batch}\n",
    "            uids_v = unique_id_batch[valid_idx, t]\n",
    "\n",
    "            X_num_rep = X_num_v.repeat_interleave(num_ads, dim=0)\n",
    "            X_cat_rep = {\n",
    "                c: X_cat_v[c].repeat_interleave(num_ads, dim=0)\n",
    "                for c in X_cat_v\n",
    "            }\n",
    "\n",
    "            ad_vals = torch.arange(num_ads, device=device).repeat(X_num_v.size(0))\n",
    "\n",
    "            if X_cat_rep[\"CURRENT_AD_ID\"].dim() == 1:\n",
    "                X_cat_rep[\"CURRENT_AD_ID\"] = X_cat_rep[\"CURRENT_AD_ID\"].unsqueeze(1)\n",
    "\n",
    "            X_cat_rep[\"CURRENT_AD_ID\"][:, t] = ad_vals\n",
    "\n",
    "            logits_cf = model(X_num_rep, X_cat_rep)\n",
    "            preds_cf = torch.sigmoid(logits_cf[:, t]).view(\n",
    "                X_num_v.size(0),\n",
    "                num_ads\n",
    "            )\n",
    "\n",
    "            for i, uid_tensor in enumerate(uids_v):\n",
    "                uid = int(uid_tensor.item())\n",
    "                cf_results[uid] = {\n",
    "                    f\"cf_ad_{a}\": preds_cf[i, a].item()\n",
    "                    for a in range(num_ads)\n",
    "                }\n",
    "\n",
    "cf_df = pd.DataFrame.from_dict(cf_results, orient='index')\n",
    "cf_df.index.name = \"Unique_ID\"\n",
    "cf_df.reset_index(inplace=True)\n",
    "\n",
    "merged_df = pd.merge(val_df, cf_df, on=\"Unique_ID\", how=\"left\")\n",
    "\n",
    "output_csv = \"Models0/val_counterfactual_predictions_Behavioral.csv\"\n",
    "merged_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Counterfactual validation predictions saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc7557-2604-4748-b2a0-361dab936210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
